var documenterSearchIndex = {"docs":
[{"location":"mcmc/#mcmc","page":"mcmc","title":"mcmc","text":"","category":"section"},{"location":"mcmc/","page":"mcmc","title":"mcmc","text":"Modules = [BayesFitness.mcmc]\nOrder   = [:function, :type]","category":"page"},{"location":"mcmc/#BayesFitness.mcmc.mcmc_mean_fitness-Tuple{}","page":"mcmc","title":"BayesFitness.mcmc.mcmc_mean_fitness","text":"mcmc_mean_fitness(; kwargs)\n\nFunction to sample the posterior distribution of the population mean fitness for a series of pairs of time points. This function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage or not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be used to sample from the population mean fitness posterior distribution.\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputdir::String: Directory where the output .jld2 files containing the MCMC chains should be stored.\noutputname::String: Common pattern for all .jld2 output files. The output files of this function will be named as\n\n$(outputdir)/$(outputname)_$(t)-$(t+1).jld\n\nwhere t and t+1 indicate the time points used during the inference.\n\nmodel::Function: Turing.jl model defining the posterior distribution from which to sample (see BayesFitness.model module). This function must take as the first two inputs the following:\nr̲ₜ::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nr̲ₜ₊₁::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t + 1. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages. \n\nOptional Arguments\n\nmodel_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\nsuppress_output::Bool=false: Boolean indicating if the screen output of Turing.jl must be actively suppressed.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler to be used.\nmultithread::Bool=true: Boolean indicating if the chains should be run in parallel.\nverbose::Bool=true: Boolean indicating if the function should print partial progress to the screen or not.\n\n\n\n\n\n","category":"method"},{"location":"mcmc/#BayesFitness.mcmc.mcmc_mutant_fitness-Tuple{}","page":"mcmc","title":"BayesFitness.mcmc.mcmc_mutant_fitness","text":"mcmc_mutant_fitness(; kwargs)\n\nFunction to sample the posterior distribution of mutant lineages relative fitness given a time-series barcode count. \n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage or not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be used to sample from the population mean fitness posterior distribution.\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputdir::String: Directory where the output .jld2 files containing the MCMC chains should be stored.\noutputname::String: Common pattern for all .jld2 output files. The output files of this function will be named as\n\n$(outputdir)/$(outputname)_$(mutant_id).jld\n\nwhere t and t+1 indicate the time points used during the inference.\n\nmodel::Function: Turing.jl model defining the posterior distribution from which to sample (see BayesFitness.model module). This function must take as the first two inputs the following:\nr̲ₜ::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nr̲ₜ₊₁::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t + 1. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages. \n\nOptional Arguments\n\nmodel_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\nsuppress_output::Bool=false: Boolean indicating if the screen output of Turing.jl must be actively suppressed.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler to be used.\nmultithread_chain::Bool=false: Boolean indicating if the chains should be run in parallel.\nmultithread_mutant::Bool=false: Boolean indicating if the chains should be run in parallel. NOTE: Only one multithread_ option can be true at any point.\nverbose::Bool=true: Boolean indicating if the function should print partial progress to the screen or not.\n\n\n\n\n\n","category":"method"},{"location":"viz/#viz","page":"viz","title":"viz","text":"","category":"section"},{"location":"viz/","page":"viz","title":"viz","text":"Modules = [BayesFitness.viz]\nOrder   = [:function, :type]","category":"page"},{"location":"viz/#BayesFitness.viz.bc_time_series!-Tuple{Makie.Axis, DataFrames.AbstractDataFrame}","page":"viz","title":"BayesFitness.viz.bc_time_series!","text":"bc_time_series!(ax, data; color, alpha, id_col, time_col, quant_col)\n\nFunction to plot the time series of a quantity (frequency or raw counts, for example) for a set of barcodes. This function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode   sequence, for example.\ntime_col: Column defining the measurement time point.\nquant_col: Column with the quantity to be plot over time.\n\nArguments\n\nax::Makie.Axis: Axis object to be populated with plot.\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be used to sample from the population mean fitness posterior distribution.\n\nOptional Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point\n\nat which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\n\nquant_col::Symbol=:count: Name of the column in data containing the raw barcode count.\nzero_lim::Real=1E-8: Number defining under which value quant_col should be considered as zero. These plots are mostly displayed in log scale, thus having a minimum threshold helps with undetermined values.\nzero_label::Union{String, Nothing}: Label to be added to the detection limit. If nothing, nothing is added to the plot.\nn_ticks::Int: Ideal number of ticks to add to plot. See Makie.WilkinsonTicks.\ncolor::Union{ColorSchemes.ColorScheme,Symbol,ColorTypes.Colorant{Float64, 3}}=ColorSchemes.glasbey_hv_n256: Single color or list of colors from ColorSchemes.jl to be used in plot. Note: when a color list is provided, colors are randomnly assigned to each barcode by sampling from the list of colors.\nalpha::AbstractFloat=1.0: Level of transparency for plots.\nlinewidth::Real=5: Trajectory linewidth.\n\n\n\n\n\n","category":"method"},{"location":"viz/#BayesFitness.viz.logfreq_ratio_time_series!-Tuple{Makie.Axis, DataFrames.AbstractDataFrame}","page":"viz","title":"BayesFitness.viz.logfreq_ratio_time_series!","text":"logfreq_ratio_time_series!((ax, data; color, alpha, id_col, time_col, freq_col)\n\nFunction to plot the time series of the log frequency ratiofor a set of barcodes. This function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode   sequence, for example.\ntime_col: Column defining the measurement time point.\nfreq_col: Column with the frequency from which to compute the log ratio.\n\nArguments\n\nax::Makie.Axis: Axis object to be populated with plot.\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be   used to sample from the population mean fitness posterior distribution.\n\nOptional Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point\n\nat which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\n\nfreq_col::Symbol=:count: Name of the column in data containing the barcode frequency.\n`color::Union{ColorSchemes.ColorScheme,Symbol,ColorTypes.Colorant{Float64,\n\n3}}=ColorSchemes.glasbeyhvn256: Single color or list of colors fromColorSchemes.jl` to be used in plot. Note: when a color list is provided, colors are randomnly assigned to each barcode by sampling from the list of colors.\n\nalpha::AbstractFloat=1.0: Level of transparency for plots.\nlinewidth::Real=5: Trajectory linewidth.\nlog_fn::Union{typeof(log), typeof(log10), typeof(log2)}=log: Log function to be used in plot.\n\n\n\n\n\n","category":"method"},{"location":"viz/#BayesFitness.viz.mcmc_fitdist_cdf!-Tuple{Makie.Axis, Vector{<:Real}, Distributions.Distribution{Distributions.Univariate, Distributions.Continuous}}","page":"viz","title":"BayesFitness.viz.mcmc_fitdist_cdf!","text":"mcmc_fitdist_cdf!(ax, chain, dist; n_points, range, ecdf_label, cdf_label, ecdf_kwargs, cdf_kwargs, legend, legend_kwargs)\n\nFunction to plot the ECDF produced from an MCMC chain along with a fitn distribution. This plot serves to compare if the parametrized distribution matches the density of MCMC samples.\n\nNOTE: For this function ecdf refers to the empirical cumulative distribution function build from the MCMC chain, and cdf refers to the parametric cumulative distribution function from the fit distribution.\n\nArguments\n\nax::Makie.Axis: Axis object to be populated with plot.\nchain::Vectors{<:Real}: Vector with the MCMC samples from which to build the ECDF plot.\ndist::Distributions.ContinuousUnivariateDistribution: Parametric distribution to be compared with the ECDF.\n\nOptional Arguments\n\nnpoints::Int=1000: Number of points to evaluate the parametric CDF.\nrange::Union{Nothing,NTuple{2,<:Real}}=nothing: Range on which to evaluate the parametric CDF. If nothing is provided (default), the range is inferred from the range of MCMC samples.\necdf_label::String=\"mcmc\": Legend label for the ECDF plot.\ncdf_label::String=\"fit\": Legend label for the CDF plot.\necdf_kwargs::Dict: Extra keyword arguments for the Makie.ecdfplot! function.\ncdf_kwargs::Dict: Extra keyword arguments for the Makie.lines! function.\nlegend::Bool=true: Boolean indicating if a legend should be added to the plot.\nlegend_kwargs:Dict(): Extra keyword arguments for the Makie.axislegend function.\n\n\n\n\n\n","category":"method"},{"location":"viz/#BayesFitness.viz.mcmc_trace_density!-Tuple{GridLayoutBase.GridLayout, MCMCChains.Chains}","page":"viz","title":"BayesFitness.viz.mcmc_trace_density!","text":"mcmc_trace_density!(gl::GridLayout, chain::MCMCChains.Chains; colors, labels)\n\nFunction to plot the traces and density estimates side-to-side for each of the parametres in the MCMCChains.Chains object.\n\nArguments\n\ngl::Makie.GridLayout: GridLayout object to be populated with plot. This allows the user to have more flexibility on whether they want to embed this plot within other subplots.\nchain::MCMCChains.Chains: Samples from the MCMC run generated with Turing.jl.\n\nOptional arguments\n\ncolors=ColorSchemes.seaborn_colorblind: List of colors to be used in plot.\nlabels: List of labels for each of the parameters. If not given, the default will be to use the names stored in the MCMCChains.Chains object.\nalpha::AbstractFloat=1: Level of transparency for plots.\ntitle::Union{String,Nothing}=nothing: Plot title.\ntitle_valign::Symbol=:bottom: Vertical alignment for title label,\ntitle_font::Symbol=:bold: Type of font to be used in plot.\ntitle_fontsize::Real=20: Font size for title.\ntitle_padding::NTuple{4,<:Real}=(0, 0, 5, 0): Padding for plot text.\n\n\n\n\n\n","category":"method"},{"location":"viz/#BayesFitness.viz.mcmc_trace_density!-Tuple{Makie.Figure, MCMCChains.Chains}","page":"viz","title":"BayesFitness.viz.mcmc_trace_density!","text":"mcmc_trace_density!(fig::Figure, chain::MCMCChains.Chains; colors, labels)\n\nFunction to plot the traces and density estimates side-to-side for each of the parametres in the MCMCChains.Chains object.\n\nArguments\n\nfig::Makie.Figure: Figure object to be populated with plot. This allows the user to decide the size of the figure outside of this function.\nchain::MCMCChains.Chains: Samples from the MCMC run generated with Turing.jl.\n\nOptional arguments\n\ncolors=ColorSchemes.seaborn_colorblind: List of colors to be used in plot.\nlabels: List of labels for each of the parameters. If not given, the default will be to use the names stored in the MCMCChains.Chains object.\nalpha::AbstractFloat=1: Level of transparency for plots.\ntitle::Union{String,Nothing}=nothing: Plot title.\ntitle_valign::Symbol=:bottom: Vertical alignment for title label,\ntitle_font::Symbol=:bold: Type of font to be used in plot.\ntitle_fontsize::Real=20: Font size for title.\ntitle_padding::Vector{<:Real}=(0, 0, 5, 0): Padding for plot text.\n\n\n\n\n\n","category":"method"},{"location":"viz/#BayesFitness.viz.ppc_time_series!-Tuple{Makie.Axis, Vector{<:AbstractFloat}, Matrix{<:Real}}","page":"viz","title":"BayesFitness.viz.ppc_time_series!","text":"ppc_time_series!(ax, quantile, ppc_mat; time, colors, alpha)\n\nFunction to plot the posterior predictive checks quantiles for any quantity.\n\nArguments\n\nax::Makie.Axis: Axis object to be populated with plot. \nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the   posterior predictive checks.\nppc_mat::Matrix{<:AbstractFloat}: Matrix containing the posterior predictive samples. Rows are assumed to contain the samples, columns the time points.\n\nOptional arguments\n\ncolors=ColorSchemes.Blues_9: List of colors to use for each quantile.\nalpha::AbstractFloat=0.75: Level of transparency for band representing each\n\nquantile.\n\n\n\n\n\n","category":"method"},{"location":"model/#model","page":"model","title":"model","text":"","category":"section"},{"location":"model/","page":"model","title":"model","text":"Modules = [BayesFitness.model]\nOrder   = [:function, :type]","category":"page"},{"location":"model/#BayesFitness.model.env_mutant_fitness_lognormal-Tuple{Vector{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.env_mutant_fitness_lognormal","text":"env_mutant_fitness_lognormal(r̲⁽ᵐ⁾, R̲; α, μ_sₜ, σ_sₜ, s_prior, σ_prior, σ_trunc)\n\nTuring.jl model to sample out of the posterior distribution for a single mutant fitness value s⁽ᵐ⁾, given the raw barcode counts and the parametrization of the population mean fitness distribution.\n\nArguments\n\nr̲⁽ᵐ⁾::Vector{Int64}: Mutant m raw barcode counts time-series. Note: this vector must be the same length as r̲⁽ᶜ⁾. This means that each entry r̲⁽ᵐ⁾[i] contains the number of reads from barcode m at time i.\nR̲::Vector{Int64}: time-series of Raw total reads. This means that entry R̲[i] contains the total number of reads obtained at time i.\n\nKeyword arguments\n\nenvs::Vector{<:Any}: Vector defining the order of environments. Environments can be labeled with numbers (e.g. [1, 2, 2, 3, 1, 3]), strings (e.g. [\"env1\", \"env2\", \"env1\"]), or any convenient label. The point being that they should follow the order of environments to which strains were exposed during the experiment.\nα::Vector{Float64}: Parameters for Beta prior distribution.\nμ_sₜ::Vector{Float64}: Array with the time-series mean values of the population mean fitness. This means entry μ_sₜ[i] contains the inferred mean value of the population mean fitness for time i, assuming sₜ[i] ~ Normal(μ_sₜ[i], σ_sₜ[i]).\nσ_sₜ::Vector{Float64}: Array with the time-series values of the population mean fitness standard deviation. This means entry σ_sₜ[i] contains the inferred value of the standard deviation of the population mean fitness at time i, assuming sₜ[i] ~ Normal(μ_sₜ[i], σ_sₜ[i]).\n\nOptional arguments\n\ns_prior::Vector{Real}=[0.0, 2.0]: Parameters for the mutant fitness prior distribution π(s⁽ᵐ⁾).\nσ_prior::Vector{Real}=[0.0, 1.0]: Parameters for the nuisance standard deviation parameter prior distribution π(σ⁽ᵐ⁾).\nσ_trunc::Real=0.0: Value at which truncate the normal distribution to define it as a half-normal.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.mean_fitness_neutrals_lognormal-Tuple{Vector{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.mean_fitness_neutrals_lognormal","text":"mean_fitness_neutrals_lognormal(r̲ₜ, r̲ₜ₊₁; α, s_prior, σ_prior, σ_trunc)\n\nTuring.jl model to sample the posterior for a single population mean fitness value sₜ, given the raw barcode counts. \n\nModel\n\nFor this inference, we can write Bayes theorem as\n\npi(\n    bars_t sigma_t underlinef_t underlinef_t+1 mid\n    underliner_t underliner_t+1\n) propto\nprod_n=1^N left\n        pi(f_t^(n) mid gamma_t^(n)) \n        pi(gamma_t^(n) mid bars_t sigma_t)\nright\npi(bars_t) pi(sigma_t)\npi(underlinef_t mid underliner_t)\npi(underlinef_t+1 mid underliner_t+1)\n\nwhere\n\ngamma_t^(n) equiv fracf_t+1^(n)f_t^n\n\nThe parametric distributions assumed in this model are of the form\n\nf_t^(n) mid gamma_t^(n) sim \noperatornameUniform left(0 frac1gamma_t^(n) right)\n\ngamma_t^(n) mid bars_t sigma_t sim \nlogmathcalN(bars_t sigma_t)\n\nbars_t sim mathcalN(mu_bars_t sigma_bars_t)\n\nsigma_t sim \noperatornameHalf-mathcalN(mu_sigma_t sigma_sigma_t)\n\nunderlinef_t mid underliner_t sim \noperatornameDirichlet(underlinealpha_t + underliner_t)\n\nand\n\nunderlinef_t+1 mid underliner_t+1 sim \noperatornameDirichlet(underlinealpha_t+1 + underliner_t+1)\n\nFor this inference, we enforce all frequencies to be > 0 (even for barcodes with zero reads) to compute gamma_t^(n).\n\nThe user defines the distribution parameters as:\n\nunderlinealpha_t: α.\nmu_bars_t sigma_bars_t: s_prior.\nmu_sigma_t sigma_sigma_t: σ_prior.\n\nArguments\n\nr̲ₜ::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nr̲ₜ₊₁::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t + 1. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\n\nKeyword Arguments\n\nα::Vector{Float64}: Parameters for Dirichlet prior distribution.\n\nOptional arguments\n\ns_prior::Vector{Real}=[0.0, 2.0]: Parameters for the mean fitness prior distribution π(sₜ).\nσ_prior::Vector{Real}=[0.0, 1.0]: Parameters for the nuisance standard deviation parameter prior distribution π(σₜ).\nσ_trunc::Real=0.0: Value at which truncate the normal distribution to define it as a half-normal.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.mean_fitness_neutrals_lognormal_priors-Tuple{Vector{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.mean_fitness_neutrals_lognormal_priors","text":"mean_fitness_neutrals_lognormal_priors(r̲ₜ, r̲ₜ₊₁; α, s_prior, σ_prior)\n\nTuring.jl model to sample out of the posterior for a single population mean fitness value sₜ, given the raw barcode counts. Note: this function allows for the definition of any prior distributions on the mean fitness and the nuisance standard deviation parameter for the log-likelihood function.\n\nModel\n\nFor this inference, we can write Bayes theorem as\n\npi(\n    bars_t sigma_t underlinef_t underlinef_t+1 mid\n    underliner_t underliner_t+1\n) propto\nprod_n=1^N left\n        pi(f_t^(n) mid gamma_t^(n)) \n        pi(gamma_t^(n) mid bars_t sigma_t)\nright\npi(bars_t) pi(sigma_t)\npi(underlinef_t mid underliner_t)\npi(underlinef_t+1 mid underliner_t+1)\n\nwhere\n\ngamma_t^(n) equiv fracf_t+1^(n)f_t^n\n\nThe parametric distributions assumed in this model are of the form\n\nf_t^(n) mid gamma_t^(n) sim \noperatornameUniform left(0 frac1gamma_t^(n) right)\n\ngamma_t^(n) mid bars_t sigma_t sim \nlogmathcalN(bars_t sigma_t)\n\nbars_t sim operatornameUser-defined\n\nsigma_t sim  operatornameUser-defined\n\nunderlinef_t mid underliner_t sim \noperatornameDirichlet(underlinealpha_t + underliner_t)\n\nand\n\nunderlinef_t+1 mid underliner_t+1 sim \noperatornameDirichlet(underlinealpha_t+1 + underliner_t+1)\n\nFor this inference, we enforce all frequencies to be > 0 (even for barcodes with zero reads) to compute gamma_t^(n).\n\nThe user defines the distribution parameters as:\n\nunderlinealpha_t: α.\n\nArguments\n\nr̲ₜ::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nr̲ₜ₊₁::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t + 1. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\n\nKeyword Arguments\n\nα::Vector{Float64}: Parameters for Dirichlet prior distribution.\ns_prior::Distributions.ContinuousUnivariateDistribution: Parametrized univariate continuous distribution for the prior on the mean fitness π(sₜ).\nσ_prior:::Distributions.ContinuousUnivariateDistribution: Parametrized univariate continuous distribution for the prior on the nuisance standard deviation of the log-normal likelihood π(σₜ).\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.mutant_fitness_lognormal-Tuple{Vector{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.mutant_fitness_lognormal","text":"mutant_fitness_lognormal(r̲⁽ᵐ⁾, R̲; α, μ_sₜ, σ_sₜ, s_prior, σ_prior, σ_trunc)\n\nTuring.jl model to sample out of the posterior distribution for a single mutant fitness value s⁽ᵐ⁾, given the raw barcode counts and the parametrization of the population mean fitness distribution.\n\nArguments\n\nr̲⁽ᵐ⁾::Vector{Int64}: Mutant m raw barcode counts time-series. Note: this vector must be the same length as r̲⁽ᶜ⁾. This means that each entry r̲⁽ᵐ⁾[i] contains the number of reads from barcode m at time i.\nR̲::Vector{Int64}: time-series of Raw total reads. This means that entry R̲[i] contains the total number of reads obtained at time i.\n\nKeyword Arguments\n\nα::Vector{Float64}: Parameters for Beta prior distribution.\nμ_sₜ::Vector{Float64}: Array with the time-series mean values of the population mean fitness. This means entry μ_sₜ[i] contains the inferred mean value of the population mean fitness for time i, assuming sₜ[i] ~ Normal(μ_sₜ[i], σ_sₜ[i]).\nσ_sₜ::Vector{Float64}: Array with the time-series values of the population mean fitness standard deviation. This means entry σ_sₜ[i] contains the inferred value of the standard deviation of the population mean fitness at time i, assuming sₜ[i] ~ Normal(μ_sₜ[i], σ_sₜ[i]).\n\nOptional arguments\n\ns_prior::Vector{Real}=[0.0, 2.0]: Parameters for the mutant fitness prior distribution π(s⁽ᵐ⁾).\nσ_prior::Vector{Real}=[0.0, 1.0]: Parameters for the nuisance standard deviation parameter prior distribution π(σ⁽ᵐ⁾).\nσ_trunc::Real=0.0: Value at which truncate the normal distribution to define it as a half-normal.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.mutant_fitness_lognormal_priors-Tuple{Vector{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.mutant_fitness_lognormal_priors","text":"mutant_fitness_lognormal_priors(r̲⁽ᵐ⁾, R̲; α, s_mean_priors, s_prior, σ_prior, σ_trunc)\n\nTuring.jl model to sample out of the posterior distribution for a single mutant fitness value s⁽ᵐ⁾, given the raw barcode counts and the parametrization of the population mean fitness distribution. Note: this function allows for the definition of any prior distributions on the population mean fitness, the nuisance standard deviation parameter for the log-likelihood function, and the mutant mean fitness.\n\nArguments\n\nr̲⁽ᵐ⁾::Vector{Int64}: Mutant m raw barcode counts time-series. Note: this vector must be the same length as r̲⁽ᶜ⁾. This means that each entry r̲⁽ᵐ⁾[i] contains the number of reads from barcode m at time i.\nR̲::Vector{Int64}: time-series of Raw total reads. This means that entry R̲[i] contains the total number of reads obtained at time i.\n\nKeyword Arguments\n\nα::Vector{Float64}: Parameters for Beta prior distribution.\ns_mean_priors::Vector{<:Distributions.ContinuousUnivariateDistribution}: Vector of univariate distributions defining the prior distribution for each population mean fitness value.\ns_prior::Distributions.ContinuousUnivariateDistribution: Parametrized univariate continuous distribution for the prior on the mean fitness π(sₜ).\nσ_prior:::Distributions.ContinuousUnivariateDistribution: Parametrized univariate continuous distribution for the prior on the nuisance standard deviation of the log-normal likelihood π(σₜ).\n\n\n\n\n\n","category":"method"},{"location":"stats/#stats","page":"stats","title":"stats","text":"","category":"section"},{"location":"stats/","page":"stats","title":"stats","text":"Modules = [BayesFitness.stats]\nOrder   = [:function, :type]","category":"page"},{"location":"stats/#BayesFitness.stats.beta_prior_mutant-Tuple{Vector}","page":"stats","title":"BayesFitness.stats.beta_prior_mutant","text":"beta_prior_mutant(neutrals)\n\nFunction to return the vector α̲ for the equivalent of a uniform Dirichlet prior when inferring the relative fitness of a single mutant. Since we use the Beta distribution as the prior when inferring the marginal distribution, this function assigns a 1 to the mutant parameter and a B̲ - 1 to the complement, where B̲ is the total number of unique barcodes.\n\nArguments\n\nbc_id::Vector{Any}: Vector with the IDs for each barcode\n\nReturns\n\nα̲::Vector{Float64}: Parameters for Beta prior. Mutant lineage is assigned α = 1. The rest of the lineages are grouped together into a single term with αᴮ = B̲ - 1, i.e., the number of lineages minus the mutant lineage being inferred.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.dirichlet_prior_neutral-Tuple{Vector{Bool}}","page":"stats","title":"BayesFitness.stats.dirichlet_prior_neutral","text":"dirichlet_prior_neutral(neutrals)\n\nFunction to return the vector α̲ for the equivalent of a uniform Dirichlet prior when inferring the population mean fitness with the neutral lineages. \n\nArguments\n\nneutrals::Vector{Bool}: Vector indicating which barcodes correspond to neutral lineages and wich to mutant lineages.\n\nReturns\n\nα̲::Vector{Float64}: Parameters for uniform Dirichlet prior. All lineages lineages are assigned α = 1. The mutant lineages are grouped together into a single term with αᴹ = ∑ₘ α, i.e., the number of non-neutral lineages.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.freq_mutant_ppc-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"stats","title":"BayesFitness.stats.freq_mutant_ppc","text":"freq_mutant_ppc(n_ppc, df; param, flatten=true)\n\nFunction to compute the posterior predictive checks for the barcode frequency for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables in the mcmc chain defining the following variables:\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\nmutant_freq: Variable defining the inferred initial frequency for the mutant.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.freq_mutant_ppc-Tuple{MCMCChains.Chains, Int64}","page":"stats","title":"BayesFitness.stats.freq_mutant_ppc","text":"freq_mutant_ppc(n_ppc, df; param, flatten=true)\n\nFunction to compute the posterior predictive checks for the barcode frequency for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables in the mcmc chain defining the following variables:\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\nmutant_freq: Variable defining the inferred initial frequency for the mutant.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.gaussian_prior_mean_fitness-Tuple{DataFrames.AbstractDataFrame}","page":"stats","title":"BayesFitness.stats.gaussian_prior_mean_fitness","text":"gaussian_prior_mean_fitness(data)\n\nFunction that fits Gaussian (normal) distributions to MCMC traces from the population mean fitness s̄ₜ. These Gaussians are then used during the mutant relative fitness inference.\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: DataFrame containing the MCMC samples for each of the inferred population mean fitness values, one inferred mean fitness per column.\n\nOptional arguments\n\nparams::Bool=true: Boolean indicating whether the distribution parameters (mean and variance) or the full distribution should be returned\n\nReturns\n\nif params == true:     - µ::Vector{Float64}: Vector encoding the mean values of the Gaussian     distributions.     - σ::Vector{Float64}: Vector encoding the standard deviation values of the     Gaussian distributions. else     - dists::Vector{<:Distributions.ContinuousUnivariateDistribution}: Vector     with the Distributions.jl fit distributions.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.gaussian_prior_mean_fitness-Tuple{MCMCChains.Chains}","page":"stats","title":"BayesFitness.stats.gaussian_prior_mean_fitness","text":"gaussian_prior_mean_fitness(data)\n\nFunction that fits Gaussian (normal) distributions to MCMC traces from the population mean fitness s̄ₜ. These Gaussians are then used during the mutant relative fitness inference.\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: DataFrame containing the MCMC samples for each of the inferred population mean fitness values, one inferred mean fitness per column.\n\nOptional arguments\n\nparams::Bool=true: Boolean indicating whether the distribution parameters (mean and variance) or the full distribution should be returned\n\nReturns\n\nif params == true:     - µ::Vector{Float64}: Vector encoding the mean values of the Gaussian     distributions.     - σ::Vector{Float64}: Vector encoding the standard deviation values of the     Gaussian distributions. else     - dists::Vector{<:Distributions.ContinuousUnivariateDistribution}: Vector     with the Distributions.jl fit distributions.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_mean_ppc-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_mean_ppc","text":"logfreq_ratio_mean_ppc(df, n_ppc, param; flatten=true)\n\nFunction to compute the posterior predictive checks (better called the posterior retrodictive checks) for the barcode log-frequency ratio for neutral lineages. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(n) = f_t^(n) \n    expleft left( - bars_t right) tau right\n\nwhere bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(n)f_t^(n) sim \n    log-mathcalNleft( - bars_t sigma^(n) right)\n\nwhere sigma^(n) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nn_ppc::Int: Number of samples to generate per set of parameters.\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:     - population_mean_fitness: Common pattern in all population mean fitness     variables.     - population_std_fitness: Common pattern in all standard deviations       estimates for the likelihood.\n\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ)= s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_mean_ppc-Tuple{MCMCChains.Chains, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_mean_ppc","text":"logfreq_ratio_mean_ppc(chain, n_ppc; param, flatten=true)\n\nFunction to compute the posterior predictive checks (better called the posterior retrodictive checks) for the barcode log-frequency ratio for neutral lineages. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(n) = f_t^(n) \n    expleft left( - bars_t right) tau right\n\nwhere bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(n)f_t^(n) sim \n    log-mathcalNleft( - bars_t sigma^(n) right)\n\nwhere sigma^(n) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nn_ppc::Int: Number of samples to generate per set of parameters.\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the   variables needed to compute the posterior predictive checks. The dataframe   should have MCMC samples for\npopulation mean fitness values. NOTE: The number of columns containing\npopulation mean fitness values determines the number of datapoints where the   ppc are evaluated.\nlog-normal likelihood standard deviation.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:     - population_mean_fitness: Common pattern in all population mean fitness     variables.     - population_std_fitness: Common pattern in all standard deviations         estimates for the likelihood.\n\nflatten::Bool=true: Boolean indicating whether to flatten the output of   multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_mutant_ppc-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_mutant_ppc","text":"logfreq_ratio_mutant_ppc(df, n_ppc, param; flatten=true)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the\n\nname of the variables in the mcmc chain defining the following variables:\n\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of\n\nmultiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_mutant_ppc-Tuple{MCMCChains.Chains, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_mutant_ppc","text":"logfreq_ratio_mutant_ppc(df, n_ppc; param, flatten=true)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the\n\nname of the variables in the mcmc chain defining the following variables:\n\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of\n\nmultiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.matrix_quantile_range-Union{Tuple{T}, Tuple{Vector{<:AbstractFloat}, Matrix{T}}} where T<:Real","page":"stats","title":"BayesFitness.stats.matrix_quantile_range","text":"matrix_quantile_range(quantile, matrix; dim=2)\n\nFunction to compute the quantile ranges of matrix mat over dimension dim. For example, if quantile[1] = 0.95, This function returns the 0.025 and 0.975 quantiles that capture 95 percent of the entires on the matrix.\n\nArguments\n\nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the posterior predictive checks.\nmatrix::Matrix{<:Real}: Array over which to compute quantile ranges.\n\nOptional arguments\n\ndim::Int=2: Dimension over which to compute quantiles. Defualt = 1, i.e., columns.\n\n\n\n\n\n","category":"method"},{"location":"#BayesFitness","page":"BayesFitness","title":"BayesFitness","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Welcome to the documentation of BayesFitness.jl! The accompanying paper, Bayesian inference of relative fitness on high-throughput pooled competition assays, explains all of the biological and mathematical background needed to understand this package. Here, we only focus on how to use the package, assuming the user already understands the objective of inferring the posterior probability distribution of the relative fitness of mutant strains in a pooled competition assay.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The package is divided into modules. Here's a brief description of the content of each module, but please visit their respective documentations to understand what each module is intended for.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"utils: Series of miscellaneous functions that make the data wrangling and processing much simpler.\nviz: Makie.jl-based module with useful plotting functions to display the data and the MCMC results for visual diagnostics.\nstats: Statistical functions used in the inference problem.\nmodel: Turing.jl-based Bayesian models used to infer the population mean fitness via the neutral lineages as well as the mutants' relative fitness.\nmcmc: The main module with which to perform the Markov-Chain Monte Carlo sampling of the posterior distributions.","category":"page"},{"location":"#Example-inference","page":"BayesFitness","title":"Example inference","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To get you going with the package, let's walk through a basic inference pipeline for one competition assay. Our ultimate goal consists of inferring the relative fitness for each of the mutant barcodes. To that end, we assume that the frequency time-series obeys the following equation","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"f_t+1^(b) = f_t^(b) mathrme^left(s^(b) - bars_t right)tau\ntag1","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"where f_t^(b) is the frequency of barcode b at time t, s^(b) is the relative fitness of this barcode, bars_t is the population mean fitness at time t, and tau is the time interval between time t and t+1.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The first step consists of importing the necessary packages. ","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"note: Note\nWe use import rather than the more common using command. We find it better to keep the project organized, but feel free to use whatever is more convenient for you!","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import Bayesian inference package\nimport BayesFitness\n\n# Import libraries to manipulate data\nimport DataFrames as DF\nimport CSV","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"After having imported the libraries, we need to load our dataset into memory. This dataset is already in the format needed for BayesFitness.jl to work, so we don't have to modify anything.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import data\ndata = CSV.read(\"~/git/BayesFitness/test/data/data_example_01.csv\", DF.DataFrame)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Here you will replace \"~/git/BayesFitness/test/data\" with the directory where your data is stored, and \"data_example_01.csv\" with the name of the file containing the data. The resulting DataFrame looks something like this:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"| BCID_x | barcode                                               | name                    | count | time | neutral | count_sum  |\n|--------|-------------------------------------------------------|-------------------------|-------|------|---------|------------|\n| 0      | TGATCAATCTACAAAAATATTTAATG_GAGTGAAACATGAATGGTATTCATCA | Batch1_1Day-T0_combined | 53    | 0    | FALSE   | 543947     |\n| 1      | CCGCCAATCCCGAACCCCGTTTCGCC_ACTCTAACGTGTAACTAATTTTGAGT | Batch1_1Day-T0_combined | 1213  | 0    | FALSE   | 543947     |\n| 2      | GACAGAAAAGCCAAATGGATTTACCG_ATGGGAACACGGAATGATCTTTTATT | Batch1_1Day-T0_combined | 17    | 0    | FALSE   | 543947     |\n| 3      | CCAACAAAACACAAATCTGTTGTGTA_TACTAAATAAGTAAGGGAATTCTGTT | Batch1_1Day-T0_combined | 19    | 0    | FALSE   | 543947     |\n| 4      | TATCGAAACCCAAAGAGATTTAATCG_ATGACAAACTTTAAATAATTTAATTG | Batch1_1Day-T0_combined | 23    | 0    | FALSE   | 543947     |\n| 5      | TATCGAAACCCAAAGAGATTTAATCG_CGATCAAAGACTAACTTATTTTGTGG | Batch1_1Day-T0_combined | 16    | 0    | FALSE   | 543947     |\n| 6      | TATCGAAACCCAAAGAGATTTAATCG_TTGCCAAGCTGGAAAGCTTTTTATGA | Batch1_1Day-T0_combined | 12    | 0    | FALSE   | 543947     |\n| 7      | ATCACAATAACTAAACTGATTCTTCA_CTCATAACATCAAAAAAAATTCAAAT | Batch1_1Day-T0_combined | 161   | 0    | FALSE   | 543947     |\n| 8      | TATCGAAACCCAAAGAGATTTAATCG_GTTTAAACCATTAATTATATTAGATC | Batch1_1Day-T0_combined | 19    | 0    | FALSE   | 543947     |","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The relevant columns in this data frame are:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"barcode: The unique ID that identifies the barcode.\ncount: The number of reads for this particular barcode.\ntime: The time point ID indicating the order in which samples were taken.\nneutral: Indicator of whether the barcode belongs to a neutral lineage or not.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Let's take a look at the data. The BayesFitness.viz module has several Makie.jl-based functions to easily display the data. Let's import the necessary plotting libraries","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import plotting libraries\nusing CairoMakie\nimport ColorSchemes","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"First, we plot the barcode frequency trajectories. For this, we use the convenient BayesFitness.viz.bc_time_series! function.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"barcode frequency\",\n    yscale=log10,\n    title=\"frequency trajectories\"\n)\n\n# Plot Mutant barcode trajectories with varying colors\nBayesFitness.viz.bc_time_series!(\n    ax,\n    data[.!data.neutral, :];\n    quant_col=:freq,\n    zero_lim=1E-9,\n    zero_label=\"extinct\",\n    alpha=0.25,\n    linewidth=2\n)\n\n# Plot Neutral barcode trajectories with a single dark blue color\nBayesFitness.viz.bc_time_series!(\n    ax,\n    data[data.neutral, :];\n    quant_col=:freq,\n    zero_lim=1E-9,\n    color=ColorSchemes.Blues_9[end],\n    alpha=0.9,\n    linewidth=2\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We highlight the neutral barcodes⸺defined to have relative fitness s^(n)=0⸺with dark blue lines. The rest of the light-color lines correspond to individual barcodes.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can rewrite Eq. (1) as","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"frac1tau ln fracf_t+1^(b)f_t^(b) = \nleft(s^(b) - bars_t right)\ntag2","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"In this form, we can se that the relevant quantity we need to infer the values of the population mean fitness bars_t and the barcode relative fitness s^(b) are not the frequencies themselves, but the log ratio of these frequencies between two adjacent time points. Let's plot this log frequency ratio using the BayesFitness.viz.logfreq_ratio_time_series! function.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"ln(fₜ₊₁/fₜ)\",\n    title=\"log-frequency ratio\"\n)\n\n# Plot log-frequency ratio of mutants with different colors\nBayesFitness.viz.logfreq_ratio_time_series!(\n    ax,\n    data[.!data.neutral, :];\n    freq_col=:freq,\n    alpha=0.25,\n    linewidth=2\n)\n\n# Plot log-frequency ratio of neutrals with a single dark blue color\nBayesFitness.viz.logfreq_ratio_time_series!(\n    ax,\n    data[data.neutral, :];\n    freq_col=:freq,\n    color=ColorSchemes.Blues_9[end],\n    alpha=1.0,\n    linewidth=2\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nWe expect is to see these log-frequency ratios as relatively flat lines. Especially for the neutral lineages.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"#Inferring-the-population-mean-fitness","page":"BayesFitness","title":"Inferring the population mean fitness","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"With the data in hand, our first task is to infer the population mean fitness using the neutral lineages. For this, we use the BayesFitness.mcmc.mcmc_mean_fitness function from the mcmc module. The main parameters we need to define are:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":":data: Tidy data frame containing the raw barcode counts.\n:n_walkers: Number of MCMC chains to run in parallel. NOTE: Having multiple chains run in parallel is convenient for diagnostics. BayesFitness.jl will use the available threads, so make sure you have more than one thread in your julia session if you want to run this inference in a multi-threaded way.\n:outputdir: String pointing to the output directory.\noutputname: String defining the pattern for the output files. This can be something related to the dataset. For example, the growth media, or the date of the experiment, of whatever metadata used to distinguish different datasets.\nmodel: Bayesian model from the model module that defines the posterior distribution to be sampled.\nmodel_kwargs: The parameters required by the model function.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We compile all of these parameters into a dictionary that looks something like this:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define dictionary with necessary parameters for MCMC sampling of the \n# population mean fitness\nparam = Dict(\n    :data => data, \n    :n_walkers => 3, \n    :n_steps => 1_000,\n    :outputdir => \"./output/\",\n    :outputname => \"data_01_meanfitness\",\n    :model => BayesFitness.model.mean_fitness_neutrals_lognormal,\n    :model_kwargs => Dict(\n        :α => BayesFitness.stats.dirichlet_prior_neutral(\n            data[data.time.==0, :neutral],\n        )\n    )\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We are now ready to sample the posterior distribution for the population mean fitness. mcmc makes this extremely easy by using the BayesFitness.mcmc.mcmc_mean_fitness function. All we have to do is run","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Run inference\nBayesFitness.mcmc.mcmc_mean_fitness(; param...)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The output of this function are .jld2 files that save the native data structure with the MCMC samples for each pair of adjacent timepoints. To extract the MCMC samples of the variable we care about⸺equivalent to marginalizing out all the nuisance variables⸺we can use the BayesFitness.utils.jld2_concat_chains from the utils module, indicating the name of the variable we want to extract. What this function does is to search for all .jld2 files in the directory that have a particular pattern in their filename, extracts the MCMC samples for the requested variable (the mean fitness in our case) and compiles them into a data frame, where each column represents the variable extracted from each file.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Concatenate population mean fitness chains into single chain\nchains = BayesFitness.utils.jld2_concat_chains(\n    \"./output/\", \"data_01_meanfitness\", [:sₜ]; id_str=\"\"\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"info: Info\nMake sure to check all of the functions in the BayesFitness.utils module that help you extract the information from the MCMC samples.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To diagnose the inference of these population mean fitness values, it is useful to plot both the MCMC traces for each walker as well as the resulting density plots. To do this, we feed the chains  data structure to the BayesFitness.viz.mcmc_trace_density! function to automatically generate these plots.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(600, 600))\n\n# Generate mcmc_trace_density! plot\nBayesFitness.viz.mcmc_trace_density!(fig, chains; alpha=0.5)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nWhat we want to see from these plots is that the traces all look relatively similar, with no big gaps where the walker got stuck. Furthermore, we want to see that all the densities converged to very similar-looking distributions. That is indeed the case for our dataset. Moreover, the densities look fairly symmetric, so should be able to parametrize the resulting posterior distribution as a Gaussian for our next step in the inference.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Another way of assessing the output of this inference step is to plot the posterior predictive checks against the data. The logic behind the posterior predictive checks is the following: before performing the inference on the parameters we seek to learn form the data, we have a prior belief of what those values can be encoded in our prior distribution. We update this prior belief after observing the experimental data given our likelihood function that captures our model for the data generation process. Thus, the posterior distribution of the parameter values contains our updated belief for what the parameter values can be. Therefore, we can sample out of this parameter posterior distribution and feed such parameters to our likelihood function to generate synthetic data. The expectation is that this simulated data should capture the range of experimental data we observed if the model and the inferred parameters describe the data generation process.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"For this particular case of the population mean fitness, we can use the BayesFitness.stats.logfreq_ratio_mean_ppc from the stats module to compute the posterior predictive checks. What this function does is to generate samples for the log-frequency ratios used to infer the population mean fitness values.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"info: Info\nNote that the BayesFitness.stats.logfreq_ratio_mean_ppc function has methods to work with either MCMCChains.Chains objects or with tidy DataFrames.DataFrame. This allows you to use the data structure you are more comfortable working with.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Name of variables to be extracted from the output MCMC chains on multiple \n# .jld2 files\nchain_vars = [:sₜ, :σₜ]\n\n# Extract variables into single chain object\nchains = BayesFitness.utils.jld2_concat_chains(\n    param[:outputdir], param[:outputname], chain_vars; id_str=\"\"\n)\n\n# Define number of posterior predictive check samples\nn_ppc = 5_000\n\n# Define dictionary with corresponding parameters for variables needed for the\n# posterior predictive checks\nparam = Dict(\n    :population_mean_fitness => :sₜ,\n    :population_std_fitness => :σₜ,\n)\n\n# Compute posterior predictive checks\nppc_mat = BayesFitness.stats.logfreq_ratio_mean_ppc(\n    chains, n_ppc; param=param\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Once we generate these samples, we can plot the quantiles of the simulated data with different shades. The BayesFitness.viz.ppc_time_series! function from the viz module makes this plotting really simple. Let us plot the standard 68-95-97.5 percentiles with different shades of blue and then add the data on top of these shaded areas","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nWhat we expect from this plot is to see that most of the experimental data falls within the range of the simulated data, meaning that the model and the inferred parameters can reproduce the range of our observations.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"ln(fₜ₊₁/fₜ)\",\n    title=\"log-frequency ratio PPC\"\n)\n\n# Define quantiles to compute\nqs = [0.68, 0.95, 0.997]\n\n# Define range of colors for each quantile colors\ncolors = get(ColorSchemes.Blues_9, LinRange(0.25, 0.75, length(qs)))\n\n# Plot posterior predictive check quantiles\nBayesFitness.viz.ppc_time_series!(\n    ax, qs, ppc_mat; colors=colors\n)\n\n# Add plot for median (we use the 5 percentile to have a \"thicker\" line showing\n# the median)\nBayesFitness.viz.ppc_time_series!(\n    ax, [0.05], ppc_mat; colors=ColorSchemes.Blues_9[end:end]\n)\n\n# Plot log-frequency ratio of neutrals\nBayesFitness.viz.logfreq_ratio_time_series!(\n    ax,\n    data[data.neutral, :];\n    freq_col=:freq,\n    color=:black,\n    alpha=1.0,\n    linewidth=2\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"This plot shows that the range of inferred population mean fitnesses does capture the log-frequency ratios of the neutral lineages. Therefore, we can confidently move to the next stage of our inference pipeline.","category":"page"},{"location":"#Inferring-mutants'-relative-fitness","page":"BayesFitness","title":"Inferring mutants' relative fitness","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Once we make sure that the population mean fitness looks okay, we can tackle the inference of each mutant relative fitness. The process is very similar, the main difference being that we use the results from the previous step as part of the inputs that go into the corresponding Bayesian model defined in the model module. More specifically, the inferred population mean fitness enters our inference as a \"prior\" on this value. However, we cannot feed the raw output of the MCMC samples we obtained from the previous step as a prior; this prior distribution has to be parametrized. Since our density plots look fairly symmetric, we assume we can parametrize the population mean fitness values as a Gaussian distribution. Thus, we need to fit a Gaussian distribution for each MCMC chain sampled in the previous section. The BayesFitness.stats.gaussian_prior_mean_fitness function in the stats module can help us with this.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"info: Info\nNote that the BayesFitness.stats.gaussian_prior_mean_fitness function has methods to work with either MCMCChains.Chains objects or with tidy DataFrames.DataFrame. This allows you to use the data structure you are more comfortable working with.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Extract mean fitness MCMC chains\nmean_fitness_chains = BayesFitness.utils.jld2_concat_chains(\n    \"./output/\", \"data_01_meanfitness\", [:sₜ]; id_str=\"\"\n)\n\n# Infer mean fitness distribution parameters by fitting a Gaussian\nmean_fitness_dist = BayesFitness.stats.gaussian_prior_mean_fitness(\n    mean_fitness_chains\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To assess whether assuming a parametrized Gaussian distribution can described the MCMC chains from the previous section, we need to visually compare both distributions. An effective way to do this is to compare the empirical cumulative distribution function (ecdf) built from the MCMC samples with the parametric cumulative distribution function (cdf) we obtain from fitting the Gaussian distributions. The BayesFitness.viz.mcmc_fitdist_cdf! function from does exactly this. Let's plot this comparison for all four inferred population mean fitness values from the previous section","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Infer mean fitness distributions by fitting a Gaussian\nfit_dists = BayesFitness.stats.gaussian_prior_mean_fitness(\n    mean_fitness_chains,\n    params=false\n)\n\n# Initialize figure\nfig = Figure(resolution=(600, 600))\n\n# Add axis objects for each timepoint\naxes = [\n    Axis(\n        fig[i, j],\n        xlabel=\"population mean fitness (s̄ₜ)\",\n        ylabel=\"ecdf\",\n    ) for i = 1:2 for j = 1:2\n]\n\n# Loop through time points\nfor (i, var) in enumerate(names(mean_fitness_chains))\n    # Plot ECDF\n    BayesFitness.viz.mcmc_fitdist_cdf!(\n        axes[i],\n        Array(mean_fitness_chains[var])[:],\n        fit_dists[i]\n    )\n\n    axes[i].title = \"timepoint $(i)\"\nend # for","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nIf the population mean fitness can be parametrized as a Gaussian distribution, there should be minimal differences between the mcmc chain and the fit distribution as shown in the figure above.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can now define the dictionary containing the parameters that go into the [BayesFitness.mcmc.mcmc_mutant_fitness] function from the mcmc module. ","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nThe BayesFitness.mcmc.mcmc_mutant_fitness function has two multi-threading modalities: multithread_chain and multithread_mutant. Only one of them can be active at any moment. The multithread_chain  samples multiple chains for a single mutant at the time in a multithread fashion. The multithread_mutant samples multiple mutants at the time, with one chain per thread.On the one hand, if you only have ≈ 4 threads available in your computer, you might want to use multithread_chain to sample 3-4 chains per mutant in parallel. On the other hand, if you have > 4 threads available, running  multithread_mutant can significantly speedup your computation; especially if you have ≥ 8 threads available.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define function parameters\nparam = Dict(\n    :data => data,\n    :n_walkers => 3,\n    :n_steps => 1_000,\n    :outputdir => \"./output/\",\n    :outputname => \"data_01_mutantfitness\",\n    :model => BayesFitness.model.mutant_fitness_lognormal,\n    :model_kwargs => Dict(\n        :α => BayesFitness.stats.beta_prior_mutant(\n            data[data.time.==0, :barcode],\n        ),\n        :μ_s̄ => mean_fitness_dist[1],\n        :σ_s̄ => mean_fitness_dist[2],\n    ),\n    :multithread_mutant => true,\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Finally, we run the inference.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Run inference in a multithread fashion\nBayesFitness.mcmc.mcmc_mutant_fitness(; param...)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"This function generates .jld2 files with the MCMC chains for each of the mutant barcodes. Let's look at an example inference. We will specifically load the inference for the barcode that reached the highest count throughout the experiment. For this, we use the Glob.jl library to locate the corresponding .jld2 file. .jld2 files store multiple Julia objects as dictionary. In our case, a single object named \"chain\" was saved on this file, so when loading the file, we index this single object.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Find barcode with maximum count\nbc = data[first(argmax(data.count, dims=1)), :barcode]\n\n# Select file to process\nfile = first(\n    Glob.glob(\"$(param[:outputdir])/$(param[:outputname])*$(bc).jld2\")\n)\n\n# Load one of the files as an example\nchain = JLD2.load(file)[\"chain\"]","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"As a first diagnostic, let's look at the trace and density plots for the mutant fitness and the likelihood standard deviation.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Name variables to be extracted from chains\nchain_vars = [Symbol(\"s⁽ᵐ⁾\"), Symbol(\"σ⁽ᵐ⁾\")]\n\n# Extract variables from chain\nchn = chain[chain_vars]\n\n# Initialize figure\nfig = Figure(resolution=(600, 350))\n\n# Generate mcmc_trace_density! plot\nBayesFitness.viz.mcmc_trace_density!(fig, chn; alpha=0.5)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can see that the mutant fitness is centered around 1.5. But the Bayesian analysis gives us a principled way to estimate the uncertainty on this estimate.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To make sure the inferred fitness value agrees with the experimental data, we must generate posterior predictive (retrodictive) checks. For this we need to extract the necessary information from the mcmc_chain object. In particular, we are interested in the mcmc traces for the mutant fitness (named :s⁽ᵐ⁾ in the chain), all of the population mean fitness traces (named :s̲ₜ[i] in the chain, where i indexes the time point), the standard deviation for the mutant fitness (named :σ⁽ᵐ⁾ in the chain), and the initial barcode frequency (named :f̲⁽ᵐ⁾[1] in the chain).","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Name variables to be extracted from chains\nchain_vars = [Symbol(\"s⁽ᵐ⁾\"), Symbol(\"σ⁽ᵐ⁾\"), Symbol(\"f̲⁽ᵐ⁾[1]\"), :s̲ₜ]\n\n# Locate variable names to extract from chain and append them into a single \n# vector\nchain_names = reduce(\n    vcat, [MCMCChains.namesingroup(chain, var) for var in chain_vars]\n)\n\n# Extract chain variables\nchn = chain[chain_names]","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We also need to extract the actual measurements for the specific barcode we are looking as an example. This can easily be extracted from our tidy data frame.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Extract data for barcode example\ndata_bc = data[data.barcode.==bc, :]\n\n# Sort data by time\nDF.sort!(data_bc, :time)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"With these variables in hand, we can generate some posterior predictive checks for the barcode frequency trajectories. To generate these samples we use the BayesFitness.stats.freq_mutant_ppc function that takes a chain (or a tidy dataframe) as an input with MCMC chains for the following variables:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The mutant mean fitness s^(m).\nThe standard deviation from the mutant fitness inference likelihood function sigma^(m).\nThe initial frequency for the mutant f^(m)_0.\nThe corresponding population mean fitness values for each time point where the data was taken underlinebars_t.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define number of posterior predictive check samples\nn_ppc = 5_000\n\n# Define dictionary with corresponding parameters for variables needed for the\n# posterior predictive checks\nparam = Dict(\n    :mutant_mean_fitness => :s⁽ᵐ⁾,\n    :mutant_std_fitness => :σ⁽ᵐ⁾,\n    :mutant_freq => Symbol(\"f̲⁽ᵐ⁾[1]\"),\n    :population_mean_fitness => :s̲ₜ,\n)\n\n# Compute posterior predictive checks\nppc_mat = BayesFitness.stats.freq_mutant_ppc(\n    chn,\n    n_ppc;\n    param=param\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Next, we can use the BayesFitness.viz.ppc_time_series! function to plot these posterior predictive checks to compare it with the frequency trajectory measured experimentally.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"barcode frequency\",\n    title=\"frequency trajectories\",\n    yscale=log10,\n)\n\n# Define quantiles to compute\nqs = [0.95, 0.675]\n\n# Define colors\ncolors = get(ColorSchemes.Blues_9, LinRange(0.5, 0.75, length(qs)))\n\n# Plot posterior predictive checks\nBayesFitness.viz.ppc_time_series!(\n    ax, qs, ppc_mat; colors=colors\n)\n\n# Add plot for median\nBayesFitness.viz.ppc_time_series!(\n    ax, [0.03], ppc_mat; colors=ColorSchemes.Blues_9[end:end]\n)\n\n# Add scatter of data\nscatterlines!(ax, data_bc.freq, color=:black)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nIn the previous plot, the credible region expands as time progresses in the experiment. This is to be expected as the uncertainty is propagated over time with new sources of uncertainty added at each time point. But notice that the experimental frequency trajectory falls within the highest probability region.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Another way to visualize the agreement between our inferred parameters and the data is to look at the quantity used directly on the inference of the fitness value, i.e., the log frequency ratio between two adjacent time points. For this we can use the BayesFitness.stats.logfreq_ratio_mutant_ppc function to compute the posterior predictive checks. The difference between this function and the previously used BayesFitness.stats.freq_mutant_ppc is that the log frequency ratio function does not require the inferred initial frequency of the mutant as an input since we are only looking at the log log frequency ratio.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Name variables to be extracted from chains\nchain_vars = [Symbol(\"s⁽ᵐ⁾\"), Symbol(\"σ⁽ᵐ⁾\"), :s̲ₜ]\n\n# Locate variable names to extract from chain\nchain_names = reduce(\n    vcat, [MCMCChains.namesingroup(chain, var) for var in chain_vars]\n)\n\n# Extract chain variables\nchn = chain[chain_names]\n\n# Define number of posterior predictive check samples\nn_ppc = 5_000\n\n# Define dictionary with corresponding parameters for variables needed for the\n# posterior predictive checks\nparam = Dict(\n    :mutant_mean_fitness => :s⁽ᵐ⁾,\n    :mutant_std_fitness => :σ⁽ᵐ⁾,\n    :population_mean_fitness => :s̲ₜ,\n)\n\n# Compute posterior predictive checks\nppc_mat = BayesFitness.stats.logfreq_ratio_mutant_ppc(\n    chn, n_ppc; param=param\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Again, we can use the BayesFitness.viz.ppc_time_series! function to plot the quantiles for our posterior predictive checks.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"ln(fₜ₊₁/fₜ)\",\n    title=\"log-frequency ratio PPC\"\n)\n\n# Define quantiles to compute\nqs = [0.95, 0.675]\n\n# Define colors\ncolors = get(ColorSchemes.Blues_9, LinRange(0.5, 0.75, length(qs)))\n\n# Plot posterior predictive checks\nBayesFitness.viz.ppc_time_series!(\n    ax, qs, ppc_mat; colors=colors\n)\n\n# Add plot for median (we use the 5 percentile to have a \"thicker\" line showing\n# the median)\nBayesFitness.viz.ppc_time_series!(\n    ax, [0.05], ppc_mat; colors=ColorSchemes.Blues_9[end:end]\n)\n\n# Add scatter of data\nscatterlines!(ax, diff(log.(data_bc.freq)), color=:black)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can see that indeed the recovered fitness value greatly agrees with the data.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"This concludes the example inference pipeline. We invited you to explore more the potential in the package and please send any comments/requests through the GitHub repository issues.","category":"page"},{"location":"#Contents","page":"BayesFitness","title":"Contents","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"","category":"page"},{"location":"utils/#utils","page":"utils","title":"utils","text":"","category":"section"},{"location":"utils/","page":"utils","title":"utils","text":"Modules = [BayesFitness.utils]\nOrder   = [:function, :type]","category":"page"},{"location":"utils/#BayesFitness.utils.concat_chains-Tuple{Vector{<:MCMCChains.Chains}, Vector{Symbol}}","page":"utils","title":"BayesFitness.utils.concat_chains","text":"`concat_chains(chains, var_pattern, id_str)`\n\nFunction that concatenates multiple MCMCChains.Chains objects into a single one. This function takes a vector of MCMCChains.Chains as inputs, extracts the variables that match the patterns in the array var_pattern, and appends all extracted variables into a single chain adding a pattern of the form [$(id_str)i], where i is the file number. For example, if two chains contain a variable named var, the new chain returned by this function names them as var[f1] and var[f2] if id_str=f.\n\nNOTE: All chains must have the same number of samples to be concatenated.\n\nArguments\n\nchains::Vector{<:MCMCChains.Chains}: Vector with the chains to be concatenated into a single chain.\nvar_pattern::Vector{Symbol}: Patterns that variables must follow to be extracted from the chain. For example, if several variables are named var[1], var[2], etc, providing a pattern [var] extracts all of them, while providing var[1] extracts only the one that perfectly matches this pattern.\n\nOptional arguments\n\nid_str::String=f: String to be attached to the variable names that identifies the different chains being concatenated. For example, if 4 chains are being concatenated, each repeated variable will be named var[$(id_str)i] to distinguish each of them.\n\nReturns\n\nMCMCChains.Chains: Chain with the requested variables from multiple files concatenated into a single object.\n\n\n\n\n\n","category":"method"},{"location":"utils/#BayesFitness.utils.jld2_concat_chains-Tuple{String, String, Vector{Symbol}}","page":"utils","title":"BayesFitness.utils.jld2_concat_chains","text":"`jld2_concat_chains(dir, file_patern, chains, var_pattern, id_str)`\n\nConvenient function that peforms the same concatenation as BayesFitness.utils.concat_chains but giving a directory and a file pattern for jld2 files storing the chains. This function reads all files in dir that have the pattern file pattern, obtaining a list of MCMCChains.Chains as inputs. It then extracts the variables that match the patterns in the array var_pattern, and appends all extracted variables into a single chain adding a pattern of the form [$(id_str)i], where i is the file number. For example, if two chains contain a variable named var, the new chain returned by this function names them as var[f1] and var[f2] if id_str=f.\n\nNOTE: All chains must have the same number of samples to be concatenated.\n\nArguments\n\ndir::String: Directory where file(s) with MCMC chains are stored.\nfile_pattern::String: Pattern common among all files to process. NOTE: This is use in the Glob.glob command to locate all jld2 files from which to extract the chains.\nvar_pattern::Vector{Symbol}: Patterns that variables must follow to be extracted from the chain. For example, if several variables are named var[1], var[2], etc, providing a pattern [var] extracts all of them, while providing var[1] extracts only the one that perfectly matches this pattern.\n\nOptional arguments\n\nid_str::String=f: String to be attached to the variable names that identifies the different chains being concatenated. For example, if 4 chains are being concatenated, each repeated variable will be named var[$(id_str)i] to distinguish each of them.\n\nReturns\n\nMCMCChains.Chains: Chain with the requested variables from multiple files concatenated into a single object.\nchainname::String=\"chain\": String defining the dictionary key on the .jld2\n\nfile to extract the MCMC chain.\n\n\n\n\n\n","category":"method"}]
}
