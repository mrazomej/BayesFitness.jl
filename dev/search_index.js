var documenterSearchIndex = {"docs":
[{"location":"mcmc/#mcmc","page":"mcmc","title":"mcmc","text":"","category":"section"},{"location":"mcmc/","page":"mcmc","title":"mcmc","text":"Modules = [BayesFitness.mcmc]\nOrder   = [:function, :type]","category":"page"},{"location":"mcmc/#BayesFitness.mcmc.mcmc_mean_fitness-Tuple{}","page":"mcmc","title":"BayesFitness.mcmc.mcmc_mean_fitness","text":"mcmc_mean_fitness(; kwargs)\n\nFunction to sample the posterior distribution of the population mean fitness for a series of pairs of time points. This function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage or not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be used to sample from the population mean fitness posterior distribution.\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputdir::String: Directory where the output .jld2 files containing the MCMC chains should be stored.\noutputname::String: Common pattern for all .jld2 output files. The output files of this function will be named as\n\n$(outputdir)/$(outputname)_$(t)-$(t+1)_meanfitness_mcmcchains.jld\n\nwhere t and t+1 indicate the time points used during the inference.\n\nmodel::Function: Turing.jl model defining the posterior distribution from which to sample (see BayesFitness.model module). This function must take as the first two inputs the following:\nr̲ₜ::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nr̲ₜ₊₁::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t + 1. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages. \n\nOptional Arguments\n\nmodele_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifyer. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\nsuppress_output::Bool=false: Boolean indicating if the screen output of Turing.jl must be actively suppressed.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler to be used.\nverbose::Bool=true: Boolean indicating if the function should print partial progress to the screen or not.\n\n\n\n\n\n","category":"method"},{"location":"mcmc/#BayesFitness.mcmc.mcmc_mutant_fitness-Tuple{}","page":"mcmc","title":"BayesFitness.mcmc.mcmc_mutant_fitness","text":"mcmc_mutant_fitness(; kwargs)\n\nFunction to sample the posterior distribution of mutant lineages relative fitness given a time-series barcode count. \n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage or not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be used to sample from the population mean fitness posterior distribution.\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputdir::String: Directory where the output .jld2 files containing the MCMC chains should be stored.\noutputname::String: Common pattern for all .jld2 output files. The output files of this function will be named as\n\n$(outputdir)/$(outputname)_$(mutant_id)_mcmcchains.jld\n\nwhere t and t+1 indicate the time points used during the inference.\n\nmodel::Function: Turing.jl model defining the posterior distribution from which to sample (see BayesFitness.model module). This function must take as the first two inputs the following:\nr̲ₜ::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nr̲ₜ₊₁::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t + 1. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages. \n\nOptional Arguments\n\nmodele_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifyer. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\nsuppress_output::Bool=false: Boolean indicating if the screen output of Turing.jl must be actively suppressed.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler to be used.\nverbose::Bool=true: Boolean indicating if the function should print partial progress to the screen or not.\n\n\n\n\n\n","category":"method"},{"location":"mcmc/#BayesFitness.mcmc.mcmc_mutant_fitness_multithread-Tuple{}","page":"mcmc","title":"BayesFitness.mcmc.mcmc_mutant_fitness_multithread","text":"mcmc_mutant_fitness_multithread(; kwargs)\n\nFunction to sample the posterior distribution of mutant lineages relative fitness given a time-series barcode count. This function runs the inference of multiple mutants in a multithread fasion. Because of this, every mutant gets only one MCMC chain.\n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage or not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be used to sample from the population mean fitness posterior distribution.\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputdir::String: Directory where the output .jld2 files containing the MCMC chains should be stored.\noutputname::String: Common pattern for all .jld2 output files. The output files of this function will be named as\n\n$(outputdir)/$(outputname)_$(mutant_id)_mcmcchains.jld\n\nwhere t and t+1 indicate the time points used during the inference.\n\nmodel::Function: Turing.jl model defining the posterior distribution from which to sample (see BayesFitness.model module). This function must take as the first two inputs the following:\nr̲ₜ::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nr̲ₜ₊₁::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t + 1. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages. \n\nOptional Arguments\n\nmodele_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifyer. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\nsuppress_output::Bool=false: Boolean indicating if the screen output of Turing.jl must be actively suppressed.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler to be used.\nverbose::Bool=true: Boolean indicating if the function should print partial progress to the screen or not.\n\n\n\n\n\n","category":"method"},{"location":"viz/#viz","page":"viz","title":"viz","text":"","category":"section"},{"location":"viz/","page":"viz","title":"viz","text":"Modules = [BayesFitness.viz]\nOrder   = [:function, :type]","category":"page"},{"location":"viz/#BayesFitness.viz.freq_mutant_ppc!-Tuple{Makie.Axis, Vector{<:AbstractFloat}, DataFrames.AbstractDataFrame, Union{AbstractString, Symbol}, Union{AbstractString, Symbol}, Union{AbstractString, Symbol}}","page":"viz","title":"BayesFitness.viz.freq_mutant_ppc!","text":"freq_mutant_ppc!(fig, quantile, df, varname_mut, varname_mean, varname_freq; colors, alpha)\n\nFunction to plot the posterior predictive checks quantiles for the barcode frequency for adaptive mutants.\n\nArguments\n\nfig::Makie.Axis: Axis object to be populated with plot. \nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the   posterior predictive checks.\nchain::MCMCChains.Chains: Turing.jl MCMC chain for the fitness of a single   mutant.\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the\n\nvariables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for     - mutant relative fitness values.     - population mean fitness values. NOTE: The number of columns containing       population mean fitness values determines the number of datapoints where the       ppc are evaluated.     - mutant initial frequency.\n\nvarname_mut::Union{Symbol, AbstractString}: Variable name for the mutant   relative fitness in the data frame.\nvarname_mean::Union{Symbol, AbstractString}: Variable name pattern for all population mean fitness. All columns in the dataframe should contain this pattern and the sorting of these names must correspond to the sorting of the time points.\nvarname_freq::Union{Symbol, AbstractString}: Variable name for initial mutant barcode frequencies.\n\nOptional arguments\n\ncolors=ColorSchemes.Blues_9: List of colors to use for each quantile.\nalpha::AbstractFloat=0.75: Level of transparency for band representing each quantile.\n\n\n\n\n\n","category":"method"},{"location":"viz/#BayesFitness.viz.freq_mutant_ppc!-Tuple{Makie.Axis, Vector{<:AbstractFloat}, MCMCChains.Chains}","page":"viz","title":"BayesFitness.viz.freq_mutant_ppc!","text":"freq_mutant_ppc!(fig, quantile, chain; colors, alpha, varname_mut, varname_mean, freq_mut)\n\nFunction to plot the posterior predictive checks quantiles for the barcode frequency for adaptive mutants.\n\nArguments\n\nfig::Makie.Axis: Axis object to be populated with plot. \nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the   posterior predictive checks.\nchain::MCMCChains.Chains: Turing.jl MCMC chain for the fitness of a single   mutant.\n\nOptional arguments\n\ncolors=ColorSchemes.Blues_9: List of colors to use for each quantile.\nalpha::AbstractFloat=0.75: Level of transparency for band representing each quantile.\nvarname_mut::Symbol=Symbol(\"s⁽ᵐ⁾\"): Variable name for the mutant relative   fitness in the chain object.\nvarname_mean::Symbol=Symbol(\"s̲ₜ\"): Variable name for all population mean   fitness.\nfreq_mut::Symbol=Symbol(\"f̲⁽ᵐ⁾\"): Variable name for all mutant barcode   frequencies.\n\n\n\n\n\n","category":"method"},{"location":"viz/#BayesFitness.viz.logfreqratio_neutral_ppc!-Tuple{Makie.Axis, Vector{<:AbstractFloat}, DataFrames.AbstractDataFrame}","page":"viz","title":"BayesFitness.viz.logfreqratio_neutral_ppc!","text":"logfreqratio_neutral_ppc!(fig, quantile, df; colors, alpha,)\n\nFunction to plot the posterior predictive checks quantiles for the log frequency ratio for neutral lineages\n\nArguments\n\nfig::Makie.Axis: Axis object to be populated with plot. \nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the   posterior predictive checks.\n\n-df::DataFrames.DataFrame: DataFrame containing all population mean fitness samples⸺multiple chains must be collapsed into a single column⸺one time point per column. Note: we recommend using the var_jld2_to_df from the utils module to build this dataframe.\n\nOptional arguments\n\ncolors=ColorSchemes.Blues_9: List of colors to use for each quantile.\nalpha::AbstractFloat=0.75: Level of transparency for band representing each quantile.\n\n\n\n\n\n","category":"method"},{"location":"viz/#BayesFitness.viz.mcmc_trace_density!-Tuple{Makie.Figure, MCMCChains.Chains}","page":"viz","title":"BayesFitness.viz.mcmc_trace_density!","text":"mcmc_trace_density!(fig::Figure, chain::MCMCChains.Chains; colors, labels)\n\nFunction to plot the traces and density estimates side-to-side for each of the parametres in the MCMCChains.Chains object.\n\nArguments\n\nfig::Makie.Figure: Figure object to be populated with plot. This allows the user to decide the size of the figure outside of this function.\nchain::MCMCChains.Chains: Samples from the MCMC run generated with Turing.jl.\n\nOptional arguments\n\ncolors=ColorSchemes.seaborn_colorblind: List of colors to be used in plot.\nlabels: List of labels for each of the parameters. If not given, the default will be to use the names stored in the MCMCChains.Chains object.\nalpha::AbstractFloat=1: Level of transparency for plots.\n\n\n\n\n\n","category":"method"},{"location":"model/#model","page":"model","title":"model","text":"","category":"section"},{"location":"model/","page":"model","title":"model","text":"Modules = [BayesFitness.model]\nOrder   = [:function, :type]","category":"page"},{"location":"model/#BayesFitness.model.mean_fitness_neutrals_lognormal-Tuple{Vector{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.mean_fitness_neutrals_lognormal","text":"mean_fitness_neutrals_lognormal(r̲ₜ, r̲ₜ₊₁; α, s_prior, σ_prior, σ_trunc)\n\nTuring.jl model to sample the posterior for a single population mean fitness value sₜ, given the raw barcode counts. \n\nModel\n\nFor this inference, we can write Bayes theorem as\n\npi(\n    bars_t sigma_t underlinef_t underlinef_t+1 mid\n    underliner_t underliner_t+1\n) propto\nprod_n=1^N left\n        pi(f_t^(n) mid gamma_t^(n)) \n        pi(gamma_t^(n) mid bars_t sigma_t)\nright\npi(bars_t) pi(sigma_t)\npi(underlinef_t mid underliner_t)\npi(underlinef_t+1 mid underliner_t+1)\n\nwhere\n\ngamma_t^(n) equiv fracf_t+1^(n)f_t^n\n\nThe parametric distributions assumed in this model are of the form\n\nf_t^(n) mid gamma_t^(n) sim \noperatornameUniform left(0 frac1gamma_t^(n) right)\n\ngamma_t^(n) mid bars_t sigma_t sim \nlogmathcalN(bars_t sigma_t)\n\nbars_t sim mathcalN(mu_bars_t sigma_bars_t)\n\nsigma_t sim \noperatornameHalf-mathcalN(mu_sigma_t sigma_sigma_t)\n\nunderlinef_t mid underliner_t sim \noperatornameDirichlet(underlinealpha_t + underliner_t)\n\nand\n\nunderlinef_t+1 mid underliner_t+1 sim \noperatornameDirichlet(underlinealpha_t+1 + underliner_t+1)\n\nFor this inference, we enforce all frequencies to be > 0 (even for barcodes with zero reads) to compute gamma_t^(n).\n\nThe user defines the distribution parameters as:\n\nunderlinealpha_t: α.\nmu_bars_t sigma_bars_t: s_prior.\nmu_sigma_t sigma_sigma_t: σ_prior.\n\nArguments\n\nr̲ₜ::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nr̲ₜ₊₁::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t + 1. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nα::Vector{Float64}: Parameters for Dirichlet prior distribution.\n\nOptional arguments\n\ns_prior::Vector{Real}=[0.0, 2.0]: Parameters for the mean fitness prior distribution π(sₜ).\nσ_prior::Vector{Real}=[0.0, 1.0]: Parameters for the nuisance standard deviation parameter prior distribution π(σₜ).\nσ_trunc::Real=0.0: Value at which truncate the normal distribution to define it as a half-normal.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.mean_fitness_neutrals_lognormal_priors-Tuple{Vector{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.mean_fitness_neutrals_lognormal_priors","text":"mean_fitness_neutrals_lognormal_priors(r̲ₜ, r̲ₜ₊₁; α, s_prior, σ_prior)\n\nTuring.jl model to sample out of the posterior for a single population mean fitness value sₜ, given the raw barcode counts. Note: this function allows for the definition of any prior distributions on the mean fitness and the nuisance standard deviation parameter for the log-likelihood function.\n\nModel\n\nFor this inference, we can write Bayes theorem as\n\npi(\n    bars_t sigma_t underlinef_t underlinef_t+1 mid\n    underliner_t underliner_t+1\n) propto\nprod_n=1^N left\n        pi(f_t^(n) mid gamma_t^(n)) \n        pi(gamma_t^(n) mid bars_t sigma_t)\nright\npi(bars_t) pi(sigma_t)\npi(underlinef_t mid underliner_t)\npi(underlinef_t+1 mid underliner_t+1)\n\nwhere\n\ngamma_t^(n) equiv fracf_t+1^(n)f_t^n\n\nThe parametric distributions assumed in this model are of the form\n\nf_t^(n) mid gamma_t^(n) sim \noperatornameUniform left(0 frac1gamma_t^(n) right)\n\ngamma_t^(n) mid bars_t sigma_t sim \nlogmathcalN(bars_t sigma_t)\n\nbars_t sim operatornameUser-defined\n\nsigma_t sim  operatornameUser-defined\n\nunderlinef_t mid underliner_t sim \noperatornameDirichlet(underlinealpha_t + underliner_t)\n\nand\n\nunderlinef_t+1 mid underliner_t+1 sim \noperatornameDirichlet(underlinealpha_t+1 + underliner_t+1)\n\nFor this inference, we enforce all frequencies to be > 0 (even for barcodes with zero reads) to compute gamma_t^(n).\n\nThe user defines the distribution parameters as:\n\nunderlinealpha_t: α.\n\nArguments\n\nr̲ₜ::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nr̲ₜ₊₁::Vector{Int64}: Raw counts for neutral lineages and the cumulative counts for mutant lineages at time t + 1. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.\nα::Vector{Float64}: Parameters for Dirichlet prior distribution.\ns_prior::Distributions.ContinuousUnivariateDistribution: Parametrized univariate continuous distribution for the prior on the mean fitness π(sₜ).\nσ_prior:::Distributions.ContinuousUnivariateDistribution: Parametrized univariate continuous distribution for the prior on the nuisance standard deviation of the log-normal likelihood π(σₜ).\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.mutant_fitness_lognormal-Tuple{Vector{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.mutant_fitness_lognormal","text":"mutant_fitness_lognormal(r̲⁽ᵐ⁾, R̲; α, μ_sₜ, σ_sₜ, s_prior, σ_prior, σ_trunc)\n\nTuring.jl model to sample out of the posterior distribution for a single mutant fitness value s⁽ᵐ⁾, given the raw barcode counts and the parametrization of the population mean fitness distribution.\n\nArguments\n\nr̲⁽ᵐ⁾::Vector{Int64}: Mutant m raw barcode counts time-series. Note: this vector must be the same length as r̲⁽ᶜ⁾. This means that each entry r̲⁽ᵐ⁾[i] contains the number of reads from barcode m at time i.\nR̲::Vector{Int64}: time-series of Raw total reads. This means that entry R̲[i] contains the total number of reads obtained at time i.\nα::Vector{Float64}: Parameters for Beta prior distribution.\nμ_sₜ::Vector{Float64}: Array with the time-series mean values of the population mean fitness. This means entry μ_sₜ[i] contains the inferred mean value of the population mean fitness for time i, assuming sₜ[i] ~ Normal(μ_sₜ[i], σ_sₜ[i]).\nσ_sₜ::Vector{Float64}: Array with the time-series values of the population mean fitness standard deviation. This means entry σ_sₜ[i] contains the inferred value of the standard deviation of the population mean fitness at time i, assuming sₜ[i] ~ Normal(μ_sₜ[i], σ_sₜ[i]).\n\nOptional arguments\n\ns_prior::Vector{Real}=[0.0, 2.0]: Parameters for the mutant fitness prior distribution π(s⁽ᵐ⁾).\nσ_prior::Vector{Real}=[0.0, 1.0]: Parameters for the nuisance standard deviation parameter prior distribution π(σ⁽ᵐ⁾).\nσ_trunc::Real=0.0: Value at which truncate the normal distribution to define it as a half-normal.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.mutant_fitness_lognormal_priors-Tuple{Vector{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.mutant_fitness_lognormal_priors","text":"mutant_fitness_lognormal_priors(r̲⁽ᵐ⁾, R̲; α, s_mean_priors, s_prior, σ_prior, σ_trunc)\n\nTuring.jl model to sample out of the posterior distribution for a single mutant fitness value s⁽ᵐ⁾, given the raw barcode counts and the parametrization of the population mean fitness distribution. Note: this function allows for the definition of any prior distributions on the population mean fitness, the nuisance standard deviation parameter for the log-likelihood function, and the mutant mean fitness.\n\nArguments\n\nr̲⁽ᵐ⁾::Vector{Int64}: Mutant m raw barcode counts time-series. Note: this vector must be the same length as r̲⁽ᶜ⁾. This means that each entry r̲⁽ᵐ⁾[i] contains the number of reads from barcode m at time i.\nR̲::Vector{Int64}: time-series of Raw total reads. This means that entry R̲[i] contains the total number of reads obtained at time i.\nα::Vector{Float64}: Parameters for Beta prior distribution.\ns_mean_priors::Vector{<:Distributions.ContinuousUnivariateDistribution}: Vector of univariate distributions defining the prior distribution for each population mean fitness value.\ns_prior::Distributions.ContinuousUnivariateDistribution: Parametrized univariate continuous distribution for the prior on the mean fitness π(sₜ).\nσ_prior:::Distributions.ContinuousUnivariateDistribution: Parametrized univariate continuous distribution for the prior on the nuisance standard deviation of the log-normal likelihood π(σₜ).\n\n\n\n\n\n","category":"method"},{"location":"stats/#stats","page":"stats","title":"stats","text":"","category":"section"},{"location":"stats/","page":"stats","title":"stats","text":"Modules = [BayesFitness.stats]\nOrder   = [:function, :type]","category":"page"},{"location":"stats/#BayesFitness.stats.beta_prior_mutant-Tuple{Vector}","page":"stats","title":"BayesFitness.stats.beta_prior_mutant","text":"beta_prior_mutant(neutrals)\n\nFunction to return the vector α̲ for the equivalent of a uniform Dirichlet prior when inferring the relative fitness of a single mutant. Since we use the Beta distribution as the prior when inferring the marginal distribution, this function assigns a 1 to the mutant parameter and a B̲ - 1 to the complement, where B̲ is the total number of unique barcodes.\n\nArguments\n\nbc_id::Vector{Any}: Vector with the IDs for each barcode\n\nReturns\n\nα̲::Vector{Float64}: Parameters for Beta prior. Mutant lineage is assigned α = 1. The rest of the lineages are grouped together into a single term with αᴮ = B̲ - 1, i.e., the number of lineages minus the mutant lineage being inferred.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.dirichlet_prior_neutral-Tuple{Vector{Bool}}","page":"stats","title":"BayesFitness.stats.dirichlet_prior_neutral","text":"dirichlet_prior_neutral(neutrals)\n\nFunction to return the vector α̲ for the equivalent of a uniform Dirichlet prior when inferring the population mean fitness with the neutral lineages. \n\nArguments\n\nneutrals::Vector{Bool}: Vector indicating which barcodes correspond to neutral lineages and wich to mutant lineages.\n\nReturns\n\nα̲::Vector{Float64}: Parameters for uniform Dirichlet prior. All lineages lineages are assigned α = 1. The mutant lineages are grouped together into a single term with αᴹ = ∑ₘ α, i.e., the number of non-neutral lineages.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.freq_mutant_ppc-Tuple{DataFrames.AbstractDataFrame, Union{AbstractString, Symbol}, Union{AbstractString, Symbol}, Union{AbstractString, Symbol}}","page":"stats","title":"BayesFitness.stats.freq_mutant_ppc","text":"freq_mutant_ppc(df, varname_mut, varname_mean, varname_freq)\n\nFunction to compute the posterior predictive checks for the barcode frequency for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. This funciton computes the frequency for each of the MCMC samples in the chain object.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nmutant initial frequency.\nvarname_mut::Union{Symbol, AbstractString}: Variable name for the mutant   relative fitness in the data frame.\nvarname_mean::Union{Symbol, AbstractString}: Variable name pattern for all population mean fitness. All columns in the dataframe should contain this pattern and the sorting of these names must correspond to the sorting of the time points.\nvarname_freq::Union{Symbol, AbstractString}: Variable name for initial mutant barcode frequencies.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample. The dimensions of the output are (nsamples × ntime × n_chains)\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.freq_mutant_ppc-Tuple{MCMCChains.Chains}","page":"stats","title":"BayesFitness.stats.freq_mutant_ppc","text":"freq_mutant_ppc(chain, varname_mut, varname_mean)\n\nFunction to compute the posterior predictive checks for the barcode frequency for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. This funciton computes the frequency for each of the MCMC samples in the chain object.\n\nArguments\n\nchain::MCMCChains.Chains: Turing.jl MCMC chain for the fitness of a single mutant.\n\nOptional arguments\n\nvarname_mut::Symbol=Symbol(\"s⁽ᵐ⁾\"): Variable name for the mutant relative fitness   in the chain object.\nvarname_mean::Symbol=Symbol(\"s̲ₜ\"): Variable name for all population mean fitness.\nfreq_mut::Symbol=Symbol(\"f̲⁽ᵐ⁾\"): Variable name for all mutant barcode frequencies.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample. The dimensions of the output are (nsamples × ntime × n_chains)\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.freq_mutant_ppc_quantile-Tuple{Vector{<:AbstractFloat}, DataFrames.AbstractDataFrame, Union{AbstractString, Symbol}, Union{AbstractString, Symbol}, Union{AbstractString, Symbol}}","page":"stats","title":"BayesFitness.stats.freq_mutant_ppc_quantile","text":"freq_mut_ppc_quantile(quantile, df, varname_mut, varname_mean, varname_freq)\n\nFunction to compute the posterior predictive checks quantiles for the barcode frequency for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. This funciton computes the frequency for each of the MCMC samples in the chain object, and then extracts the quantiles from these posterior predictive checks.\n\nArguments\n\nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the posterior predictive checks.\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the\n\nvariables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\n\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nmutant initial frequency.\nvarname_mut::Union{Symbol, AbstractString}: Variable name for the mutant relative fitness in the data frame.\nvarname_mean::Union{Symbol, AbstractString}: Variable name pattern for all\n\npopulation mean fitness. All columns in the dataframe should contain this   pattern and the sorting of these names must correspond to the sorting of the   time points.\n\nvarname_freq::Union{Symbol, AbstractString}: Variable name for initial mutant barcode frequencies.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive check quantiles at all times for each MCMC sample. The dimensions of the output are (ntime × nquantile × 2), where the last dimension is used to store the lower and upper bound of the quantile. For example, if the quantile is 0.95, the third dimension stores the 0.025 and the 0.975 quantile that encompass the requested 0.95 quantile.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.freq_mutant_ppc_quantile-Tuple{Vector{<:AbstractFloat}, MCMCChains.Chains}","page":"stats","title":"BayesFitness.stats.freq_mutant_ppc_quantile","text":"freq_mut_ppc_quantile(quantile, chain, varname_mut, varname_mean, freq_mut)\n\nFunction to compute the posterior predictive checks quantiles for the barcode frequency for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. This funciton computes the frequency for each of the MCMC samples in the chain object, and then extracts the quantiles from these posterior predictive checks.\n\nArguments\n\nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the posterior predictive checks.\nchain::MCMCChains.Chains: Turing.jl MCMC chain for the fitness of a single   mutant.\n\nOptional arguments\n\nvarname_mut::Symbol=Symbol(\"s⁽ᵐ⁾\"): Variable name for the mutant relative   fitness in the chain object.\nvarname_mean::Symbol=Symbol(\"s̲ₜ\"): Variable name for all population mean   fitness.\nfreq_mut::Symbol=Symbol(\"f̲⁽ᵐ⁾\"): Variable name for all mutant barcode   frequencies.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive check quantiles at all times for each MCMC sample. The dimensions of the output are (ntime × nquantile × 2), where the last dimension is used to store the lower and upper bound of the quantile. For example, if the quantile is 0.95, the third dimension stores the 0.025 and the 0.975 quantile that encompass the requested 0.95 quantile.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.gaussian_prior_mean_fitness-Tuple{DataFrames.AbstractDataFrame}","page":"stats","title":"BayesFitness.stats.gaussian_prior_mean_fitness","text":"gaussian_prior_mean_fitness(data)\n\nFunction that fits Gaussian (normal) distributions to MCMC traces from the population mean fitness s̄ₜ. These Gaussians are then used during the mutant relative fitness inference.\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: DataFrame containing the MCMC samples for each of the inferred population mean fitness values, one inferred mean fitness per column.\n\nReturns\n\nµ::Vector{Float64}: Vector encoding the mean values of the Gaussian distributions.\nσ::Vector{Float64}: Vector encoding the standard deviation values of the Gaussian distributions.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreqratio_neutral_ppc_quantile-Tuple{Vector{<:AbstractFloat}, DataFrames.AbstractDataFrame}","page":"stats","title":"BayesFitness.stats.logfreqratio_neutral_ppc_quantile","text":"logfreqratio_neutral_ppc_quantile(quantile, df)\n\nFunction to compute the posterior predictive checks for the barcode log frequency ratio for neutral lineages. Our model predicts the frequency for neutral lineages at time t+1 based on the frequency at time t as\n\n    f_t+1^(n) = f_t^(n) \n    expleft  - bars_t tau right\n\nwhere bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Solving for the mean fitness results in\n\n    frac1tau log fracf_t+1^(n)f_t^(n) = - bars_t\n\nThis function computes the quantiles of the log frequency ration for the neutral lineages, given the MCMC samples of the population mean fitness.\n\nArguments\n\nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the posterior predictive checks. \n\n-df::DataFrames.DataFrame: DataFrame containing all population mean fitness samples⸺multiple chains must be collapsed into a single column⸺one time point per column. Note: we recommend using the var_jld2_to_df from the utils module to build this dataframe.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample. The dimensions of the output are (ntime × nquantile × 2), where the last dimension is used to store the lower and upper bound of the quantile. For example, if the quantile is 0.95, the third dimension stores the 0.025 and the 0.975 quantile that encompass the requested 0.95 quantile.\n\n\n\n\n\n","category":"method"},{"location":"#BayesFitness","page":"BayesFitness","title":"BayesFitness","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Welcome to the documentation of BayesFitness.jl! The accompanying paper, Bayesian inference of relative fitness on high-throughput pooled competition assays, explains all of the biological and mathematical background needed to understand this package. Here, we only focus on how to use the package, assuming the user already understands the objective of inferring the posterior probability distribution of the relative fitness of mutant strains in a pooled competition assay.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The package is divided into modules. Here's a brief description of the content of each module, but please visit their respective documentations to understand what each module is intended for.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"utils: Series of miscellaneous functions that make the data wrangling and processing much simpler.\nstats: Statistical functions used in the inference problem.\nmodel: Turing.jl-based Bayesian models used to infer the population mean fitness via the neutral lineages as well as the mutants' relative fitness.\nmcmc: Package main module with which to perform the Markov-Chain Monte Carlo sampling of the posterior distributions.","category":"page"},{"location":"#Example-inference","page":"BayesFitness","title":"Example inference","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To get you going with the package, let's walk through a basic inference pipeline for one competition assay. The first step consists of importing the necessary packages. ","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"note: Note\nWe use import rather than the more common using command. We find it better to keep the project organized, but feel free to use whatever is more convenient for you!","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import Bayesian inference package\nimport BayesFitness\n\n# Import libraries to manipulate data\nimport DataFrames as DF\nimport CSV","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"After having imported the libraries, we need to load our dataset into memory. This dataset is already in the format needed for BayesFitness.jl to work, so we don't have to modify anything.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import data\ndata = CSV.read(\"~/git/BayesFitness/test/data/data_example_01.csv\", DF.DataFrame)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Here you will replace \"~/git/BayesFitness/test/data\" with the directory where your data is stored, and \"data_example_01.csv\" with the name of the file containing the data. The resulting DataFrame looks something like this:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"| BCID_x | barcode                                               | name                    | count | time | neutral | count_sum  |   |   |   |\n|--------|-------------------------------------------------------|-------------------------|-------|------|---------|------------|---|---|---|\n| 0      | TGATCAATCTACAAAAATATTTAATG_GAGTGAAACATGAATGGTATTCATCA | Batch1_1Day-T0_combined | 53    | 0    | FALSE   | 543947     |   |   |   |\n| 1      | CCGCCAATCCCGAACCCCGTTTCGCC_ACTCTAACGTGTAACTAATTTTGAGT | Batch1_1Day-T0_combined | 1213  | 0    | FALSE   | 543947     |   |   |   |\n| 2      | GACAGAAAAGCCAAATGGATTTACCG_ATGGGAACACGGAATGATCTTTTATT | Batch1_1Day-T0_combined | 17    | 0    | FALSE   | 543947     |   |   |   |\n| 3      | CCAACAAAACACAAATCTGTTGTGTA_TACTAAATAAGTAAGGGAATTCTGTT | Batch1_1Day-T0_combined | 19    | 0    | FALSE   | 543947     |   |   |   |\n| 4      | TATCGAAACCCAAAGAGATTTAATCG_ATGACAAACTTTAAATAATTTAATTG | Batch1_1Day-T0_combined | 23    | 0    | FALSE   | 543947     |   |   |   |\n| 5      | TATCGAAACCCAAAGAGATTTAATCG_CGATCAAAGACTAACTTATTTTGTGG | Batch1_1Day-T0_combined | 16    | 0    | FALSE   | 543947     |   |   |   |\n| 6      | TATCGAAACCCAAAGAGATTTAATCG_TTGCCAAGCTGGAAAGCTTTTTATGA | Batch1_1Day-T0_combined | 12    | 0    | FALSE   | 543947     |   |   |   |\n| 7      | ATCACAATAACTAAACTGATTCTTCA_CTCATAACATCAAAAAAAATTCAAAT | Batch1_1Day-T0_combined | 161   | 0    | FALSE   | 543947     |   |   |   |\n| 8      | TATCGAAACCCAAAGAGATTTAATCG_GTTTAAACCATTAATTATATTAGATC | Batch1_1Day-T0_combined | 19    | 0    | FALSE   | 543947     |   |   |   |","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The relevant columns in this data frame are:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"barcode: The unique ID that identifies the barcode.\ncount: The number of reads for this particular barcode.\ntime: The time point ID indicating the order in which samples were taken.\nneutral: Indicator of whether the barcode belongs to a neutral lineage or not.","category":"page"},{"location":"#Inferring-the-population-mean-fitness","page":"BayesFitness","title":"Inferring the population mean fitness","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"With the data in hand, our first task is to infer the population mean fitness using the neutral lineages. For this, we use the BayesFitness.mcmc.mcmc_mean_fitness function from the mcmc module. The main parameters we need to define are:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":":data: Tidy data frame containing the raw barcode counts.\n:n_walkers: Number of MCMC chains to run in parallel. NOTE: Having multiple chains run in parallel is convenient for diagnostics. BayesFitness.jl will use the available threads, so make sure you have more than one thread in your julia session if you want to run this inference in a multi-threaded way.\n:outputdir: String pointing to the output directory.\noutputname: String defining the pattern for the output files. This can be something related to the dataset. For example, the growth media, or the date of the experiment, of whatever metadata used to distinguish different datasets.\nmodel: Bayesian model from the model module that defines the posterior distribution to be sampled.\nmodel_kwargs: The parameters required by the model function.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We compile all of these parameters into a dictionary that looks something like this:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"param = Dict(\n    :data => data, \n    :n_walkers => 3, \n    :n_steps => 1_000,\n    :outputdir => \"./output/\",\n    :outputname => \"data_01_meanfitness\",\n    :model => BayesFitness.model.mean_fitness_neutrals_lognormal,\n    :model_kwargs => Dict(\n        :α => BayesFitness.stats.dirichlet_prior_neutral(\n            data[data.time.==0, :neutral],\n        )\n    )\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We are now ready to sample the posterior distribution for the population mean fitness. BayesFitness.jl makes this very easy by using the Bayes.mcmc.mcmc_mean_fitness function from the mcmc module. All we have to do is run","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Run inference\nBayesFitness.mcmc.mcmc_mean_fitness(; param...)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The output of this function are jld2 files that save the native data structure. To extract the MCMC samples of the variable we care about–-equivalent to marginalizing out all the nuisance variables–-we can use the BayesFitness.utils.var_jld2_to_df from the utils module, indicating the name of the variable we want to extract.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"BayesFitness.utils.var_jld2_to_df(\"./output/\", \"data_01_meanfitness\", :sₜ)","category":"page"},{"location":"#Inferring-mutants'-relative-fitness","page":"BayesFitness","title":"Inferring mutants' relative fitness","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Once we make sure that the mutants relative fitness looks okay, we can tackle the inference of each mutant relative fitness. The process is very similar, the main difference being that we use the results from the previous step as part of the inputs that go into the corresponding Bayesian model defined in the model module. More specifically, the inferred population mean fitness enters our inference as a \"prior\" on this value. This prior has to be parametrized, for which we chose a Gaussian distribution. So we need to fit one Gaussian distribution for each MCMC chain sampled in the previous section. The BayesFitness.stats.gaussian_prior_mean_fitness function in the stats module can help us with this.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Infer mean fitness distributions\nmean_fitness_dist = BayesFitness.stats.gaussian_prior_mean_fitness(\n    BayesFitness.utils.var_jld2_to_df(\"./output/\", \"data_01_meanfitness\", :sₜ)\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can now define the dictionary containing the parameters that go into the [BayesFitness.mcmc.mcmc_mutants_fitness_multithread] function from the mcmc module. ","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"note: Note\nNotice that we can either use the [BayesFitness.mcmc.mcmc_mutants_fitness_multithread] or the [BayesFitness.mcmc.mcmc_mutants_fitness] function. The difference being that the first one can run multiple mutants simultaneously, but only one chain at the time, while the second one can run the chains in parallel, but only one mutant at the time. You might need to use either depending on what you are trying to do, but we recommend the _multithread function to speed up the inference of thousands of fitness values.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define function parameters\nparam = Dict(\n    :data => data,\n    :n_walkers => 3,\n    :n_steps => 1_000,\n    :outputdir => \"./output/\",\n    :outputname => \"data_01_mutantfitness\",\n    :model => BayesFitness.model.mutant_fitness_lognormal,\n    :model_kwargs => Dict(\n        :α => BayesFitness.stats.beta_prior_mutant(\n            data[data.time.==0, :barcode],\n        ),\n        :μ_s̄ => mean_fitness_dist[1],\n        :σ_s̄ => mean_fitness_dist[2],\n    )\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Finally, we run the inference.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Run inference\nBayesFitness.mcmc.mcmc_mutant_fitness_multithread(; param...)","category":"page"},{"location":"#Contents","page":"BayesFitness","title":"Contents","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"","category":"page"},{"location":"#Index","page":"BayesFitness","title":"Index","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"","category":"page"},{"location":"utils/#utils","page":"utils","title":"utils","text":"","category":"section"},{"location":"utils/","page":"utils","title":"utils","text":"Modules = [BayesFitness.utils]\nOrder   = [:function, :type]","category":"page"},{"location":"utils/#BayesFitness.utils.chain_to_df","page":"utils","title":"BayesFitness.utils.chain_to_df","text":"chain_to_df(chain, varnames)\n\nFunction that extracts the variables in varnames from the chain object and concatenates them into a DataFrame. Multiple chains are piled on top of each other.\n\nArguments\n\nchain::MCMCChains.Chains: Chain with variables to be converted to dataframe\n\nOptional arguments\n\nvarnames::Union{Vector{Symbol}, Nothing}=nothing: Names of the variables in the chain to be extracted. These can be either the full variable name or patterns to extract multi-dimensional variables. If nothing is given, all parameters are extracted into a dataframe.\n\nReturns\n\nDataFrames.DataFrame: Data frame where each column represents all the MCMC samples for a single variable (multiple chains are stack on top of each other)\n\n\n\n\n\n","category":"function"},{"location":"utils/#BayesFitness.utils.var_jld2_concat","page":"utils","title":"BayesFitness.utils.var_jld2_concat","text":"var_jld2_concat(dir, pattern, varname)\n\nFunction that takes .jld2 files in dir with pattern and extracts a single variable to concatentate into a single chain object. This function is useful to extract variables with the same name on multiple .jld2 files and compile them into a single MCMCChains.Chains object.\n\nNOTE: All chains from which samples will be extracted must have the same number of samples.\n\nArguments\n\ndir::String: Directory where file(s) with MCMC chains are stored.\npattern::String: Pattern common among all files to process. NOTE: This is use in the Glob.glob command to locate all jld2 files from which to extract the chains.\nvarname::Symbol: Name of variable in chain object to extract.\n\nOptional Arguments\n\nchainname::String=\"chain\": String defining the dictionary key on the .jld2 file to extract the MCMC chain.\n\nReturns\n\nMCMCChains.Chains: Chain containing all variable samples.\n\n\n\n\n\n","category":"function"},{"location":"utils/#BayesFitness.utils.var_jld2_to_df","page":"utils","title":"BayesFitness.utils.var_jld2_to_df","text":"var_jld2_to_df(dir, pattern, varname, chainname)\n\nFunction that takes .jld2 files in dir with pattern and extracts a single variable into a dataframe. This function is useful to extract, for example, the chains for each inference of the population mean fitness over multiple time points.\n\nNOTE: All chains from which samples will be extracted must have the same number of samples.\n\nArguments\n\ndir::String: Directory where file(s) with MCMC chains are stored.\npattern::String: Pattern common among all files to process. NOTE: This is use in the Glob.glob command to locate all jld2 files from which to extract the chains.\nvarname::Symbol: Name of variable in chain object to extract.\n\nOptional Arguments\n\nchainname::String=\"chain\": String defining the dictionary key on the .jld2 file to extract the MCMC chain.\n\nReturns\n\nDataFrames.DataFrame: DataFrame containing all variable samples⸺multiple chains are collapsed into a single column⸺one variable per column.\n\n\n\n\n\n","category":"function"}]
}
