var documenterSearchIndex = {"docs":
[{"location":"mcmc/#mcmc","page":"mcmc","title":"mcmc","text":"","category":"section"},{"location":"mcmc/","page":"mcmc","title":"mcmc","text":"Modules = [BayesFitness.mcmc]\nOrder   = [:function, :type]","category":"page"},{"location":"mcmc/#BayesFitness.mcmc.mcmc_joint_fitness-Tuple{}","page":"mcmc","title":"BayesFitness.mcmc.mcmc_joint_fitness","text":"mcmc_joint_fitness(; kwargs)\n\nFunction to sample the joint posterior distribution for the fitness value of all mutant and neutral linages given a time-series barcode count.\n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage or not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to sample from the population mean fitness posterior distribution.\n\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputname::String: String to be used to name the .jld2 output file.\nmodel::Function: Turing.jl model defining the posterior distribution from which to sample (see BayesFitness.model module). This function must take as the first four inputs the following:\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage.  NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲⁽ᵐ⁾::Matrix{Int64}: T × M matrix where T is the number of time points in the data set and M is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲::Matrix{Int64}:: T × B matrix, where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix must be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). The reason it is an independent input parameter is to avoid the hcat computation within the Turing model.\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nOptional Keyword Arguments\n\nmodel_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler to be used.\nensemble::Turing.AbstractMCMC.AbstractMCMCEnsemble=Turing.MCMCSerial():\n\nSampling modality to be used. Options are:     - Turing.MCMCSerial()     - Turing.MCMCThreads()     - Turing.MCMCDistributed()\n\nverbose::Bool=true: Boolean indicating if the function should print partial progress to the screen or not.\n\n\n\n\n\n","category":"method"},{"location":"mcmc/#BayesFitness.mcmc.mcmc_joint_fitness_hierarchical_replicates-Tuple{}","page":"mcmc","title":"BayesFitness.mcmc.mcmc_joint_fitness_hierarchical_replicates","text":"mcmc_joint_fitness_hierarchical_replicates(; kwargs)\n\nFunction to sample the joint posterior distribution for the fitness value of all mutant and neutral linages given a time-series barcode count.\n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage or not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to sample from the population mean fitness posterior distribution.\n\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputname::String: String to be used to name the .jld2 output file.\nmodel::Function: Turing.jl model defining the posterior distribution from which to sample (see BayesFitness.model module). This function must take as the first four inputs the following:\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage.  NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲⁽ᵐ⁾::Matrix{Int64}: T × M matrix where T is the number of time points in the data set and M is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲::Matrix{Int64}:: T × B matrix, where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix must be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). The reason it is an independent input parameter is to avoid the hcat computation within the Turing model.\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nOptional Keyword Arguments\n\nmodel_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler to be used.\nensemble::Turing.AbstractMCMC.AbstractMCMCEnsemble=Turing.MCMCSerial():\n\nSampling modality to be used. Options are:     - Turing.MCMCSerial()     - Turing.MCMCThreads()     - Turing.MCMCDistributed()\n\nverbose::Bool=true: Boolean indicating if the function should print partial progress to the screen or not.\n\n\n\n\n\n","category":"method"},{"location":"mcmc/#BayesFitness.mcmc.mcmc_popmean_fitness-Tuple{}","page":"mcmc","title":"BayesFitness.mcmc.mcmc_popmean_fitness","text":"mcmc_popmean_fitness(; kwargs)\n\nFunction to sample the joint posterior distribution for the population mean fitness value using only neutral linages given a time-series barcode count.\n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage or not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to sample from the population mean fitness posterior distribution.\n\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputname::String: String to be used to name the .jld2 output file.\nmodel::Function: Turing.jl model defining the posterior distribution from which to sample (see BayesFitness.model module). This function must take as the first three inputs the following:\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage.  NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲::Matrix{Int64}:: T × B matrix, where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix must be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). The reason it is an independent input parameter is to avoid the hcat computation within the Turing model.\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nOptional Keyword Arguments\n\nmodel_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler to be used.\nensemble::Turing.AbstractMCMC.AbstractMCMCEnsemble=Turing.MCMCSerial():\n\nSampling modality to be used. Options are:     - Turing.MCMCSerial()     - Turing.MCMCThreads()     - Turing.MCMCDistributed()\n\nverbose::Bool=true: Boolean indicating if the function should print partial progress to the screen or not.\n\n\n\n\n\n","category":"method"},{"location":"mcmc/#BayesFitness.mcmc.mcmc_single_fitness-Tuple{}","page":"mcmc","title":"BayesFitness.mcmc.mcmc_single_fitness","text":"mcmc_single_fitness(; kwargs)\n\nFunction to sample the joint posterior distribution for the fitness value of a single mutant barcode and all neutral linages given a time-series barcode count.\n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage or not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to sample from the population mean fitness posterior distribution.\n\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputname::String: String to be used to name the .jld2 output file.\nmodel::Function: Turing.jl model defining the posterior distribution from which to sample (see BayesFitness.model module). This function must take as the first four inputs the following:\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage.  NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲⁽ᵐ⁾::Matrix{Int64}: T × M matrix where T is the number of time points in the data set and M is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲::Matrix{Int64}:: T × B matrix, where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix must be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). The reason it is an independent input parameter is to avoid the hcat computation within the Turing model.\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nOptional Keyword Arguments\n\nmodel_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler to be used.\nensemble::Turing.AbstractMCMC.AbstractMCMCEnsemble=Turing.MCMCSerial():\n\nSampling modality to be used. Options are:     - Turing.MCMCSerial()     - Turing.MCMCThreads()     - Turing.MCMCDistributed()\n\nverbose::Bool=true: Boolean indicating if the function should print partial progress to the screen or not.\nmultithread::Bool=false: Boolean indicating whether to use Threads.@threads when running the for-loop over all mutants. NOTE: This requires julia to be initialized with multiple threads.\n\n\n\n\n\n","category":"method"},{"location":"viz/#viz","page":"viz","title":"viz","text":"","category":"section"},{"location":"viz/","page":"viz","title":"viz","text":"Modules = [BayesFitness.viz]\nOrder   = [:function, :type]","category":"page"},{"location":"model/#model","page":"model","title":"model","text":"","category":"section"},{"location":"model/","page":"model","title":"model","text":"Modules = [BayesFitness.model]\nOrder   = [:function, :type]","category":"page"},{"location":"model/#BayesFitness.model.fitness_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}","page":"model","title":"BayesFitness.model.fitness_lognormal","text":"fitness_lognormal(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲, n̲ₜ; s_pop_prior, σ_pop_prior, s_mut_prior, σ_mut_prior, λ_prior)\n\nTuring.jl model to sample the joint posterior distribution for a competitive fitness experiment.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲⁽ᵐ⁾::Matrix{Int64}: T × M matrix where T is the number of time points in the data set and M is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲::Vector{Vector{Int64}}:: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] =   standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] =   standard deviation) for a Normal prior on the population mean fitness   values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.\nσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the   correspnding parameters (Vector: σ_pop_prior[1] = mean, σ_pop_prior[2] =   standard deviation, Matrix: σ_pop_prior[:, 1] = mean, σ_pop_prior[:, 2] =   standard deviation) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If typeof(σ_pop_prior) <:   Matrix, there should be as many rows in the matrix as pairs of time   adjacent time points in dataset.\ns_mut_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] =   standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] =   standard deviation) for a Normal prior on the mutant fitness values. If   typeof(s_mut_prior) <: Matrix, there should be as many rows in the matrix   as mutant lineages in the dataset.\nσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(σ_mut_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages in the dataset.\nλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the correspnding parameters (Vector: λ_prior[1] = mean, λ_prior[2] = standard deviation, Matrix: λ_prior[:, 1] = mean, λ_prior[:, 2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(λ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points in the dataset.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.fitness_lognormal-Tuple{Matrix{Int64}, Vector{Int64}, Vector{Vector{Int64}}, Vector{Int64}}","page":"model","title":"BayesFitness.model.fitness_lognormal","text":"fitness_lognormal(R̲̲⁽ⁿ⁾, r̲⁽ᵐ⁾, R̲̲, n̲ₜ; s_pop_prior, σ_pop_prior, s_mut_prior, σ_mut_prior, λ_prior)\n\nTuring.jl model to sample the joint posterior distribution for a competitive fitness experiment for the neutral barcodes and a single mutant barcode\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nr̲⁽ᵐ⁾::Vector{Int64}: T dimensional vector where T is the number of time points in the data set. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲::Vector{Vector{Int64}}:: T × B matrix–split into a vector of vectors\n\nfor computational efficiency–where T is the number of time points in the data   set and B is the number of barcodes. Each column represents the barcode   count trajectory for a single lineage.\n\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nOptional Keyword Arguments\n\ns_pop_prior::Vector{Float64}=[0.0, 2.0]: Vector with the correspnding   parameters (s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation)   for a Normal prior on the population mean fitness values. NOTE: This   method assigns the same prior to all population mean fitness to be   inferred.\nσ_pop_prior::Vector{Float64}=[0.0, 1.0]: Vector with the correspnding   parameters (σ_pop_prior[1] = mean, σ_pop_prior[2] = standard deviation)   for a Log-Normal prior on the population mean fitness error utilized in the   log-likelihood function. NOTE: This method assigns the same prior to   all population mean fitness errors to be inferred.\ns_mut_prior::Vector{Float64}=[0.0, 2.0]: Vector with the correspnding   parameters (s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation)   for a Normal prior on the mutant fitness values. NOTE: This method   assigns the same prior to all mutant fitness values to be inferred.\nσ_mut_prior::Vector{Float64}=[0.0, 1.0]: Vector with the correspnding   parameters (σ_mut_prior[1] = mean, σ_mut_prior[2] = standard deviation)   for a Log-Normal prior on the mutant fitness error utilized in the   log-likelihood function. NOTE: This method assigns the same prior to   all mutant fitness error values to be inferred.\nλ_prior::Vector{Float64}=[3.0, 3.0]: Vector with the corresponding parameters (λ_prior[1] = mean, λ_prior[2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). NOTE: This method assigns   the same prior to all mutant fitness error values to be inferred.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.fitness_lognormal_hierarchical_replicates-Tuple{Array{Int64, 3}, Array{Int64, 3}, Array{Int64, 3}, Matrix{Int64}}","page":"model","title":"BayesFitness.model.fitness_lognormal_hierarchical_replicates","text":"fitness_lognormal(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲, n̲ₜ; s_pop_prior, σ_pop_prior, s_mut_prior, σ_mut_prior, λ_prior)\n\nTuring.jl model to sample the joint posterior distribution for a competitive fitness experiment.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲⁽ⁿ⁾::Array{Int64, 3}: T × N × R array where T is the number of time points in the data set, N is the number of neutral lineage barcodes, and R is the number of experimental replicates. For each slice on the R-axis, each column represents the barcode count trajectory for a single neutral lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲⁽ᵐ⁾::Array{Int64, 3}: T × M × R array where T is the number of time\n\npoints in the data set, M is the number of mutant lineage barcodes, and R is the number of experimental replicates. For each slice on the R-axis, each   column represents the barcode count trajectory for a single mutant lineage.   NOTE: The model assumes the rows are sorted in order of increasing time.\n\nR̲̲::Array{Int64, 3}:: T × B × R where T is the number of time points in the data set, B is the number of barcodes, and R is the number of experimental replicates. For each slince in the R axis, each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Vector{Int64}}: R Vectors with the total number of barcode counts for each time point on each experimental replicate. NOTE: Each vector vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nOptional Keyword Arguments\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] =   standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] =   standard deviation) for a Normal prior on the population mean fitness   values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.\nσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the   correspnding parameters (Vector: σ_pop_prior[1] = mean, σ_pop_prior[2] =   standard deviation, Matrix: σ_pop_prior[:, 1] = mean, σ_pop_prior[:, 2] =   standard deviation) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If typeof(σ_pop_prior) <:   Matrix, there should be as many rows in the matrix as pairs of time   adjacent time points × number of replicates in dataset.\ns_mut_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] =   standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] =   standard deviation) for a Normal prior on the mutant fitness values. If   typeof(s_mut_prior) <: Matrix, there should be as many rows in the matrix   as number of mutant lineages × number of replicates in the dataset.\nσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(σ_mut_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of replicates in the dataset.\nλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the correspnding parameters (Vector: λ_prior[1] = mean, λ_prior[2] = standard deviation, Matrix: λ_prior[:, 1] = mean, λ_prior[:, 2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(λ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points × number of replicates in the dataset.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.fitness_normal-Tuple{Matrix{Int64}, Matrix{Int64}, Matrix{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.fitness_normal","text":"fitness_lognormal(R̲̲, R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, n̲ₜ; s_pop_prior, σ_pop_prior, s_mut_prior, σ_mut_prior, λ_prior)\n\nTuring.jl model to sample the joint posterior distribution for a competitive fitness experiment.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲⁽ᵐ⁾::Matrix{Int64}: T × M matrix where T is the number of time points in the data set and M is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲::Matrix{Int64}:: T × B matrix, where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nOptional Keyword Arguments\n\ns_pop_prior::Vector{Float64}=[0.0, 2.0]: Vector with the correspnding   parameters (s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation)   for a Normal prior on the population mean fitness values. NOTE: This   method assigns the same prior to all population mean fitness to be   inferred.\nσ_pop_prior::Vector{Float64}=[0.0, 1.0]: Vector with the correspnding   parameters (σ_pop_prior[1] = mean, σ_pop_prior[2] = standard deviation)   for a Log-Normal prior on the population mean fitness error utilized in the   log-likelihood function. NOTE: This method assigns the same prior to   all population mean fitness errors to be inferred.\ns_mut_prior::Vector{Float64}=[0.0, 2.0]: Vector with the correspnding   parameters (s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation)   for a Normal prior on the mutant fitness values. NOTE: This method   assigns the same prior to all mutant fitness values to be inferred.\nσ_mut_prior::Vector{Float64}=[0.0, 1.0]: Vector with the correspnding   parameters (σ_mut_prior[1] = mean, σ_mut_prior[2] = standard deviation)   for a Log-Normal prior on the mutant fitness error utilized in the   log-likelihood function. NOTE: This method assigns the same prior to   all mutant fitness error values to be inferred.\nλ_prior::Vector{Float64}=[3.0, 3.0]: Vector with the corresponding parameters (λ_prior[1] = mean, λ_prior[2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). NOTE: This method assigns   the same prior to all mutant fitness error values to be inferred.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.freq_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}","page":"model","title":"BayesFitness.model.freq_lognormal","text":"freq_lognormal(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲, n̲ₜ; λ_prior)\n\nTuring.jl model to sample the joint posterior distribution for frequency values on a fitness experiment.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. NOTE: This is a place-holder variable only used to reuse functions from the mcmc module.\nR̲̲⁽ᵐ⁾::Matrix{Int64}: T × M matrix where T is the number of time points in the data set and M is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. NOTE: The model assumes the rows are sorted in order of increasing time. NOTE: This is a place-holder variable only used to reuse functions from the mcmc module.\nR̲̲::Vector{Vector{Int64}}:: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nOptional Keyword Arguments\n\nλ_prior::Vector{Float64}=[3.0, 3.0]: Vector with the corresponding parameters (λ_prior[1] = mean, λ_prior[2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). NOTE: This method assigns   the same prior to all mutant fitness error values to be inferred.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.multienv_fitness_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Matrix{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.multienv_fitness_lognormal","text":"multienv_fitness_lognormal(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲, n̲ₜ; kwargs)\n\nTuring.jl model to sample the joint posterior distribution for a competitive fitness experiment with different environments on each growth-dilution cycle.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲⁽ᵐ⁾::Matrix{Int64}: T × M matrix where T is the number of time points in the data set and M is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲::Matrix{Int64}:: T × B matrix, where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nKeyword Arguments\n\nenvs::Vector{<:Any}: List of environments for each time point in dataset. NOTE: The length must be equal to that of n̲ₜ to have one environment per time point.\n\nOptional Keyword Arguments\n\ns_pop_prior::Vector{Float64}=[0.0, 2.0]: Vector with the correspnding   parameters (s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation)   for a Normal prior on the population mean fitness values. NOTE: This   method assigns the same prior to all population mean fitness to be   inferred.\nσ_pop_prior::Vector{Float64}=[0.0, 1.0]: Vector with the correspnding   parameters (σ_pop_prior[1] = mean, σ_pop_prior[2] = standard deviation)   for a Log-Normal prior on the population mean fitness error utilized in the   log-likelihood function. NOTE: This method assigns the same prior to   all population mean fitness errors to be inferred.\ns_mut_prior::Vector{Float64}=[0.0, 2.0]: Vector with the correspnding   parameters (s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation)   for a Normal prior on the mutant fitness values. NOTE: This method   assigns the same prior to all mutant fitness values to be inferred.\nσ_mut_prior::Vector{Float64}=[0.0, 1.0]: Vector with the correspnding   parameters (σ_mut_prior[1] = mean, σ_mut_prior[2] = standard deviation)   for a Log-Normal prior on the mutant fitness error utilized in the   log-likelihood function. NOTE: This method assigns the same prior to   all mutant fitness error values to be inferred.\nλ_prior::Vector{Float64}=[3.0, 3.0]: Vector with the corresponding parameters (λ_prior[1] = mean, λ_prior[2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). NOTE: This method assigns   the same prior to all mutant fitness error values to be inferred.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.multienv_fitness_lognormal-Tuple{Matrix{Int64}, Vector{Int64}, Matrix{Int64}, Vector{Int64}}","page":"model","title":"BayesFitness.model.multienv_fitness_lognormal","text":"multienv_fitness_lognormal(R̲̲⁽ⁿ⁾, r̲⁽ᵐ⁾, R̲̲, n̲ₜ; kwargs)\n\nTuring.jl model to sample the posterior distribution for a competitive fitness experiment with different environments on each growth-dilution cycle using data from a single mutant barcode and all available neutral barcodes.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nr̲⁽ᵐ⁾::Vector{Int64}: T dimensional vector where T is the number of time points in the data set. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲::Matrix{Int64}:: T × (N+2) matrix, where T is the number of time points in the data set and N is the number of neutral barcodes. Each of the first N columns represent the barcode count trajectory for a single neutral lineage. The N+1 column represents the count trajectory for the relevant mutant barcode. The N+2 column represents the trajectory of all other ignored barcodes.\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nKeyword Arguments\n\nenvs::Vector{<:Any}: List of environments for each time point in dataset. NOTE: The length must be equal to that of n̲ₜ to have one environment per time point.\n\nOptional Keyword Arguments\n\ns_pop_prior::Vector{Float64}=[0.0, 2.0]: Vector with the correspnding   parameters (s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation)   for a Normal prior on the population mean fitness values. NOTE: This   method assigns the same prior to all population mean fitness to be   inferred.\nσ_pop_prior::Vector{Float64}=[0.0, 1.0]: Vector with the correspnding   parameters (σ_pop_prior[1] = mean, σ_pop_prior[2] = standard deviation)   for a Log-Normal prior on the population mean fitness error utilized in the   log-likelihood function. NOTE: This method assigns the same prior to   all population mean fitness errors to be inferred.\ns_mut_prior::Vector{Float64}=[0.0, 2.0]: Vector with the correspnding   parameters (s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation)   for a Normal prior on the mutant fitness values. NOTE: This method   assigns the same prior to all mutant fitness values to be inferred.\nσ_mut_prior::Vector{Float64}=[0.0, 1.0]: Vector with the correspnding   parameters (σ_mut_prior[1] = mean, σ_mut_prior[2] = standard deviation)   for a Log-Normal prior on the mutant fitness error utilized in the   log-likelihood function. NOTE: This method assigns the same prior to   all mutant fitness error values to be inferred.\nλ_prior::Vector{Float64}=[3.0, 3.0]: Vector with the corresponding parameters (λ_prior[1] = mean, λ_prior[2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). NOTE: This method assigns   the same prior to all mutant fitness error values to be inferred.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.neutrals_lognormal-Tuple{Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}","page":"model","title":"BayesFitness.model.neutrals_lognormal","text":"mean_fitness_lognormal(R̲̲, R̲̲⁽ⁿ⁾, n̲ₜ; s_pop_prior, σ_pop_prior, λ_prior)\n\nTuring.jl model to sample the joint posterior distribution of the population mean fitness for a competitive fitness experiment using only the neutral lineages.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲⁽ⁿ⁾::Matrix{Int64}: T × N matrix where T is the number of time points in the data set and N is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. NOTE: The model assumes the rows are sorted in order of increasing time.\nR̲̲::Matrix{Int64}:: T × B matrix, where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\n\nOptional Keyword Arguments\n\ns_pop_prior::Vector{Float64}=[0.0, 2.0]: Vector with the correspnding   parameters (s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation)   for a Normal prior on the population mean fitness values. NOTE: This   method assigns the same prior to all population mean fitness to be   inferred.\nσ_pop_prior::Vector{Float64}=[0.0, 1.0]: Vector with the correspnding   parameters (σ_pop_prior[1] = mean, σ_pop_prior[2] = standard deviation)   for a Log-Normal prior on the population mean fitness error utilized in the   log-likelihood function. NOTE: This method assigns the same prior to   all population mean fitness errors to be inferred.\nλ_prior::Vector{Float64}=[3.0, 3.0]: Vector with the corresponding parameters (λ_prior[1] = mean, λ_prior[2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). NOTE: This method assigns   the same prior to all mutant fitness error values to be inferred.\n\n\n\n\n\n","category":"method"},{"location":"stats/#stats","page":"stats","title":"stats","text":"","category":"section"},{"location":"stats/","page":"stats","title":"stats","text":"Modules = [BayesFitness.stats]\nOrder   = [:function, :type]","category":"page"},{"location":"stats/#BayesFitness.stats.freq_mutant_ppc-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"stats","title":"BayesFitness.stats.freq_mutant_ppc","text":"freq_mutant_ppc(n_ppc, df; param, flatten=true)\n\nFunction to compute the posterior predictive checks for the barcode frequency for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables in the mcmc chain defining the following variables:\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\nmutant_freq: Variable defining the inferred initial frequency for the mutant.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.freq_mutant_ppc-Tuple{MCMCChains.Chains, Int64}","page":"stats","title":"BayesFitness.stats.freq_mutant_ppc","text":"freq_mutant_ppc(n_ppc, df; param, flatten=true)\n\nFunction to compute the posterior predictive checks for the barcode frequency for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables in the mcmc chain defining the following variables:\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\nmutant_freq: Variable defining the inferred initial frequency for the mutant.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_mean_ppc-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_mean_ppc","text":"logfreq_ratio_mean_ppc(df, n_ppc, param; flatten=true)\n\nFunction to compute the posterior predictive checks (better called the posterior retrodictive checks) for the barcode log-frequency ratio for neutral lineages. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(n) = f_t^(n) \n    expleft left( - bars_t right) tau right\n\nwhere bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(n)f_t^(n) sim \n    log-mathcalNleft( - bars_t sigma^(n) right)\n\nwhere sigma^(n) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nn_ppc::Int: Number of samples to generate per set of parameters.\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:     - population_mean_fitness: Common pattern in all population mean fitness     variables.     - population_std_fitness: Common pattern in all standard deviations       estimates for the likelihood.\n\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ)= s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_mean_ppc-Tuple{MCMCChains.Chains, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_mean_ppc","text":"logfreq_ratio_mean_ppc(chain, n_ppc; param, flatten=true)\n\nFunction to compute the posterior predictive checks (better called the posterior retrodictive checks) for the barcode log-frequency ratio for neutral lineages. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(n) = f_t^(n) \n    expleft left( - bars_t right) tau right\n\nwhere bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(n)f_t^(n) sim \n    log-mathcalNleft( - bars_t sigma^(n) right)\n\nwhere sigma^(n) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nn_ppc::Int: Number of samples to generate per set of parameters.\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the   variables needed to compute the posterior predictive checks. The dataframe   should have MCMC samples for\npopulation mean fitness values. NOTE: The number of columns containing\npopulation mean fitness values determines the number of datapoints where the   ppc are evaluated.\nlog-normal likelihood standard deviation.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:     - population_mean_fitness: Common pattern in all population mean fitness     variables.     - population_std_fitness: Common pattern in all standard deviations         estimates for the likelihood.\n\nflatten::Bool=true: Boolean indicating whether to flatten the output of   multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_multienv_ppc-Tuple{DataFrames.AbstractDataFrame, Int64, Vector}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_multienv_ppc","text":"logfreq_ratio_mutienv_ppc(df, n_ppc, param; flatten=true)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\nenvs::Vector{<:Any}: List of environments in experiment. This is used to index the corresponding fitness from the chain. NOTE: The list of environments should be the name or corresponding label of the environemnt; the index is generated internally.\n\nOptional Keyword Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:\n\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of\n\nmultiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_mutant_ppc-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_mutant_ppc","text":"logfreq_ratio_mutant_ppc(df, n_ppc; param, flatten=true)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Keyword Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the\n\nname of the variables in the mcmc chain defining the following variables:\n\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of\n\nmultiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_mutant_ppc-Tuple{MCMCChains.Chains, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_mutant_ppc","text":"logfreq_ratio_mutant_ppc(chain, n_ppc; param, flatten=true)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\nlog-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the\n\nname of the variables in the mcmc chain defining the following variables:\n\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nflatten::Bool=true: Boolean indicating whether to flatten the output of\n\nmultiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.matrix_quantile_range-Union{Tuple{T}, Tuple{Vector{<:AbstractFloat}, Matrix{T}}} where T<:Real","page":"stats","title":"BayesFitness.stats.matrix_quantile_range","text":"matrix_quantile_range(quantile, matrix; dim=2)\n\nFunction to compute the quantile ranges of matrix mat over dimension dim. For example, if quantile[1] = 0.95, This function returns the 0.025 and 0.975 quantiles that capture 95 percent of the entires on the matrix.\n\nArguments\n\nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the posterior predictive checks.\nmatrix::Matrix{<:Real}: Array over which to compute quantile ranges.\n\nOptional arguments\n\ndim::Int=2: Dimension over which to compute quantiles. Defualt = 1, i.e., columns.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.naive_fitness-Tuple{DataFrames.AbstractDataFrame}","page":"stats","title":"BayesFitness.stats.naive_fitness","text":"naive_fitness(data; id_col, time_col, count_col, neutral_col, pseudo_count)\n\nFunction to compute a naive estimate of mutant fitness data based on counts. The fitness estimate is computed as\n\nleftlangle\nlogfracf^(m)_t+1f^(m)_t - logfracf^(n)_t+1f^(n)_t\nrightrangle = s^(m)\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to infer the fitness values on mutants. The DataFrame must contain at least the following columns:     - id_col: Column identifying the ID of the barcode. This can the barcode     sequence, for example.     - time_col: Column defining the measurement time point.     - count_col: Column with the raw barcode count.     - neutral_col: Column indicating whether the barcode is from a neutral     lineage or not.\n\nOptional Keyword Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the\n\ninference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\n\npseudo_count::Int=1: Pseudo count number to add to all counts. This is useful to avoid divisions by zero.\n\nReturns\n\nDataFrames.DataFrame: Data frame with two columns:\nid_col: Column indicating the strain ID.\nfitness: Naive fitness estimate.\n\n\n\n\n\n","category":"method"},{"location":"#BayesFitness","page":"BayesFitness","title":"BayesFitness","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Welcome to the documentation of BayesFitness.jl! The accompanying paper, Bayesian inference of relative fitness on high-throughput pooled competition assays, explains all of the biological and mathematical background needed to understand this package. Here, we only focus on how to use the package, assuming the user already understands the objective of inferring the posterior probability distribution of the relative fitness of mutant strains in a pooled competition assay.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The package is divided into modules. Here's a brief description of the content of each module, but please visit their respective documentations to understand what each module is intended for.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"utils: Series of miscellaneous functions that make the data wrangling and processing much simpler.\nviz: Makie.jl-based module with useful plotting functions to display the data and the MCMC results for visual diagnostics.\nstats: Statistical functions used in the inference problem.\nmodel: Turing.jl-based Bayesian models used to infer the population mean fitness via the neutral lineages as well as the mutants' relative fitness.\nmcmc: The main module with which to perform the Markov-Chain Monte Carlo sampling of the posterior distributions.","category":"page"},{"location":"#Example-inference","page":"BayesFitness","title":"Example inference","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To get you going with the package, let's walk through a basic inference pipeline for one competition assay. Our ultimate goal consists of inferring the relative fitness for each of the mutant barcodes. To that end, we assume that the frequency time-series obeys the following equation","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"f_t+1^(b) = f_t^(b) mathrme^left(s^(b) - bars_t right)tau\ntag1","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"where f_t^(b) is the frequency of barcode b at time t, s^(b) is the relative fitness of this barcode, bars_t is the population mean fitness at time t, and tau is the time interval between time t and t+1.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The first step consists of importing the necessary packages. ","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"note: Note\nWe use import rather than the more common using command. We find it better to keep the project organized, but feel free to use whatever is more convenient for you!","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import Bayesian inference package\nimport BayesFitness\n\n# Import libraries to manipulate data\nimport DataFrames as DF\nimport CSV","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"After having imported the libraries, we need to load our dataset into memory. This dataset is already in the format needed for BayesFitness.jl to work, so we don't have to modify anything.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import data\ndata = CSV.read(\"~/git/BayesFitness/test/data/data_example_01.csv\", DF.DataFrame)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Here you will replace \"~/git/BayesFitness/test/data\" with the directory where your data is stored, and \"data_example_01.csv\" with the name of the file containing the data. The resulting DataFrame looks something like this:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"| BCID_x | barcode                                               | name                    | count | time | neutral | count_sum  |\n|--------|-------------------------------------------------------|-------------------------|-------|------|---------|------------|\n| 0      | TGATCAATCTACAAAAATATTTAATG_GAGTGAAACATGAATGGTATTCATCA | Batch1_1Day-T0_combined | 53    | 0    | FALSE   | 543947     |\n| 1      | CCGCCAATCCCGAACCCCGTTTCGCC_ACTCTAACGTGTAACTAATTTTGAGT | Batch1_1Day-T0_combined | 1213  | 0    | FALSE   | 543947     |\n| 2      | GACAGAAAAGCCAAATGGATTTACCG_ATGGGAACACGGAATGATCTTTTATT | Batch1_1Day-T0_combined | 17    | 0    | FALSE   | 543947     |\n| 3      | CCAACAAAACACAAATCTGTTGTGTA_TACTAAATAAGTAAGGGAATTCTGTT | Batch1_1Day-T0_combined | 19    | 0    | FALSE   | 543947     |\n| 4      | TATCGAAACCCAAAGAGATTTAATCG_ATGACAAACTTTAAATAATTTAATTG | Batch1_1Day-T0_combined | 23    | 0    | FALSE   | 543947     |\n| 5      | TATCGAAACCCAAAGAGATTTAATCG_CGATCAAAGACTAACTTATTTTGTGG | Batch1_1Day-T0_combined | 16    | 0    | FALSE   | 543947     |\n| 6      | TATCGAAACCCAAAGAGATTTAATCG_TTGCCAAGCTGGAAAGCTTTTTATGA | Batch1_1Day-T0_combined | 12    | 0    | FALSE   | 543947     |\n| 7      | ATCACAATAACTAAACTGATTCTTCA_CTCATAACATCAAAAAAAATTCAAAT | Batch1_1Day-T0_combined | 161   | 0    | FALSE   | 543947     |\n| 8      | TATCGAAACCCAAAGAGATTTAATCG_GTTTAAACCATTAATTATATTAGATC | Batch1_1Day-T0_combined | 19    | 0    | FALSE   | 543947     |","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The relevant columns in this data frame are:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"barcode: The unique ID that identifies the barcode.\ncount: The number of reads for this particular barcode.\ntime: The time point ID indicating the order in which samples were taken.\nneutral: Indicator of whether the barcode belongs to a neutral lineage or not.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Let's take a look at the data. The BayesFitness.viz module has several Makie.jl-based functions to easily display the data. Let's import the necessary plotting libraries","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import plotting libraries\nusing CairoMakie\nimport ColorSchemes","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"First, we plot the barcode frequency trajectories. For this, we use the convenient BayesFitness.viz.bc_time_series! function.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"barcode frequency\",\n    yscale=log10,\n    title=\"frequency trajectories\"\n)\n\n# Plot Mutant barcode trajectories with varying colors\nBayesFitness.viz.bc_time_series!(\n    ax,\n    data[.!data.neutral, :];\n    quant_col=:freq,\n    zero_lim=1E-9,\n    zero_label=\"extinct\",\n    alpha=0.25,\n    linewidth=2\n)\n\n# Plot Neutral barcode trajectories with a single dark blue color\nBayesFitness.viz.bc_time_series!(\n    ax,\n    data[data.neutral, :];\n    quant_col=:freq,\n    zero_lim=1E-9,\n    color=ColorSchemes.Blues_9[end],\n    alpha=0.9,\n    linewidth=2\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We highlight the neutral barcodes⸺defined to have relative fitness s^(n)=0⸺with dark blue lines. The rest of the light-color lines correspond to individual barcodes.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can rewrite Eq. (1) as","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"frac1tau ln fracf_t+1^(b)f_t^(b) = \nleft(s^(b) - bars_t right)\ntag2","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"In this form, we can se that the relevant quantity we need to infer the values of the population mean fitness bars_t and the barcode relative fitness s^(b) are not the frequencies themselves, but the log ratio of these frequencies between two adjacent time points. Let's plot this log frequency ratio using the BayesFitness.viz.logfreq_ratio_time_series! function.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"ln(fₜ₊₁/fₜ)\",\n    title=\"log-frequency ratio\"\n)\n\n# Plot log-frequency ratio of mutants with different colors\nBayesFitness.viz.logfreq_ratio_time_series!(\n    ax,\n    data[.!data.neutral, :];\n    freq_col=:freq,\n    alpha=0.25,\n    linewidth=2\n)\n\n# Plot log-frequency ratio of neutrals with a single dark blue color\nBayesFitness.viz.logfreq_ratio_time_series!(\n    ax,\n    data[data.neutral, :];\n    freq_col=:freq,\n    color=ColorSchemes.Blues_9[end],\n    alpha=1.0,\n    linewidth=2\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nWe expect is to see these log-frequency ratios as relatively flat lines. Especially for the neutral lineages.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"#Inferring-the-population-mean-fitness","page":"BayesFitness","title":"Inferring the population mean fitness","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"With the data in hand, our first task is to infer the population mean fitness using the neutral lineages. For this, we use the BayesFitness.mcmc.mcmc_mean_fitness function from the mcmc module. The main parameters we need to define are:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":":data: Tidy data frame containing the raw barcode counts.\n:n_walkers: Number of MCMC chains to run in parallel. NOTE: Having multiple chains run in parallel is convenient for diagnostics. BayesFitness.jl will use the available threads, so make sure you have more than one thread in your julia session if you want to run this inference in a multi-threaded way.\n:outputdir: String pointing to the output directory.\noutputname: String defining the pattern for the output files. This can be something related to the dataset. For example, the growth media, or the date of the experiment, of whatever metadata used to distinguish different datasets.\nmodel: Bayesian model from the model module that defines the posterior distribution to be sampled.\nmodel_kwargs: The parameters required by the model function.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We compile all of these parameters into a dictionary that looks something like this:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define dictionary with necessary parameters for MCMC sampling of the \n# population mean fitness\nparam = Dict(\n    :data => data, \n    :n_walkers => 3, \n    :n_steps => 1_000,\n    :outputdir => \"./output/\",\n    :outputname => \"data_01_meanfitness\",\n    :model => BayesFitness.model.mean_fitness_neutrals_lognormal,\n    :model_kwargs => Dict(\n        :α => BayesFitness.stats.dirichlet_prior_neutral(\n            data[data.time.==0, :neutral],\n        )\n    )\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We are now ready to sample the posterior distribution for the population mean fitness. mcmc makes this extremely easy by using the BayesFitness.mcmc.mcmc_mean_fitness function. All we have to do is run","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Run inference\nBayesFitness.mcmc.mcmc_mean_fitness(; param...)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The output of this function are .jld2 files that save the native data structure with the MCMC samples for each pair of adjacent timepoints. To extract the MCMC samples of the variable we care about⸺equivalent to marginalizing out all the nuisance variables⸺we can use the BayesFitness.utils.jld2_concat_chains from the utils module, indicating the name of the variable we want to extract. What this function does is to search for all .jld2 files in the directory that have a particular pattern in their filename, extracts the MCMC samples for the requested variable (the mean fitness in our case) and compiles them into a data frame, where each column represents the variable extracted from each file.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Concatenate population mean fitness chains into single chain\nchains = BayesFitness.utils.jld2_concat_chains(\n    \"./output/\", \"data_01_meanfitness\", [:sₜ]; id_str=\"\"\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"info: Info\nMake sure to check all of the functions in the BayesFitness.utils module that help you extract the information from the MCMC samples.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To diagnose the inference of these population mean fitness values, it is useful to plot both the MCMC traces for each walker as well as the resulting density plots. To do this, we feed the chains  data structure to the BayesFitness.viz.mcmc_trace_density! function to automatically generate these plots.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(600, 600))\n\n# Generate mcmc_trace_density! plot\nBayesFitness.viz.mcmc_trace_density!(fig, chains; alpha=0.5)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nWhat we want to see from these plots is that the traces all look relatively similar, with no big gaps where the walker got stuck. Furthermore, we want to see that all the densities converged to very similar-looking distributions. That is indeed the case for our dataset. Moreover, the densities look fairly symmetric, so should be able to parametrize the resulting posterior distribution as a Gaussian for our next step in the inference.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Another way of assessing the output of this inference step is to plot the posterior predictive checks against the data. The logic behind the posterior predictive checks is the following: before performing the inference on the parameters we seek to learn form the data, we have a prior belief of what those values can be encoded in our prior distribution. We update this prior belief after observing the experimental data given our likelihood function that captures our model for the data generation process. Thus, the posterior distribution of the parameter values contains our updated belief for what the parameter values can be. Therefore, we can sample out of this parameter posterior distribution and feed such parameters to our likelihood function to generate synthetic data. The expectation is that this simulated data should capture the range of experimental data we observed if the model and the inferred parameters describe the data generation process.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"For this particular case of the population mean fitness, we can use the BayesFitness.stats.logfreq_ratio_mean_ppc from the stats module to compute the posterior predictive checks. What this function does is to generate samples for the log-frequency ratios used to infer the population mean fitness values.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"info: Info\nNote that the BayesFitness.stats.logfreq_ratio_mean_ppc function has methods to work with either MCMCChains.Chains objects or with tidy DataFrames.DataFrame. This allows you to use the data structure you are more comfortable working with.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Name of variables to be extracted from the output MCMC chains on multiple \n# .jld2 files\nchain_vars = [:sₜ, :σₜ]\n\n# Extract variables into single chain object\nchains = BayesFitness.utils.jld2_concat_chains(\n    param[:outputdir], param[:outputname], chain_vars; id_str=\"\"\n)\n\n# Define number of posterior predictive check samples\nn_ppc = 5_000\n\n# Define dictionary with corresponding parameters for variables needed for the\n# posterior predictive checks\nparam = Dict(\n    :population_mean_fitness => :sₜ,\n    :population_std_fitness => :σₜ,\n)\n\n# Compute posterior predictive checks\nppc_mat = BayesFitness.stats.logfreq_ratio_mean_ppc(\n    chains, n_ppc; param=param\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Once we generate these samples, we can plot the quantiles of the simulated data with different shades. The BayesFitness.viz.ppc_time_series! function from the viz module makes this plotting really simple. Let us plot the standard 68-95-97.5 percentiles with different shades of blue and then add the data on top of these shaded areas","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nWhat we expect from this plot is to see that most of the experimental data falls within the range of the simulated data, meaning that the model and the inferred parameters can reproduce the range of our observations.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"ln(fₜ₊₁/fₜ)\",\n    title=\"log-frequency ratio PPC\"\n)\n\n# Define quantiles to compute\nqs = [0.68, 0.95, 0.997]\n\n# Define range of colors for each quantile colors\ncolors = get(ColorSchemes.Blues_9, LinRange(0.25, 0.75, length(qs)))\n\n# Plot posterior predictive check quantiles\nBayesFitness.viz.ppc_time_series!(\n    ax, qs, ppc_mat; colors=colors\n)\n\n# Add plot for median (we use the 5 percentile to have a \"thicker\" line showing\n# the median)\nBayesFitness.viz.ppc_time_series!(\n    ax, [0.05], ppc_mat; colors=ColorSchemes.Blues_9[end:end]\n)\n\n# Plot log-frequency ratio of neutrals\nBayesFitness.viz.logfreq_ratio_time_series!(\n    ax,\n    data[data.neutral, :];\n    freq_col=:freq,\n    color=:black,\n    alpha=1.0,\n    linewidth=2\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"This plot shows that the range of inferred population mean fitnesses does capture the log-frequency ratios of the neutral lineages. Therefore, we can confidently move to the next stage of our inference pipeline.","category":"page"},{"location":"#Inferring-mutants'-relative-fitness","page":"BayesFitness","title":"Inferring mutants' relative fitness","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Once we make sure that the population mean fitness looks okay, we can tackle the inference of each mutant relative fitness. The process is very similar, the main difference being that we use the results from the previous step as part of the inputs that go into the corresponding Bayesian model defined in the model module. More specifically, the inferred population mean fitness enters our inference as a \"prior\" on this value. However, we cannot feed the raw output of the MCMC samples we obtained from the previous step as a prior; this prior distribution has to be parametrized. Since our density plots look fairly symmetric, we assume we can parametrize the population mean fitness values as a Gaussian distribution. Thus, we need to fit a Gaussian distribution for each MCMC chain sampled in the previous section. The BayesFitness.stats.gaussian_prior_mean_fitness function in the stats module can help us with this.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"info: Info\nNote that the BayesFitness.stats.gaussian_prior_mean_fitness function has methods to work with either MCMCChains.Chains objects or with tidy DataFrames.DataFrame. This allows you to use the data structure you are more comfortable working with.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Extract mean fitness MCMC chains\nmean_fitness_chains = BayesFitness.utils.jld2_concat_chains(\n    \"./output/\", \"data_01_meanfitness\", [:sₜ]; id_str=\"\"\n)\n\n# Infer mean fitness distribution parameters by fitting a Gaussian\nmean_fitness_dist = BayesFitness.stats.gaussian_prior_mean_fitness(\n    mean_fitness_chains\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To assess whether assuming a parametrized Gaussian distribution can described the MCMC chains from the previous section, we need to visually compare both distributions. An effective way to do this is to compare the empirical cumulative distribution function (ecdf) built from the MCMC samples with the parametric cumulative distribution function (cdf) we obtain from fitting the Gaussian distributions. The BayesFitness.viz.mcmc_fitdist_cdf! function from does exactly this. Let's plot this comparison for all four inferred population mean fitness values from the previous section","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Infer mean fitness distributions by fitting a Gaussian\nfit_dists = BayesFitness.stats.gaussian_prior_mean_fitness(\n    mean_fitness_chains,\n    params=false\n)\n\n# Initialize figure\nfig = Figure(resolution=(600, 600))\n\n# Add axis objects for each timepoint\naxes = [\n    Axis(\n        fig[i, j],\n        xlabel=\"population mean fitness (s̄ₜ)\",\n        ylabel=\"ecdf\",\n    ) for i = 1:2 for j = 1:2\n]\n\n# Loop through time points\nfor (i, var) in enumerate(names(mean_fitness_chains))\n    # Plot ECDF\n    BayesFitness.viz.mcmc_fitdist_cdf!(\n        axes[i],\n        Array(mean_fitness_chains[var])[:],\n        fit_dists[i]\n    )\n\n    axes[i].title = \"timepoint $(i)\"\nend # for","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nIf the population mean fitness can be parametrized as a Gaussian distribution, there should be minimal differences between the mcmc chain and the fit distribution as shown in the figure above.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can now define the dictionary containing the parameters that go into the [BayesFitness.mcmc.mcmc_mutant_fitness] function from the mcmc module. ","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nThe BayesFitness.mcmc.mcmc_mutant_fitness function has two multi-threading modalities: multithread_chain and multithread_mutant. Only one of them can be active at any moment. The multithread_chain  samples multiple chains for a single mutant at the time in a multithread fashion. The multithread_mutant samples multiple mutants at the time, with one chain per thread.On the one hand, if you only have ≈ 4 threads available in your computer, you might want to use multithread_chain to sample 3-4 chains per mutant in parallel. On the other hand, if you have > 4 threads available, running  multithread_mutant can significantly speedup your computation; especially if you have ≥ 8 threads available.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define function parameters\nparam = Dict(\n    :data => data,\n    :n_walkers => 3,\n    :n_steps => 1_000,\n    :outputdir => \"./output/\",\n    :outputname => \"data_01_mutantfitness\",\n    :model => BayesFitness.model.mutant_fitness_lognormal,\n    :model_kwargs => Dict(\n        :α => BayesFitness.stats.beta_prior_mutant(\n            data[data.time.==0, :barcode],\n        ),\n        :μ_s̄ => mean_fitness_dist[1],\n        :σ_s̄ => mean_fitness_dist[2],\n    ),\n    :multithread_mutant => true,\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Finally, we run the inference.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Run inference in a multithread fashion\nBayesFitness.mcmc.mcmc_mutant_fitness(; param...)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"This function generates .jld2 files with the MCMC chains for each of the mutant barcodes. Let's look at an example inference. We will specifically load the inference for the barcode that reached the highest count throughout the experiment. For this, we use the Glob.jl library to locate the corresponding .jld2 file. .jld2 files store multiple Julia objects as dictionary. In our case, a single object named \"chain\" was saved on this file, so when loading the file, we index this single object.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Find barcode with maximum count\nbc = data[first(argmax(data.count, dims=1)), :barcode]\n\n# Select file to process\nfile = first(\n    Glob.glob(\"$(param[:outputdir])/$(param[:outputname])*$(bc).jld2\")\n)\n\n# Load one of the files as an example\nchain = JLD2.load(file)[\"chain\"]","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"As a first diagnostic, let's look at the trace and density plots for the mutant fitness and the likelihood standard deviation.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Name variables to be extracted from chains\nchain_vars = [Symbol(\"s⁽ᵐ⁾\"), Symbol(\"σ⁽ᵐ⁾\")]\n\n# Extract variables from chain\nchn = chain[chain_vars]\n\n# Initialize figure\nfig = Figure(resolution=(600, 350))\n\n# Generate mcmc_trace_density! plot\nBayesFitness.viz.mcmc_trace_density!(fig, chn; alpha=0.5)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can see that the mutant fitness is centered around 1.5. But the Bayesian analysis gives us a principled way to estimate the uncertainty on this estimate.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To make sure the inferred fitness value agrees with the experimental data, we must generate posterior predictive (retrodictive) checks. For this we need to extract the necessary information from the mcmc_chain object. In particular, we are interested in the mcmc traces for the mutant fitness (named :s⁽ᵐ⁾ in the chain), all of the population mean fitness traces (named :s̲ₜ[i] in the chain, where i indexes the time point), the standard deviation for the mutant fitness (named :σ⁽ᵐ⁾ in the chain), and the initial barcode frequency (named :f̲⁽ᵐ⁾[1] in the chain).","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Name variables to be extracted from chains\nchain_vars = [Symbol(\"s⁽ᵐ⁾\"), Symbol(\"σ⁽ᵐ⁾\"), Symbol(\"f̲⁽ᵐ⁾[1]\"), :s̲ₜ]\n\n# Locate variable names to extract from chain and append them into a single \n# vector\nchain_names = reduce(\n    vcat, [MCMCChains.namesingroup(chain, var) for var in chain_vars]\n)\n\n# Extract chain variables\nchn = chain[chain_names]","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We also need to extract the actual measurements for the specific barcode we are looking as an example. This can easily be extracted from our tidy data frame.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Extract data for barcode example\ndata_bc = data[data.barcode.==bc, :]\n\n# Sort data by time\nDF.sort!(data_bc, :time)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"With these variables in hand, we can generate some posterior predictive checks for the barcode frequency trajectories. To generate these samples we use the BayesFitness.stats.freq_mutant_ppc function that takes a chain (or a tidy dataframe) as an input with MCMC chains for the following variables:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The mutant mean fitness s^(m).\nThe standard deviation from the mutant fitness inference likelihood function sigma^(m).\nThe initial frequency for the mutant f^(m)_0.\nThe corresponding population mean fitness values for each time point where the data was taken underlinebars_t.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define number of posterior predictive check samples\nn_ppc = 5_000\n\n# Define dictionary with corresponding parameters for variables needed for the\n# posterior predictive checks\nparam = Dict(\n    :mutant_mean_fitness => :s⁽ᵐ⁾,\n    :mutant_std_fitness => :σ⁽ᵐ⁾,\n    :mutant_freq => Symbol(\"f̲⁽ᵐ⁾[1]\"),\n    :population_mean_fitness => :s̲ₜ,\n)\n\n# Compute posterior predictive checks\nppc_mat = BayesFitness.stats.freq_mutant_ppc(\n    chn,\n    n_ppc;\n    param=param\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Next, we can use the BayesFitness.viz.ppc_time_series! function to plot these posterior predictive checks to compare it with the frequency trajectory measured experimentally.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"barcode frequency\",\n    title=\"frequency trajectories\",\n    yscale=log10,\n)\n\n# Define quantiles to compute\nqs = [0.95, 0.675]\n\n# Define colors\ncolors = get(ColorSchemes.Blues_9, LinRange(0.5, 0.75, length(qs)))\n\n# Plot posterior predictive checks\nBayesFitness.viz.ppc_time_series!(\n    ax, qs, ppc_mat; colors=colors\n)\n\n# Add plot for median\nBayesFitness.viz.ppc_time_series!(\n    ax, [0.03], ppc_mat; colors=ColorSchemes.Blues_9[end:end]\n)\n\n# Add scatter of data\nscatterlines!(ax, data_bc.freq, color=:black)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nIn the previous plot, the credible region expands as time progresses in the experiment. This is to be expected as the uncertainty is propagated over time with new sources of uncertainty added at each time point. But notice that the experimental frequency trajectory falls within the highest probability region.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Another way to visualize the agreement between our inferred parameters and the data is to look at the quantity used directly on the inference of the fitness value, i.e., the log frequency ratio between two adjacent time points. For this we can use the BayesFitness.stats.logfreq_ratio_mutant_ppc function to compute the posterior predictive checks. The difference between this function and the previously used BayesFitness.stats.freq_mutant_ppc is that the log frequency ratio function does not require the inferred initial frequency of the mutant as an input since we are only looking at the log log frequency ratio.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Name variables to be extracted from chains\nchain_vars = [Symbol(\"s⁽ᵐ⁾\"), Symbol(\"σ⁽ᵐ⁾\"), :s̲ₜ]\n\n# Locate variable names to extract from chain\nchain_names = reduce(\n    vcat, [MCMCChains.namesingroup(chain, var) for var in chain_vars]\n)\n\n# Extract chain variables\nchn = chain[chain_names]\n\n# Define number of posterior predictive check samples\nn_ppc = 5_000\n\n# Define dictionary with corresponding parameters for variables needed for the\n# posterior predictive checks\nparam = Dict(\n    :mutant_mean_fitness => :s⁽ᵐ⁾,\n    :mutant_std_fitness => :σ⁽ᵐ⁾,\n    :population_mean_fitness => :s̲ₜ,\n)\n\n# Compute posterior predictive checks\nppc_mat = BayesFitness.stats.logfreq_ratio_mutant_ppc(\n    chn, n_ppc; param=param\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Again, we can use the BayesFitness.viz.ppc_time_series! function to plot the quantiles for our posterior predictive checks.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"ln(fₜ₊₁/fₜ)\",\n    title=\"log-frequency ratio PPC\"\n)\n\n# Define quantiles to compute\nqs = [0.95, 0.675]\n\n# Define colors\ncolors = get(ColorSchemes.Blues_9, LinRange(0.5, 0.75, length(qs)))\n\n# Plot posterior predictive checks\nBayesFitness.viz.ppc_time_series!(\n    ax, qs, ppc_mat; colors=colors\n)\n\n# Add plot for median (we use the 5 percentile to have a \"thicker\" line showing\n# the median)\nBayesFitness.viz.ppc_time_series!(\n    ax, [0.05], ppc_mat; colors=ColorSchemes.Blues_9[end:end]\n)\n\n# Add scatter of data\nscatterlines!(ax, diff(log.(data_bc.freq)), color=:black)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can see that indeed the recovered fitness value greatly agrees with the data.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"This concludes the example inference pipeline. We invited you to explore more the potential in the package and please send any comments/requests through the GitHub repository issues.","category":"page"},{"location":"#Contents","page":"BayesFitness","title":"Contents","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"","category":"page"},{"location":"utils/#utils","page":"utils","title":"utils","text":"","category":"section"},{"location":"utils/","page":"utils","title":"utils","text":"Modules = [BayesFitness.utils]\nOrder   = [:function, :type]","category":"page"},{"location":"utils/#BayesFitness.utils.concat_chains-Tuple{Vector{<:MCMCChains.Chains}, Vector{Symbol}}","page":"utils","title":"BayesFitness.utils.concat_chains","text":"`concat_chains(chains, var_pattern, id_str)`\n\nFunction that concatenates multiple MCMCChains.Chains objects into a single one. This function takes a vector of MCMCChains.Chains as inputs, extracts the variables that match the patterns in the array var_pattern, and appends all extracted variables into a single chain adding a pattern of the form [$(id_str)i], where i is the file number. For example, if two chains contain a variable named var, the new chain returned by this function names them as var[f1] and var[f2] if id_str=f.\n\nNOTE: All chains must have the same number of samples to be concatenated.\n\nArguments\n\nchains::Vector{<:MCMCChains.Chains}: Vector with the chains to be concatenated into a single chain.\nvar_pattern::Vector{Symbol}: Patterns that variables must follow to be extracted from the chain. For example, if several variables are named var[1], var[2], etc, providing a pattern [var] extracts all of them, while providing var[1] extracts only the one that perfectly matches this pattern.\n\nOptional arguments\n\nid_str::String=f: String to be attached to the variable names that identifies the different chains being concatenated. For example, if 4 chains are being concatenated, each repeated variable will be named var[$(id_str)i] to distinguish each of them.\n\nReturns\n\nMCMCChains.Chains: Chain with the requested variables from multiple files concatenated into a single object.\n\n\n\n\n\n","category":"method"},{"location":"utils/#BayesFitness.utils.group_split-Tuple{DataFrames.AbstractDataFrame, Int64, Symbol, Symbol}","page":"utils","title":"BayesFitness.utils.group_split","text":"group_split(data, n_groups, groupby_col, count_col; sort_function)\n\nFunction to split a set of labels into n_group subgroups.\n\nArguments\n\ndata::DF.AbstractDataFrame: Data to be split into groups. This function   expects a tidy dataframe with at least two columns:\ngroupby_col: Column to group entries by. This is commonly the barcode ID that distinguishes different strains.\nsort_col: Column with values used to sort the data entries.\nn_groups::Int: Number of groups in which to split the data\ngroupby_col::Symbol: Name of column used to group the unique entries in dataset. This is commonly the barcode ID that distinguishes different strains.\nsort_col::Symbol: Name of column with quantity used to sort the entries in the dataset. This is commonly the number of barcode counts or frequency.\n\nOptional Keyword Arguments\n\nsort_function::Function=x -> StatsBase.mean(log.(x .+ 1)): Functio to use on the group-apply-combine routine. The default function computes the mean in log-scale, adding a 1 to avoid computing log(0).\n\nReturns\n\ngroups::Vector{Vector{typeof(data[groupby_col][1])}}: Vectors containing the different groups in which to split the dataset.\n\n\n\n\n\n","category":"method"},{"location":"utils/#BayesFitness.utils.group_split_naive_fitness-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"utils","title":"BayesFitness.utils.group_split_naive_fitness","text":"group_split(data, n_groups; kwargs)\n\nFunction to split a set of labels into n_group subgroups sorted by a naive estimate of the fitness value.\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to infer the fitness values on mutants. The DataFrame must contain at least the following columns:     - id_col: Column identifying the ID of the barcode. This can the barcode     sequence, for example.     - time_col: Column defining the measurement time point.     - count_col: Column with the raw barcode count.     - neutral_col: Column indicating whether the barcode is from a neutral     lineage or not.\n\nn_groups::Int: Number of groups in which to split the data.\n\nOptional Keyword Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the\n\ninference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\n\npseudo_count::Int=1: Pseudo count number to add to all counts. This is useful to avoid divisions by zero.\n\nReturns\n\ngroups::Vector{Vector{typeof(data[groupby_col][1])}}: Vectors containing the\n\ndifferent groups in which to split the dataset.\n\n\n\n\n\n","category":"method"},{"location":"utils/#BayesFitness.utils.jld2_concat_chains-Tuple{String, String, Vector{Symbol}}","page":"utils","title":"BayesFitness.utils.jld2_concat_chains","text":"`jld2_concat_chains(dir, file_patern, chains, var_pattern, id_str)`\n\nConvenient function that peforms the same concatenation as BayesFitness.utils.concat_chains but giving a directory and a file pattern for jld2 files storing the chains. This function reads all files in dir that have the pattern file pattern, obtaining a list of MCMCChains.Chains as inputs. It then extracts the variables that match the patterns in the array var_pattern, and appends all extracted variables into a single chain adding a pattern of the form [$(id_str)i], where i is the file number. For example, if two chains contain a variable named var, the new chain returned by this function names them as var[f1] and var[f2] if id_str=f.\n\nNOTE: All chains must have the same number of samples to be concatenated.\n\nArguments\n\ndir::String: Directory where file(s) with MCMC chains are stored.\nfile_pattern::String: Pattern common among all files to process. NOTE: This is use in the Glob.glob command to locate all jld2 files from which to extract the chains.\nvar_pattern::Vector{Symbol}: Patterns that variables must follow to be extracted from the chain. For example, if several variables are named var[1], var[2], etc, providing a pattern [var] extracts all of them, while providing var[1] extracts only the one that perfectly matches this pattern.\n\nOptional arguments\n\nid_str::String=f: String to be attached to the variable names that identifies the different chains being concatenated. For example, if 4 chains are being concatenated, each repeated variable will be named var[$(id_str)i] to distinguish each of them.\n\nReturns\n\nMCMCChains.Chains: Chain with the requested variables from multiple files concatenated into a single object.\nchainname::String=\"chain\": String defining the dictionary key on the .jld2\n\nfile to extract the MCMC chain.\n\n\n\n\n\n","category":"method"}]
}
