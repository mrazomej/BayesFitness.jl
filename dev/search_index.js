var documenterSearchIndex = {"docs":
[{"location":"mcmc/#mcmc","page":"mcmc","title":"mcmc","text":"","category":"section"},{"location":"mcmc/","page":"mcmc","title":"mcmc","text":"Modules = [BayesFitness.mcmc]\nOrder   = [:function, :type]","category":"page"},{"location":"mcmc/#BayesFitness.mcmc.mcmc_sample-Tuple{}","page":"mcmc","title":"BayesFitness.mcmc.mcmc_sample","text":"Function to sample the joint posterior distribution for the fitness value of all     mutant and neutral linages given a time-series barcode count.\n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode   sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage\n\nor not.\n\nKeyword Arguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to sample from the population mean fitness posterior distribution.\n\nn_walkers::Int: Number of walkers (chains) for the MCMC sample.\nn_steps::Int: Number of steps to take.\noutputname::String: String to be used to name the .jld2 output file.\nmodel::Function: Turing.jl model defining the posterior distribution from   which to sample (see BayesFitness.model module). This function must take   as the first four inputs the following:\nR̲̲::Array{Int64}:: 2 or 3D array containing the raw barcode counts for all tracked genotypes. The dimensions of this array represent:\ndim=1: time.\ndim=2: genotype.\ndim=3 (optional): experimental repeats\nn̲ₜ::VecOrMat{Int64}: Array with the total number of barcode counts for   each time point (on each experimental repeat, if necessary).\nn_neutral::Int: Number of neutral lineages.\nn_mut::Int: Number of neutral lineages.\n\nOptional Keyword Arguments\n\nmodel_kwargs::Dict=Dict(): Extra keyword arguments to be passed to the   model function.\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point   at which measurements were done. The column may contain any type of entry as   long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw   barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether   the barcode belongs to a neutral lineage or not. The column must contain   entries of type Bool.\nrep_col::Union{Nothing,Symbol}=nothing: Optional column in tidy dataframe to specify the experimental repeat for each observation.\nrm_T0::Bool=false: Optional argument to remove the first time point from the   inference. Commonly, the data from this first time point is of much lower   quality. Therefore, removing this first time point might result in a better   inference.\nsampler::Turing.Inference.InferenceAlgorithm=Turing.NUTS(0.65): MCMC sampler   to be used.\nensemble::Turing.AbstractMCMC.AbstractMCMCEnsemble=Turing.MCMCSerial():\n\nSampling modality to be used. Options are:     - Turing.MCMCSerial()     - Turing.MCMCThreads()     - Turing.MCMCDistributed()\n\nverbose::Bool=true: Boolean indicating if the function should print partial   progress to the screen or not.\n\n\n\n\n\n","category":"method"},{"location":"model/#model","page":"model","title":"model","text":"","category":"section"},{"location":"model/","page":"model","title":"model","text":"Modules = [BayesFitness.model]\nOrder   = [:function, :type]","category":"page"},{"location":"model/#BayesFitness.model.exprep_fitness_lognormal-Tuple{Array{Int64, 3}, Matrix{Int64}, Int64, Int64}","page":"model","title":"BayesFitness.model.exprep_fitness_lognormal","text":"exprep_fitness_lognormal(R̲̲, n̲ₜ, n_neutral, n_mut; kwargs)\n\nTuring.jl model to sample the joint posterior distribution for a competitive fitness experiment.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲::Array{Int64, 3}:: T × B × R where T is the number of time points in the data set, B is the number of barcodes, and R is the number of experimental replicates. For each slince in the R axis, each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Matrix{Int64}: Matrix with the total number of barcode counts for each time point on each replicate. NOTE: This matrix must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\nn_neutral::Int: Number of neutral lineages in dataset.\nn_mut::Int: Number of mutant lineages in datset.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] =   standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] =   standard deviation) for a Normal prior on the population mean fitness   values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.\nσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the   correspnding parameters (Vector: σ_pop_prior[1] = mean, σ_pop_prior[2] =   standard deviation, Matrix: σ_pop_prior[:, 1] = mean, σ_pop_prior[:, 2] =   standard deviation) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If typeof(σ_pop_prior) <:   Matrix, there should be as many rows in the matrix as pairs of time   adjacent time points × number of replicates in dataset.\ns_mut_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] =   standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] =   standard deviation) for a Normal prior on the mutant fitness values. If   typeof(s_mut_prior) <: Matrix, there should be as many rows in the matrix   as number of mutant lineages × number of replicates in the dataset.\nσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(σ_mut_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of replicates in the dataset.\nλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the correspnding parameters (Vector: λ_prior[1] = mean, λ_prior[2] = standard deviation, Matrix: λ_prior[:, 1] = mean, λ_prior[:, 2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(λ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points × number of replicates in the dataset.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.exprep_fitness_normal-Tuple{Array{Int64, 3}, Matrix{Int64}, Int64, Int64}","page":"model","title":"BayesFitness.model.exprep_fitness_normal","text":"exprepfitnessnormal(R̲̲::Matrix{Int64}, n̲ₜ::Vector{Int64}, nneutral::Int,                       nmut::Int; kwargs...)\n\nDefines a hierarchical model to estimate fitness effects in a competitive fitness experiment across growth-dilution cycles over multiple experimental replicates. \n\nArguments\n\nR̲̲::Array{Int64, 3}:: T × B × R where T is the number of time points in the data set, B is the number of barcodes, and R is the number of experimental replicates. For each slice in the R axis, each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Matrix{Int64}: Matrix with the total number of barcode counts for each time point on each replicate. NOTE: This matrix must be equivalent to computing vec(sum(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset.  \nn_mut::Int: Number of mutant lineages in dataset.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points in dataset.  \nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] = standard deviation, Matrix: logσ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points × number of replicates in dataset.\ns_mut_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness values. If typeof(s_mut_prior) <: Matrix, there should be as many rows in the matrix as number of mutant lineages × number of replicates in the dataset. \nlogσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(logσ_mut_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of replicates in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the corresponding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(logλ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points × number of replicates in the dataset.\n\nLatent Variables\n\nPopulation mean fitness per timepoint.\nMutant hyper-fitness effects. \nMutant fitness effects per experimental replicate.\nλ dispersion parameters per barcode and timepoint.\n\nNotes\n\nModels hyper-fitness effects as normally distributed.\nModels fitness effects as normally distributed.\nUtilizes a Poisson observation model for barcode counts.  \nSetting informative priors is recommended for stable convergence.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.fitness_lognormal-Tuple{Matrix{Int64}, Vector{Int64}, Int64, Int64}","page":"model","title":"BayesFitness.model.fitness_lognormal","text":"fitness_lognormal(R̲̲, n̲ₜ, n_neutral, n_mut; kwargs)\n\nTuring.jl model to sample the joint posterior distribution for a competitive fitness experiment.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲::Matrix{Int64}:: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\nn_neutral::Int: Number of neutral lineages in dataset.\nn_mut::Int: Number of mutant lineages in datset.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] =   standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] =   standard deviation) for a Normal prior on the population mean fitness   values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.\nσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the   correspnding parameters (Vector: σ_pop_prior[1] = mean, σ_pop_prior[2] =   standard deviation, Matrix: σ_pop_prior[:, 1] = mean, σ_pop_prior[:, 2] =   standard deviation) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If typeof(σ_pop_prior) <:   Matrix, there should be as many rows in the matrix as pairs of time   adjacent time points in dataset.\ns_mut_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] =   standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] =   standard deviation) for a Normal prior on the mutant fitness values. If   typeof(s_mut_prior) <: Matrix, there should be as many rows in the matrix   as mutant lineages in the dataset.\nσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(σ_mut_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages in the dataset.\nλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the correspnding parameters (Vector: λ_prior[1] = mean, λ_prior[2] = standard deviation, Matrix: λ_prior[:, 1] = mean, λ_prior[:, 2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(λ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points in the dataset.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.fitness_normal-Tuple{Matrix{Int64}, Vector{Int64}, Int64, Int64}","page":"model","title":"BayesFitness.model.fitness_normal","text":"fitness_lognormal(R̲̲, n̲ₜ, n_neutral, n_mut; s_pop_prior, logσ_pop_prior, s_mut_prior, logσ_mut_prior, logλ_prior)\n\nTuring.jl model to sample the joint posterior distribution for a competitive fitness experiment.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲::Matrix{Int64}:: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\nn_neutral::Int: Number of neutral lineages in dataset.\nn_mut::Int: Number of mutant lineages in datset.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] =   standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] =   standard deviation) for a Normal prior on the population mean fitness   values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.\nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the   correspnding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] =   standard deviation, Matrix: logσ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] =   standard deviation) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <:   Matrix, there should be as many rows in the matrix as pairs of time   adjacent time points in dataset.\ns_mut_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] =   standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] =   standard deviation) for a Normal prior on the mutant fitness values. If   typeof(s_mut_prior) <: Matrix, there should be as many rows in the matrix   as mutant lineages in the dataset.\nlogσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(logσ_mut_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the correspnding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(logλ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points in the dataset.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.freq_lognormal-Tuple{Matrix{Int64}, Vector{Int64}, Int64, Int64}","page":"model","title":"BayesFitness.model.freq_lognormal","text":"freq_lognormal(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲, n̲ₜ; λ_prior)\n\nTuring.jl model to sample the joint posterior distribution for frequency values on a fitness experiment.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲::Matrix{Int64}:: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\nn_neutral::Int: Number of neutral lineages in dataset. NOTE This argument is irrelevant for this function. It is only included to have consistent inputs across models.\nn_mut::Int: Number of mutant lineages in datset. NOTE This argument is irrelevant for this function. It is only included to have consistent inputs across models.\n\nOptional Keyword Arguments\n\nλ_prior::Vector{Float64}=[3.0, 3.0]: Vector with the corresponding parameters (λ_prior[1] = mean, λ_prior[2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). NOTE: This method assigns   the same prior to all mutant fitness error values to be inferred.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.multienv_exprep_fitness_normal-Tuple{Array{Int64, 3}, Matrix{Int64}, Int64, Int64}","page":"model","title":"BayesFitness.model.multienv_exprep_fitness_normal","text":"multienvexprepfitnessnormal(R̲̲::Matrix{Int64}, n̲ₜ::Vector{Int64},                                nneutral::Int, n_mut::Int; kwargs...)\n\nDefines a hierarchical model to estimate fitness effects in a competitive fitness experiment with different environments across growth-dilution cycles over multiple experimental replicates. \n\nArguments\n\nR̲̲::Array{Int64, 3}:: T × B × R where T is the number of time points in the data set, B is the number of barcodes, and R is the number of experimental replicates. For each slice in the R axis, each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Matrix{Int64}: Matrix with the total number of barcode counts for each time point on each replicate. NOTE: This matrix must be equivalent to computing vec(sum(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset.  \nn_mut::Int: Number of mutant lineages in dataset.\n\nKeyword Arguments\n\nenvs::Vector{<:Any}: List of environments for each time point in dataset. NOTE: The length must be equal to that of the number of rows in n̲t to have one environment per time point.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points in dataset.  \nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] = standard deviation, Matrix: logσ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of time adjacent time points × number of replicates in dataset.\ns_mut_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness values. If typeof(s_mut_prior) <: Matrix, there should be as many rows in the matrix as number of mutant lineages × number of replicates in the dataset. \nlogσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(logσ_mut_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of replicates in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the corresponding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(logλ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points × number of replicates in the dataset.\n\nLatent Variables\n\nPopulation mean fitness per timepoint.\nMutant hyper-fitness effects per environment. \nMutant fitness effects per environment per experimental replicate.\nλ dispersion parameters per barcode and timepoint.\n\nNotes\n\nModels hyper-fitness effects as normally distributed.\nModels fitness effects as normally distributed.\nUtilizes a Poisson observation model for barcode counts.  \nCan estimate time-varying and environment-specific fitness effects.\nSetting informative priors is recommended for stable convergence.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.multienv_fitness_lognormal-Tuple{Matrix{Int64}, Vector{Int64}, Int64, Int64}","page":"model","title":"BayesFitness.model.multienv_fitness_lognormal","text":"multienv_fitness_lognormal(R̲̲, n̲ₜ, n_neutral, n_mut; kwargs)\n\nTuring.jl model to sample the joint posterior distribution for a competitive fitness experiment with different environments on each growth-dilution cycle.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲::Matrix{Int64}:: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\nn_neutral::Int: Number of neutral lineages in dataset.\nn_mut::Int: Number of mutant lineages in datset.\n\nKeyword Arguments\n\nenvs::Vector{<:Any}: List of environments for each time point in dataset. NOTE: The length must be equal to that of n̲ₜ to have one environment per time point.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] =   standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] =   standard deviation) for a Normal prior on the population mean fitness   values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.\nσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the   correspnding parameters (Vector: σ_pop_prior[1] = mean, σ_pop_prior[2] =   standard deviation, Matrix: σ_pop_prior[:, 1] = mean, σ_pop_prior[:, 2] =   standard deviation) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If typeof(σ_pop_prior) <:   Matrix, there should be as many rows in the matrix as pairs of time   adjacent time points in dataset.\ns_mut_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] =   standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] =   standard deviation) for a Normal prior on the mutant fitness values. If   typeof(s_mut_prior) <: Matrix, there should be as many rows in the matrix   as mutant lineages × number of unique environments in the dataset.\nσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the correspnding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If typeof(σ_mut_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of unique environments in the dataset.\nλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the correspnding parameters (Vector: λ_prior[1] = mean, λ_prior[2] = standard deviation, Matrix: λ_prior[:, 1] = mean, λ_prior[:, 2] = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(λ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points in the dataset.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.multienv_fitness_normal-Tuple{Matrix{Int64}, Vector{Int64}, Int64, Int64}","page":"model","title":"BayesFitness.model.multienv_fitness_normal","text":"multienvfitnessnormal(R̲̲::Matrix{Int64}, n̲ₜ::Vector{Int64},                           nneutral::Int, nmut::Int; kwargs...)\n\nDefines a model to estimate fitness effects in a competitive fitness experiment with different environments across growth-dilution cycles.\n\nArguments\n\nR̲̲::Matrix{Int64}:: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage.\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)).\nn_neutral::Int: Number of neutral lineages in dataset. \nn_mut::Int: Number of mutant lineages in dataset.\n\nKeyword Arguments\n\nenvs::Vector{<:Any}: List of environments for each time point in dataset. NOTE: The length must be equal to that of n̲t to have one environment per time point.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] = standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of adjacent time points in dataset.\nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_pop_prior[1] = mean, logσ_pop_prior[2] = standard deviation, Matrix: σ_pop_prior[:, 1] = mean, logσ_pop_prior[:, 2] = standard deviation) for a Normal prior on the population mean fitness log-error utilized in the log-likelihood function. If typeof(logσ_pop_prior) <: Matrix, there should be as many rows in the matrix as pairs of adjacent time points in dataset.  \ns_mut_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the corresponding parameters (Vector: s_mut_prior[1] = mean, s_mut_prior[2] = standard deviation, Matrix: s_mut_prior[:, 1] = mean, s_mut_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness values. If typeof(s_mut_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of unique environments in the dataset.\nlogσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the corresponding parameters (Vector: logσ_mut_prior[1] = mean, logσ_mut_prior[2] = standard deviation, Matrix: logσ_mut_prior[:, 1] = mean, logσ_mut_prior[:, 2] = standard deviation) for a Normal prior on the mutant fitness log-error utilized in the log-likelihood function. If typeof(logσ_mut_prior) <: Matrix, there should be as many rows in the matrix as mutant lineages × number of unique environments in the dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the corresponding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] = standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] = standard deviation) for a Normal prior on the log of the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾). If typeof(λ_prior) <: Matrix, there should be as many rows in the matrix as number of barcodes × number of time points in the dataset.\n\nLatent Variables\n\nPopulation mean fitness per timepoint\nMutant fitness effects per environment\nλ dispersion parameters per barcode and timepoint\n\nNotes\n\nModels fitness effects as normally distributed. \nUtilizes a Poisson observation model for barcode counts.\nCan estimate time-varying and environment-specific fitness effects.  \nSetting informative priors is recommended for stable convergence.\n\n\n\n\n\n","category":"method"},{"location":"model/#BayesFitness.model.neutrals_lognormal","page":"model","title":"BayesFitness.model.neutrals_lognormal","text":"neutrals_lognormal(R̲̲, R̲̲⁽ⁿ⁾, n̲ₜ; s_pop_prior, σ_pop_prior, λ_prior)\n\nTuring.jl model to sample the joint posterior distribution of the population mean fitness for a competitive fitness experiment using only the neutral lineages.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲::Matrix{Int64}:: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\nn_neutral::Int: Number of neutral lineages in dataset.\nn_mut::Int: Number of mutant lineages in datset. NOTE This argument is irrelevant for this function. It is only included to have consistent inputs across models.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] =   standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] =   standard deviation) for a Normal prior on the population mean fitness   values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.\nσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the   correspnding parameters (Vector: σ_pop_prior[1] = mean, σ_pop_prior[2] =   standard deviation, Matrix: σ_pop_prior[:, 1] = mean, σ_pop_prior[:, 2] =   standard deviation) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If typeof(σ_pop_prior) <:   Matrix, there should be as many rows in the matrix as pairs of time   adjacent time points in dataset.\nλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the   correspnding parameters (Vector: λ_prior[1] = mean, λ_prior[2] =   standard deviation, Matrix: λ_prior[:, 1] = mean, λ_prior[:, 2] =   standard deviation) for a Log-Normal prior on the λ parameter in the   Poisson distribution. The λ parameter can be interpreted as the mean number   of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾).   If typeof(λ_prior) <: Matrix, there should be as many rows in the matrix   as number of barcodes × number of time points in the dataset.\n\n\n\n\n\n","category":"function"},{"location":"model/#BayesFitness.model.neutrals_normal","page":"model","title":"BayesFitness.model.neutrals_normal","text":"neutrals_normal(R̲̲, R̲̲⁽ⁿ⁾, n̲ₜ; s_pop_prior, σ_pop_prior, λ_prior)\n\nTuring.jl model to sample the joint posterior distribution of the population mean fitness for a competitive fitness experiment using only the neutral lineages.\n\nModel\n\n[write model here]\n\nArguments\n\nR̲̲::Matrix{Int64}:: T × B matrix–split into a vector of vectors for computational efficiency–where T is the number of time points in the data set and B is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. NOTE: This matrix does not necessarily need to be equivalent to hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾). This is because R̲̲⁽ᵐ⁾ can exclude mutant barcodes to perform the joint inference only for a subgroup, but R̲̲ must still contain all counts. Usually, if R̲̲⁽ᵐ⁾ excludes mutant barcodes, R̲̲ must be of the form hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾), where R̲̲⁽ᴹ⁾ is a vector that aggregates all excluded mutant barcodes into a \"super barcode.\"\nn̲ₜ::Vector{Int64}: Vector with the total number of barcode counts for each time point. NOTE: This vector must be equivalent to computing vec(sum(R̲̲, dims=2)). The reason it is an independent input parameter is to avoid the sum computation within the Turing model.\nn_neutral::Int: Number of neutral lineages in dataset.\nn_mut::Int: Number of mutant lineages in datset. NOTE This argument is irrelevant for this function. It is only included to have consistent inputs across models.\n\nOptional Keyword Arguments\n\ns_pop_prior::VecOrMat{Float64}=[0.0, 2.0]: Vector or Matrix with the   correspnding parameters (Vector: s_pop_prior[1] = mean, s_pop_prior[2] =   standard deviation, Matrix: s_pop_prior[:, 1] = mean, s_pop_prior[:, 2] =   standard deviation) for a Normal prior on the population mean fitness   values. If typeof(s_pop_prior) <: Matrix, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.\nlogσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]: Vector or Matrix with the   correspnding parameters (Vector: logσ_pop_prior[1] = mean,   logσ_pop_prior[2] = standard deviation, Matrix: logσ_pop_prior[:, 1] =   mean, logσ_pop_prior[:, 2] = standard deviation) for a Log-Normal prior   on the population mean fitness error utilized in the log-likelihood   function. If typeof(logσ_pop_prior) <: Matrix, there should be as many   rows in the matrix as pairs of time adjacent time points in dataset.\nlogλ_prior::VecOrMat{Float64}=[3.0, 3.0]: Vector or Matrix with the   correspnding parameters (Vector: logλ_prior[1] = mean, logλ_prior[2] =   standard deviation, Matrix: logλ_prior[:, 1] = mean, logλ_prior[:, 2] =   standard deviation) for a Log-Normal prior on the λ parameter in the   Poisson distribution. The λ parameter can be interpreted as the mean number   of barcode counts since we assume any barcode count n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾).   If typeof(logλ_prior) <: Matrix, there should be as many rows in the   matrix as number of barcodes × number of time points in the dataset.\n\n\n\n\n\n","category":"function"},{"location":"stats/#stats","page":"stats","title":"stats","text":"","category":"section"},{"location":"stats/","page":"stats","title":"stats","text":"Modules = [BayesFitness.stats]\nOrder   = [:function, :type]","category":"page"},{"location":"stats/#BayesFitness.stats.build_getq-Tuple{Any, Any}","page":"stats","title":"BayesFitness.stats.build_getq","text":"Function to build a full-rank distribution to be used for ADVI optimization.\nThe code in this function comes from (`Turing.jl\ntutorial`)[https://turinglang.org/v0.28/tutorials/09-variational-inference/]\n\nArguments\n\ndim::Int: Dimensionality of parameter space.\nmodel::DynamicPPL.model: Turing model to be fit using ADVI.\n\nReturns\n\nInitialized distribution to be used when fitting a full-rank variational model.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.freq_mutant_ppc-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"stats","title":"BayesFitness.stats.freq_mutant_ppc","text":"freq_mutant_ppc(df, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks for the barcode frequency for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables in the mcmc chain defining the following variables:\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\nmutant_freq: Variable defining the inferred initial frequency for the mutant.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if   the model used a normal or lognormal distribution for the likelihood. This   is because when using a normal distribution, the nuisance parameters are   sampled in log scale and need to be exponentiated.\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.freq_mutant_ppc-Tuple{MCMCChains.Chains, Int64}","page":"stats","title":"BayesFitness.stats.freq_mutant_ppc","text":"freq_mutant_ppc(chain, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks for the barcode frequency for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nmutant initial frequency.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables in the mcmc chain defining the following variables:\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\nmutant_freq: Variable defining the inferred initial frequency for the mutant.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if   the model used a normal or lognormal distribution for the likelihood. This   is because when using a normal distribution, the nuisance parameters are   sampled in log scale and need to be exponentiated.\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nfₜ₊₁ = fₜ × exp(s⁽ᵐ⁾ - s̅ₜ)::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_multienv_ppc-Tuple{DataFrames.AbstractDataFrame, Int64, Vector}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_multienv_ppc","text":"logfreq_ratio_mutienv_ppc(df, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\nenvs::Vector{<:Any}: List of environments in experiment. This is used to index the corresponding fitness from the chain. NOTE: The list of environments should be the name or corresponding label of the environemnt; the index is generated internally.\n\nOptional Keyword Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:\n\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if\n\nthe model used a normal or lognormal distribution for the likelihood. This is   because when using a normal distribution, the nuisance parameters are sampled   in log scale and need to be exponentiated.\n\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_multienv_ppc-Tuple{MCMCChains.Chains, Int64, Vector}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_multienv_ppc","text":"logfreqratiomutienvppc(chain, nppc; kwargs)\n\nFunction to compute the posterior predictive checks (better called the posterior retrodictive checks) for the barcode log-frequency ratio for neutral lineages. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(n) = f_t^(n) \n    expleft left( - bars_t right) tau right\n\nwhere bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(n)f_t^(n) sim \n    log-mathcalNleft( - bars_t sigma^(n) right)\n\nwhere sigma^(n) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:     - population_mean_fitness: Common pattern in all population mean fitness     variables.     - population_std_fitness: Common pattern in all standard deviations         estimates for the likelihood.\n\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if the model used a normal or lognormal distribution for the likelihood. This is because when using a normal distribution, the nuisance parameters are sampled in log scale and need to be exponentiated.\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if the model used a normal or lognormal distribution for the likelihood. This is because when using a normal distribution, the nuisance parameters are sampled in log scale and need to be exponentiated.\nflatten::Bool=true: Boolean indicating whether to flatten the output of   multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_mutant_ppc-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_mutant_ppc","text":"logfreq_ratio_mutant_ppc(df, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Keyword Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:\n\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if the model used a normal or lognormal distribution for the likelihood. This is because when using a normal distribution, the nuisance parameters are sampled in log scale and need to be exponentiated.\nflatten::Bool=true: Boolean indicating whether to flatten the output of\n\nmultiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_mutant_ppc-Tuple{MCMCChains.Chains, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_mutant_ppc","text":"logfreq_ratio_mutant_ppc(chain, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks for the barcode log-frequency ratio for adaptive mutants. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(m) = f_t^(m) \n    expleft left( s^(m) - bars_t right) tau right\n\nwhere s^(m) is the mutant relative fitness, bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(m)f_t^(m) sim \n    log-mathcalNleft( s^(m) - bars_t sigma^(m) right)\n\nwhere sigma^(m) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:\n\n:mutant_mean_fitness: Variable defining the inferred mutant fitness value s⁽ᵐ⁾.\n:mutant_std_fitness: Variable defining the standard defining the inferred standard deviation on the likelihood function σ⁽ᵐ⁾.\npopulation_mean_fitness: Common pattern in all population mean fitness variables.\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if\n\nthe model used a normal or lognormal distribution for the likelihood. This is   because when using a normal distribution, the nuisance parameters are sampled   in log scale and need to be exponentiated.\n\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the frequency posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_popmean_ppc-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_popmean_ppc","text":"logfreq_ratio_popmean_ppc(df, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks (better called the posterior retrodictive checks) for the barcode log-frequency ratio for neutral lineages. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(n) = f_t^(n) \n    expleft left( - bars_t right) tau right\n\nwhere bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(n)f_t^(n) sim \n    log-mathcalNleft( - bars_t sigma^(n) right)\n\nwhere sigma^(n) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\ndf::DataFrames.DataFrame: Dataframe containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:     - population_mean_fitness: Common pattern in all population mean fitness     variables.     - population_std_fitness: Common pattern in all standard deviations       estimates for the likelihood.\n\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if   the model used a normal or lognormal distribution for the likelihood. This   is because when using a normal distribution, the nuisance parameters are   sampled in log scale and need to be exponentiated.\nflatten::Bool=true: Boolean indicating whether to flatten the output of multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ)= s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.logfreq_ratio_popmean_ppc-Tuple{MCMCChains.Chains, Int64}","page":"stats","title":"BayesFitness.stats.logfreq_ratio_popmean_ppc","text":"logfreq_ratio_popmean_ppc(chain, n_ppc; kwargs)\n\nFunction to compute the posterior predictive checks (better called the posterior retrodictive checks) for the barcode log-frequency ratio for neutral lineages. Our model predicts the frequency at time t+1 based on the frequency at time t as\n\n    f_t+1^(n) = f_t^(n) \n    expleft left( - bars_t right) tau right\n\nwhere bars_t is the population mean fitness between time t and t+1, and tau is the time interval between time t and t+1. Our inference model assumes that\n\n    fracf_t+1^(n)f_t^(n) sim \n    log-mathcalNleft( - bars_t sigma^(n) right)\n\nwhere sigma^(n) is the inferred standard deviation for the model. This function generates samples out of this distribution.\n\nArguments\n\nchain::MCMCChains.Chains: Chain containing the MCMC samples for the variables needed to compute the posterior predictive checks. The dataframe should have MCMC samples for\nmutant relative fitness values.\npopulation mean fitness values. NOTE: The number of columns containing population mean fitness values determines the number of datapoints where the ppc are evaluated.\n(log)-normal likelihood standard deviation.\nn_ppc::Int: Number of samples to generate per set of parameters.\n\nOptional Arguments\n\nparam::Dict{Symbol, Symbol}: Dictionary indicating the name of the variables\n\nin the mcmc chain defining the following variables:     - population_mean_fitness: Common pattern in all population mean fitness     variables.     - population_std_fitness: Common pattern in all standard deviations         estimates for the likelihood.\n\nmodel::Symbol=:lognormal: Either :normal or :lognormal to indicate if the model used a normal or lognormal distribution for the likelihood. This is because when using a normal distribution, the nuisance parameters are sampled in log scale and need to be exponentiated.\nflatten::Bool=true: Boolean indicating whether to flatten the output of   multiple chain into a single column.\n\nReturns\n\nlog(fₜ₊₁ / fₜ) = s⁽ᵐ⁾ - s̅ₜ::Array{Float64}: Evaluation of the log frequency ratio posterior predictive checks at all times for each MCMC sample.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.matrix_quantile_range-Union{Tuple{T}, Tuple{Vector{<:AbstractFloat}, Matrix{T}}} where T<:Real","page":"stats","title":"BayesFitness.stats.matrix_quantile_range","text":"matrix_quantile_range(quantile, matrix; dim=2)\n\nFunction to compute the quantile ranges of matrix mat over dimension dim. For example, if quantile[1] = 0.95, This function returns the 0.025 and 0.975 quantiles that capture 95 percent of the entires on the matrix.\n\nArguments\n\nquantile::Vector{<:AbstractFloat}: List of quantiles to extract from the posterior predictive checks.\nmatrix::Matrix{<:Real}: Array over which to compute quantile ranges.\n\nOptional arguments\n\ndim::Int=2: Dimension over which to compute quantiles. Defualt = 1, i.e., columns.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.naive_fitness-Tuple{DataFrames.AbstractDataFrame}","page":"stats","title":"BayesFitness.stats.naive_fitness","text":"naive_fitness(data; id_col, time_col, count_col, neutral_col, pseudo_count)\n\nFunction to compute a naive estimate of mutant fitness data based on counts. The fitness estimate is computed as\n\nleftlangle\nlogfracf^(m)_t+1f^(m)_t - logfracf^(n)_t+1f^(n)_t\nrightrangle = s^(m)\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to infer the fitness values on mutants. The DataFrame must contain at least the following columns:     - id_col: Column identifying the ID of the barcode. This can the barcode     sequence, for example.     - time_col: Column defining the measurement time point.     - count_col: Column with the raw barcode count.     - neutral_col: Column indicating whether the barcode is from a neutral     lineage or not.\n\nOptional Keyword Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the\n\ninference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\n\npseudo_count::Int=1: Pseudo count number to add to all counts. This is useful to avoid divisions by zero.\n\nReturns\n\nDataFrames.DataFrame: Data frame with two columns:\nid_col: Column indicating the strain ID.\nfitness: Naive fitness estimate.\n\n\n\n\n\n","category":"method"},{"location":"stats/#BayesFitness.stats.naive_prior_neutral-Tuple{DataFrames.AbstractDataFrame}","page":"stats","title":"BayesFitness.stats.naive_prior_neutral","text":"naive_prior_neutral(data, rm_T0)\n\nFunction to compute a naive set of parameters for the prior distributions of the population mean fitness s̲ₜ values and the nuisance parameters in the log-likelihood functions for the frequency ratios σ̲ₜ and σ̲⁽ᵐ⁾.\n\nThis function expects the data in a tidy format. This means that every row represents a single observation. For example, if we measure barcode i in 4 different time points, each of these four measurements gets an individual row. Furthermore, measurements of barcode j over time also get their own individual rows.\n\nThe DataFrame must contain at least the following columns:\n\nid_col: Column identifying the ID of the barcode. This can the barcode   sequence, for example.\ntime_col: Column defining the measurement time point.\ncount_col: Column with the raw barcode count.\nneutral_col: Column indicating whether the barcode is from a neutral lineage\n\nor not.\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to sample from the population mean fitness posterior distribution.\n\nOptional Keyword Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point   at which measurements were done. The column may contain any type of entry as   long as sort will resulted in time-ordered names.\nfreq_col::Symbol=:freq: Name of the column in data containing the naive   barcode frequency. The column must contain entries of type Float64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether   the barcode belongs to a neutral lineage or not. The column must contain   entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the\n\ninference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\n\nReturns\n\nprior_params::Dict: Dictionary with two entries:\ns_pop_prior: Mean value of the population mean fitness. NOTE: This naive empirical method cannot make statements about the expected standard deviation of the population mean fitness. It is up to the researcher to determine this value.\nlogσ_pop_prior: Prior on the nuisance parameter for the log-likelihood functions on the log-frequency ratios. In other words, the mean and standard deviation for the (log)-Normal distribution on the frequency ratios. NOTE: Typically, one can use the same estimate for both the neutral and the mutant lineages.\n\n\n\n\n\n","category":"method"},{"location":"#BayesFitness","page":"BayesFitness","title":"BayesFitness","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Welcome to the documentation of BayesFitness.jl! The accompanying paper, Bayesian inference of relative fitness on high-throughput pooled competition assays, explains all of the biological and mathematical background needed to understand this package. Here, we only focus on how to use the package, assuming the user already understands the objective of inferring the posterior probability distribution of the relative fitness of mutant strains in a pooled competition assay.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The package is divided into modules. Here's a brief description of the content of each module, but please visit their respective documentations to understand what each module is intended for.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"utils: Series of miscellaneous functions that make the data wrangling and processing much simpler.\nstats: Statistical functions used in the inference problem.\nmodel: Turing.jl-based Bayesian models used to infer the population mean fitness via the neutral lineages as well as the mutants' relative fitness.\nmcmc: The main module with which to perform the Markov-Chain Monte Carlo sampling of the posterior distributions.","category":"page"},{"location":"#Example-inference","page":"BayesFitness","title":"Example inference","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To get you going with the package, let's walk through a basic inference pipeline for one competition assay. Our ultimate goal consists of inferring the relative fitness for each of the barcoded genotypes of interest. To that end, we assume that the frequency time-series obeys the following equation","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"f_t+1^(b) = f_t^(b) mathrme^left(s^(b) - bars_t right)tau\ntag1","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"where f_t^(b) is the frequency of barcode b at time t, s^(b) is the relative fitness of this barcode, bars_t is the population mean fitness at time t, and tau is the time interval between time t and t+1.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The first step consists of importing the necessary packages. ","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"note: Note\nWe use import rather than the more common using command. We find it better to keep the project organized, but feel free to use whatever is more convenient for you!","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import Bayesian inference package\nimport BayesFitness\n\n# Import libraries to manipulate data\nimport DataFrames as DF\nimport CSV","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"After having imported the libraries, we need to load our dataset into memory. This dataset is already in the format needed for BayesFitness.jl to work, so we don't have to modify anything.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import data\ndata = CSV.read(\"~/git/BayesFitness/test/data/data_example_01.csv\", DF.DataFrame)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Here you will replace \"~/git/BayesFitness/test/data\" with the directory where your data is stored, and \"data_example_01.csv\" with the name of the file containing the data. The resulting DataFrame looks something like this:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"| BCID_x | barcode                                               | name                    | count | time | neutral | count_sum  |\n|--------|-------------------------------------------------------|-------------------------|-------|------|---------|------------|\n| 0      | TGATCAATCTACAAAAATATTTAATG_GAGTGAAACATGAATGGTATTCATCA | Batch1_1Day-T0_combined | 53    | 0    | FALSE   | 543947     |\n| 1      | CCGCCAATCCCGAACCCCGTTTCGCC_ACTCTAACGTGTAACTAATTTTGAGT | Batch1_1Day-T0_combined | 1213  | 0    | FALSE   | 543947     |\n| 2      | GACAGAAAAGCCAAATGGATTTACCG_ATGGGAACACGGAATGATCTTTTATT | Batch1_1Day-T0_combined | 17    | 0    | FALSE   | 543947     |\n| 3      | CCAACAAAACACAAATCTGTTGTGTA_TACTAAATAAGTAAGGGAATTCTGTT | Batch1_1Day-T0_combined | 19    | 0    | FALSE   | 543947     |\n| 4      | TATCGAAACCCAAAGAGATTTAATCG_ATGACAAACTTTAAATAATTTAATTG | Batch1_1Day-T0_combined | 23    | 0    | FALSE   | 543947     |\n| 5      | TATCGAAACCCAAAGAGATTTAATCG_CGATCAAAGACTAACTTATTTTGTGG | Batch1_1Day-T0_combined | 16    | 0    | FALSE   | 543947     |\n| 6      | TATCGAAACCCAAAGAGATTTAATCG_TTGCCAAGCTGGAAAGCTTTTTATGA | Batch1_1Day-T0_combined | 12    | 0    | FALSE   | 543947     |\n| 7      | ATCACAATAACTAAACTGATTCTTCA_CTCATAACATCAAAAAAAATTCAAAT | Batch1_1Day-T0_combined | 161   | 0    | FALSE   | 543947     |\n| 8      | TATCGAAACCCAAAGAGATTTAATCG_GTTTAAACCATTAATTATATTAGATC | Batch1_1Day-T0_combined | 19    | 0    | FALSE   | 543947     |","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The relevant columns in this data frame are:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"barcode: The unique ID that identifies the barcode.\ncount: The number of reads for this particular barcode.\ntime: The time point ID indicating the order in which samples were taken.\nneutral: Indicator of whether the barcode belongs to a neutral lineage or not.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Let's take a look at the data. For this we import the extra package that includes some plotting routines. ","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"warning: Warning\nTo make the package more modular, we did not include plotting functionalities since this can interfere with the installation of the package on remote servers. Instead, the accompanying paper repository includes a module that we can import to create basic plots using Makie.jl. There are other options within the Julia ecosystem that users might be more familiar with.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The BayesFitUtil.viz module has several Makie.jl-based functions to easily display the data. Let's import the necessary plotting libraries","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import package with useful plotting functions for our dataset\nimport BayesFitUtils\n# Import plotting libraries\nusing CairoMakie\nimport ColorSchemes","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"First, let's plot the barcode frequency trajectories. For this, we use the convenient [BayesFitUtils.viz.bc_time_series!] function.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(400, 300))\n\n# Add axis\nax = Axis(\n    fig[1, 1], xlabel=\"time\", ylabel=\"barcode frequency\", yscale=log10\n)\n\n# Plot mutant barcode trajectories\nBayesFitUtils.viz.bc_time_series!(\n    ax,\n    data[.!(data.neutral), :],\n    zero_lim=0,\n    alpha=0.3\n)\n\n# Plot neutral barcode trajectories\nBayesFitUtils.viz.bc_time_series!(\n    ax,\n    data[data.neutral, :],\n    zero_lim=0,\n    color=ColorSchemes.Blues_9[end],\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We highlight the neutral barcodes⸺defined to have relative fitness s^(n)=0⸺with dark blue lines. The rest of the light-color lines correspond to individual barcodes.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can rewrite Eq. (1) as","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"frac1tau ln fracf_t+1^(b)f_t^(b) = \nleft(s^(b) - bars_t right)\ntag2","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"In this form, we can se that the relevant quantity we need to infer the values of the population mean fitness bars_t and the barcode relative fitness s^(b) are not the frequencies themselves, but the log ratio of these frequencies between two adjacent time points. Let's plot this log frequency ratio using the [BayesFitUtils.viz.logfreq_ratio_time_series!] function.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Initialize figure\nfig = Figure(resolution=(400, 300))\n\n# Add axis\nax = Axis(fig[1, 1], xlabel=\"time\", ylabel=\"ln(fₜ₊₁/fₜ)\")\n\n# Plot mutant barcode trajectories\nBayesFitUtils.viz.logfreq_ratio_time_series!(\n    ax,\n    data[.!(data.neutral), :],\n    alpha=0.3\n)\n\n# Plot neutral barcode trajectories\nBayesFitUtils.viz.logfreq_ratio_time_series!(\n    ax,\n    data[data.neutral, :],\n    color=ColorSchemes.Blues_9[end],\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nWe expect is to see these log-frequency ratios as relatively flat lines. Especially for the neutral lineages.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"#Brief-description-of-the-Bayesian-model","page":"BayesFitness","title":"Brief description of the Bayesian model","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We invite the user to read the full details of our statistical model in the accompanying paper. Briefly, we track B unique barcodes over T time points. Therefore, We can think of the data as consisting of a T times B matrix underlineunderlineD with integer entries D_t^(i) representing the number of reads for barcode i at time t. For these number of reads per barcode, we imagine we draw a Poisson-distributed number of organisms such that","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"D_t^(i) sim textPoissleft(lambda_t^(i)right)\ntag3","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"where","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"lambda_t^(i) propto n_t^(i)\ntag4","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"i.e., the Poisson sample for organism i depends on the current number of organisms of type i in the population. The barcode dynamics described in Eq. 1 and 2 depend on the relative frequency rather than the absolute number of organisms in the population. In the context of this model, the frequency is then defined as","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"f_t^(i) = fracn_t^(i)sum_j n_t^(j) = \nfraclambda_t^(i)sum_j lambda_t^(j)\ntag5","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Our Bayesian inference then is done over the list of parameters s^(m), bars_t, and lambda_t^(i). Furthermore, we include nuisance parameters sigma^(m) and barsigma_t that go into our likelihood function (see details in accompanying paper). For this inference, we then define the following priors:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"s^(m) sim mathcalNleft(mu_s sigma_sright)\ntag6","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"sigma^(m) sim mathcalNleft(mu_sigma sigma_sigmaright)\ntag7","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"bars_t sim mathcalNleft(mu_bars sigma_barsright)\ntag8","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"barsigma_t sim \nmathcalNleft(mu_barsigma sigma_barsigmaright)\ntag9","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"and","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"lambda_t^(i) sim logmathcalNleft(mu_lambda sigma_lambdaright)\ntag10","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"For the likelihood function, we divide it between our direct observations⸺the number of reads per barcode⸺and the latent variables⸺the frequency ratio between adjacent time points. For the observations, we have that each entry of our data matrix underlineunderlineD is Poisson distributed, as defined  in Eq. 3. It can be shown that the joint probability of the B independent  Poisson random variables at time t is equivalent to writing","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"N_t sim textPoissonleft(sum_j lambda_t^(j)right)\ntag11","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"and","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"underlineD_t sim textMultinomialleft(N_t underlinef_tright)\ntag12","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"where underlineD_t is the list of counts for time point t, N_t = sum_j D_t^(j) is the total number of reads at time t, and underlinef_t is the list of barcode frequencies for time point t.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"For the latent (unobserved) frequency ratios, we define one likelihood function  for the neutral lineages only of the form","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"fracf_t+1^(n)f_t^(n) sim \nlogmathcalNleft(-bars_t barsigma_tright)\ntag13","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"For the mutant lineages, we have","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"fracf_t+1^(m)f_t^(m) sim \nlogmathcalNleft(s^(m) -bars_t sigma^(m)right)\ntag14","category":"page"},{"location":"#Using-the-neutral-lineages-to-determine-our-priors","page":"BayesFitness","title":"Using the neutral lineages to determine our priors","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"One of the feature of Bayesian analysis is that we can include prior information into our inference task that encodes our domain expertise. For analysis with a lot of data, as long as the prior is broad-enough, this becomes less relevant. However, although we have a lot of data for multiple barcodes, we are actually in the low-data regime since for each barcode we typically have on the order of 4-5 time point measurements. Thus, defining appropriate priors is important for our inference pipeline. Unfortunately, we do not necessarily measure each genotype multiple times within the same experiment to get a sense of the expected variation in our measurements. An exception to this are the neutral barcodes. These barcodes represent multiple measurement of allegedly the same reference genotype. Therefore, we can use the variability within these measurements to define the priors for our inference.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Specifically, we will use the data from the neutral lineages to define the parameters (mu_bars sigma_bars), (mu_barsigma sigma_barsigma), and (mu_sigma sigma_sigma). We will use the default values for the rest of the parameters (mu_s sigma_s), and (mu_lambda sigma_lambda).","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Let's now take the neutrals data and obtain these parameters","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Group neutral data by barcode\ndata_group = DF.groupby(data[data.neutral, :], :barcode)\n\n# Initialize list to save log frequency changes\nlogfreq = []\n\n# Loop through each neutral barcode\nfor d in data_group\n    # Sort data by time\n    DF.sort!(d, :time)\n    # Compute log frequency ratio and append to list\n    push!(logfreq, diff(log.(d[:, :freq])))\nend # for\n\n# Generate matrix with log-freq ratios\nlogfreq_mat = hcat(logfreq...)\n\n# Compute mean per time point for approximate mean fitness\nlogfreq_mean = StatsBase.mean(logfreq_mat, dims=2)\n\n# Define prior for population mean fitness\ns_pop_prior = hcat(-logfreq_mean, repeat([0.3], length(logfreq_mean)))\n\n# Generate single list of log-frequency ratios to compute prior on σ\nlogfreq_vec = vcat(logfreq...)\n\n# Define priors for nuisance parameters for log-likelihood functions\nσ_pop_prior = [StatsBase.mean(logfreq_vec), StatsBase.std(logfreq_vec)]\nσ_mut_prior = σ_pop_prior","category":"page"},{"location":"#Running-the-inference","page":"BayesFitness","title":"Running the inference","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"With these priors in hand, we can run the inference. For this, we use the BayesFitness.mcmc.mcmc_joint_fitness function from the mcmc module. The main parameters we need to define are:","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":":data: Tidy data frame containing the raw barcode counts.\n:n_steps: Number of posterior samples per walker to keep.\n:n_walkers: Number of MCMC chains to run in parallel. NOTE: Having multiple chains run in parallel is convenient for diagnostics. NOTE: Turing.jl gives us the functionality to run multiple chains simultaneously in a multi-threaded way. We specify this with the :ensemble option\n:outputname: String defining the pattern for the output file. This can be something related to the dataset. For example, the growth media, or the date of the experiment, of whatever metadata used to distinguish different datasets.\n:model: Bayesian model from the model module that defines the posterior distribution to be sampled.\n:model_kwargs: The parameters required by the model function.\n:sampler: Turing.jl MCMC sampler to use for the inference.\n:ensemble: Modality to be used when running the inference. This allows us to run multiple chains either in series (Turing.MCMCSerial()), in multithread (Turing.MCMCThreads()), or with multiple process (Turing.MCMCDistributed()).\n:rm_T0: Whether or not to remove the first time point in the data when performing the inference.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To speed-up the computation, we will use the DynamicHMC.jl No-U-Turn sampler with ReverseDiff.jl as the auto differentiation backend (see Turing.jl documentation for more information on this). Let's import the necessary packages and set the differentiation backend options.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import library to perform Bayesian inference\nimport Turing\nimport DynamicHMC\n\n# Import AutoDiff backend\nusing ReverseDiff\n\n# Import Memoization\nusing Memoization\n\n# Set AutoDiff backend\nTuring.setadbackend(:reversediff)\n# Allow system to generate cache to speed up computation\nTuring.setrdcache(true)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"For this dataset, we use the BayesFitness.model.fitness_lognormal model from the model module. Now, we can compile all of the necessary parameters into a dictionary.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define sampling hyperparameters\nn_steps = 1000\nn_walkers = 4\n\n# Define function parameters\nparam = Dict(\n    :data => data,\n    :n_walkers => n_walkers,\n    :n_steps => n_steps,\n    :outputname => \"./output/chain_joint_fitness_$(n_steps)steps_$(lpad(n_walkers, 2, \"0\"))walkers\",\n    :model => BayesFitness.model.fitness_lognormal,\n    :model_kwargs => Dict(\n        :s_pop_prior => s_pop_prior,\n        :σ_pop_prior => σ_pop_prior,\n        :σ_mut_prior => σ_mut_prior,\n    ),\n    :sampler => Turing.DynamicNUTS(),\n    :ensemble => Turing.MCMCThreads(),\n    :rm_T0 => false,\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Next, we run the inference.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"BayesFitness.mcmc.mcmc_joint_fitness(; param...)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The output of this function is a .jld2 file that saves the native data structure with the MCMC samples and the list of the mutant barcodes in the order used in the inference so that we can map the variable names to the corresponding barcodes.","category":"page"},{"location":"#Validating-the-inference","page":"BayesFitness","title":"Validating the inference","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"The first step to check the inference results is to load the MCMC chain into memory. For this, we need to load the JLD2.jl package as well as the MCMCChains.jl package that allows us to manipulate the data structure containing the MCMC chains.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Import package to search file name\nimport Glob\n# Import package to load .jld2 files into memory\nimport JLD2\n# Import package to manipulate MCMCChains.Chain objects\nimport MCMCChains\n\n# Define file\nfile = first(Glob.glob(\"./output/chain_joint_fitness_*\"))\n\n# Load list of mutants and MCMC chain\nids, chn = values(JLD2.load(file))","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"To diagnose the inference, it is useful to plot both the MCMC traces for each walker as well as the resulting density plots. Let's first do this for the population mean fitness-related values underlinebars_t and underlinebarsigma_t. To do this, we feed the chain data structure to the BayesFitnUtils.viz.mcmc_trace_density! function to automatically generate these plots.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Extract variable names\nvar_names = vcat(\n    [MCMCChains.namesingroup(chn, :s̲ₜ), MCMCChains.namesingroup(chn, :σ̲ₜ)]...\n)\n\n# Initialize figure\nfig = Figure(resolution=(600, 800))\n\n# Generate mcmc_trace_density! plot\nBayesFitUtils.viz.mcmc_trace_density!(fig, chn[var_names]; alpha=0.5)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nWhat we want to see from these plots is that all traces look relatively similar, with no big gaps where the walker got stuck. Furthermore, we want to see that all the densities converged to very similar-looking distributions. That is indeed the case for our dataset.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Another way of assessing the output of this inference step is to plot the posterior predictive checks against the data. The logic behind the posterior predictive checks is the following: before performing the inference on the parameters we seek to learn form the data, we have a prior belief of what those values can be encoded in our prior distribution. We update this prior belief after observing the experimental data given our likelihood function that captures our model for the data generating process. Thus, the posterior distribution of the parameter values contains our updated belief for what the parameter values can be. Therefore, we can sample out of this parameter posterior distribution and feed such parameters to our likelihood function to generate synthetic data. The expectation is that this simulated data should capture the range of experimental data we observed if the model and the inferred parameters describe the data generation process.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"For this particular case of the population mean fitness, we can use the BayesFitness.stats.logfreq_ratio_mean_ppc from the stats module to compute the posterior predictive checks. What this function does is to generate samples for the log-frequency ratios used to infer the population mean fitness values.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"info: Info\nNote that the BayesFitness.stats.logfreq_ratio_mean_ppc function has methods to work with either MCMCChains.Chains objects or with tidy DataFrames.DataFrame. This allows you to use the data structure you are more comfortable working with.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define dictionary with corresponding parameters for variables needed for\n# the posterior predictive checks\nparam = Dict(\n    :population_mean_fitness => :s̲ₜ,\n    :population_std_fitness => :σ̲ₜ,\n)\n\n# Define number of posterior predictive check samples\nn_ppc = 500\n\n# Define colors\ncolors = get(ColorSchemes.Blues_9, LinRange(0.25, 1.0, length(qs)))\n\n# Compute posterior predictive checks\nppc_mat = BayesFitness.stats.logfreq_ratio_mean_ppc(\n    chn, n_ppc; param=param\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Once we generate these samples, we can plot the quantiles of the simulated data with different shades. The BayesFitUtils.viz.ppc_time_series! function makes this plotting really simple. Let us plot the standard 68-95 as well as the 5 percentile with different shades of blue and then add the data on top of these shaded areas","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"tip: Tip\nWhat we expect from this plot is to see that most of the experimental data falls within the range of the simulated data, meaning that the model and the inferred parameters can reproduce the range of our observations.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define quantiles to compute\nqs = [0.05, 0.68, 0.95]\n\n# Define colors\ncolors = get(ColorSchemes.Blues_9, LinRange(0.25, 1.0, length(qs)))\n\n# Define time\nt = vec(collect(axes(ppc_mat, 2)) .+ 1)\n\n# Initialize figure\nfig = Figure(resolution=(450, 350))\n\n# Add axis\nax = Axis(\n    fig[1, 1],\n    xlabel=\"time point\",\n    ylabel=\"ln(fₜ₊₁/fₜ)\",\n    title=\"neutral lineages PPC\"\n)\n\n# Plot posterior predictive checks\nBayesFitUtils.viz.ppc_time_series!(\n    ax, qs, ppc_mat; colors=colors, time=t\n)\n\n# Plot log-frequency ratio of neutrals\nBayesFitUtils.viz.logfreq_ratio_time_series!(\n    ax,\n    data[data.neutral, :];\n    freq_col=:freq,\n    color=:black,\n    alpha=1.0,\n    linewidth=2\n)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"This plot shows that the range of inferred population mean fitnesses does capture the log-frequency ratios of the neutral lineages. ","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"Let us repeat this analysis for the mutants. Obviously, with the incredibly large number of unique mutant barcodes, it would be difficult to visualize all trace-density plots as well as all posterior predictive checks. But we can take a random subset of them to make sure they look okay in general.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"\n# Find columns with mutant fitness values and error\ns_names = MCMCChains.namesingroup(chn, :s̲⁽ᵐ⁾)\n\n# Define barcodes to include\nvar_names = StatsBase.sample(s_names, 8)\n\n# Initialize figure\nfig = Figure(resolution=(600, 800))\n\n# Generate mcmc_trace_density! plot\nBayesFitUtils.viz.mcmc_trace_density!(fig, chn[var_names]; alpha=0.5)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"All these example density and trace plots look good. Next, let us compute and plot some example posterior predictive checks for a few mutants. ","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"# Define number of posterior predictive check samples\nn_ppc = 500\n# Define quantiles to compute\nqs = [0.95, 0.675, 0.05]\n\n# Define number of rows and columns\nn_row, n_col = [4, 4]\n\n# Initialize figure\nfig = Figure(resolution=(300 * n_col, 300 * n_row))\n\n# List example barcodes to plot\nbc_plot = StatsBase.sample(eachrow(df_summary), n_row * n_col)\n\n# Initialize plot counter\ncounter = 1\n# Loop through rows\nfor row in 1:n_row\n    # Loop through columns\n    for col in 1:n_col\n        # Add axis\n        ax = Axis(fig[row, col])\n\n        # Extract data\n        data_bc = DF.sort(\n            data[data.barcode.==bc_plot[counter].barcode, :], :time\n        )\n\n        # Define colors\n        colors = get(ColorSchemes.Blues_9, LinRange(0.5, 1.0, length(qs)))\n\n        # Define dictionary with corresponding parameters for variables needed\n        # for the posterior predictive checks\n        param = Dict(\n            :mutant_mean_fitness => Symbol(bc_plot[counter].variable),\n            :mutant_std_fitness => Symbol(\n                replace(bc_plot[counter].variable, \"s\" => \"σ\")\n            ),\n            :population_mean_fitness => :s̲ₜ,\n        )\n        # Compute posterior predictive checks\n        ppc_mat = BayesFitness.stats.logfreq_ratio_mutant_ppc(\n            chn, n_ppc; param=param\n        )\n        # Plot posterior predictive checks\n        BayesFitUtils.viz.ppc_time_series!(\n            ax, qs, ppc_mat; colors=colors\n        )\n\n        # Add scatter of data\n        scatterlines!(ax, diff(log.(data_bc.freq)), color=:black, linewidth=2.5)\n\n        # Add title\n        ax.title = \"barcode $(first(data_bc.barcode))\"\n        ax.titlesize = 18\n\n        ## == Plot format == ##\n\n        # Hide axis decorations\n        hidedecorations!.(ax, grid=false)\n\n        # Update counter\n        global counter += 1\n    end  # for\nend # for\n\n# Add x-axis label\nLabel(fig[end, :, Bottom()], \"time points\", fontsize=22)\n# Add y-axis label\nLabel(fig[:, 1, Left()], \"ln(fₜ₊₁/fₜ)\", rotation=π / 2, fontsize=22)","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"(Image: )","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"We can see that indeed the recovered fitness value greatly agrees with the data.","category":"page"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"This concludes the example inference pipeline. We invited you to explore more the potential in the package and please send any comments/requests through the GitHub repository issues.","category":"page"},{"location":"#Contents","page":"BayesFitness","title":"Contents","text":"","category":"section"},{"location":"","page":"BayesFitness","title":"BayesFitness","text":"","category":"page"},{"location":"utils/#utils","page":"utils","title":"utils","text":"","category":"section"},{"location":"utils/","page":"utils","title":"utils","text":"Modules = [BayesFitness.utils]\nOrder   = [:function, :type]","category":"page"},{"location":"utils/#BayesFitness.utils.advi2df-Tuple{Distributions.Sampleable, Vector, Vector}","page":"utils","title":"BayesFitness.utils.advi2df","text":"advi2df(dist, vars, mutids; nrep=1, envs=[1], nsamples=10000)\n\nConvert the output of automatic differentiation variational inference (ADVI) to a tidy dataframe.\n\nArguments\n\ndist::Distributions.Sampleable: The ADVI posterior sampleable distribution object.\nvars::Vector{<:Any}: Vector of variable/parameter names from the ADVI run. \nmut_ids::Vector{<:Any}: Vector of mutant strain IDs.\n\nOprtional Keyword Arguments\n\nn_rep::Int=1: Number of experimental replicates. Default is 1. \nenvs::Vector{<:Any}=[1]: Vector of environment ids for each timepoint. Default is a single environment [1].\nn_samples::Int=10_000: Number of posterior samples to draw used for hierarchical models. Default is 10,000.\n\nReturns\n\ndf::DataFrames.DataFrame: DataFrame containing summary statistics of\n\nposterior samples for each parameter. Columns include:     - mean, std: posterior mean and standard deviation for each of the       variables.     - varname: parameter name from the ADVI posterior distribution.     - var_type: Description of the type of parameter. The types are:         - pop_mean: Population mean fitness value s̲ₜ.         - pop_error: (Nuisance parameter) Log of standard deviation in the           likelihood function for the neutral lineages.         - mut_fitness: Mutant relative fitness s⁽ᵐ⁾.         - mut_hyperfitness: For hierarchical models, mutant hyper parameter           that connects the fitness over multiple experimental replicates           θ⁽ᵐ⁾.         - mut_noncenter: (Nuisance parameter) For hierarchical models,           non-centered samples used to connect the experimental replicates to           the hyperparameter θ̃⁽ᵐ⁾.         - mut_deviations: (Nuisance parameter) For hierarchicaal models,           samples that define the log of the deviation from the hyper parameter           fitness value logτ⁽ᵐ⁾.         - mut_error: (Nuisance parameter) Log of standard deviation in the           likelihood function for the mutant lineages.         - freq: (Nuisance parameter) Log of the Poisson parameter used to           define the frequency of each lineage.     - rep: Experimental replicate number.     - env: Environment for each parameter.     - id: Mutant or neutral strain ID.\n\nNotes\n\nConverts multivariate posterior into summarized dataframe format.\nAdds metadata like parameter type, replicate, strain ID, etc.\nCan handle models with multiple replicates and environments.\nUseful for post-processing ADVI results for further analysis and plotting.\n\n\n\n\n\n","category":"method"},{"location":"utils/#BayesFitness.utils.concat_chains-Tuple{Vector{<:MCMCChains.Chains}, Vector{Symbol}}","page":"utils","title":"BayesFitness.utils.concat_chains","text":"`concat_chains(chains, var_pattern, id_str)`\n\nFunction that concatenates multiple MCMCChains.Chains objects into a single one. This function takes a vector of MCMCChains.Chains as inputs, extracts the variables that match the patterns in the array var_pattern, and appends all extracted variables into a single chain adding a pattern of the form [$(id_str)i], where i is the file number. For example, if two chains contain a variable named var, the new chain returned by this function names them as var[f1] and var[f2] if id_str=f.\n\nNOTE: All chains must have the same number of samples to be concatenated.\n\nArguments\n\nchains::Vector{<:MCMCChains.Chains}: Vector with the chains to be concatenated into a single chain.\nvar_pattern::Vector{Symbol}: Patterns that variables must follow to be extracted from the chain. For example, if several variables are named var[1], var[2], etc, providing a pattern [var] extracts all of them, while providing var[1] extracts only the one that perfectly matches this pattern.\n\nOptional arguments\n\nid_str::String=f: String to be attached to the variable names that identifies the different chains being concatenated. For example, if 4 chains are being concatenated, each repeated variable will be named var[$(id_str)i] to distinguish each of them.\n\nReturns\n\nMCMCChains.Chains: Chain with the requested variables from multiple files concatenated into a single object.\n\n\n\n\n\n","category":"method"},{"location":"utils/#BayesFitness.utils.data2arrays-Tuple{DataFrames.AbstractDataFrame}","page":"utils","title":"BayesFitness.utils.data2arrays","text":"data2arrays(data; kwargs)\n\nFunction to preprocess the tidy dataframes with the data into the corresponding inputs for the models in the model submodule.\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to sample from the population mean fitness posterior distribution.\n\nOptional Keyword Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the inference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\nverbose::Bool=true: Boolean indicating if printing statements should be made.\n\nReturns\n\nif typeof(rep_col) <: Nothing Dictionary with the following entries: -     bc_count::Matrix: T × B matrix with all barcodes read counts. -     bc_total::Vector: T-dimensional vector with the total number of reads     per time point. - n_neutral::Int: Number of neutral lineages. -     n_mut::Int: Number of mutant lineages. - mut_keys: List of mutant names     in the order used to build R̲̲.\n\nelseif typeof(rep_col) <: Symbol Dictionary with the following entries: -         bc_count::Array: T × B × R array with all barcodes read counts. -         bc_total::Matrix: T × R matrix with the total number of reads per         time point per repeat. - n_neutral::Int: Number of neutral lineages. -         n_mut::Int: Number of mutant lineages. - mut_keys: List of mutant         names in the order used to build R̲̲.\n\n\n\n\n\n","category":"method"},{"location":"utils/#BayesFitness.utils.group_split-Tuple{DataFrames.AbstractDataFrame, Int64, Symbol, Symbol}","page":"utils","title":"BayesFitness.utils.group_split","text":"group_split(data, n_groups, groupby_col, count_col; sort_function)\n\nFunction to split a set of labels into n_group subgroups.\n\nArguments\n\ndata::DF.AbstractDataFrame: Data to be split into groups. This function   expects a tidy dataframe with at least two columns:\ngroupby_col: Column to group entries by. This is commonly the barcode ID that distinguishes different strains.\nsort_col: Column with values used to sort the data entries.\nn_groups::Int: Number of groups in which to split the data\ngroupby_col::Symbol: Name of column used to group the unique entries in dataset. This is commonly the barcode ID that distinguishes different strains.\nsort_col::Symbol: Name of column with quantity used to sort the entries in the dataset. This is commonly the number of barcode counts or frequency.\n\nOptional Keyword Arguments\n\nsort_function::Function=x -> StatsBase.mean(log.(x .+ 1)): Functio to use on the group-apply-combine routine. The default function computes the mean in log-scale, adding a 1 to avoid computing log(0).\n\nReturns\n\ngroups::Vector{Vector{typeof(data[groupby_col][1])}}: Vectors containing the different groups in which to split the dataset.\n\n\n\n\n\n","category":"method"},{"location":"utils/#BayesFitness.utils.group_split_naive_fitness-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"utils","title":"BayesFitness.utils.group_split_naive_fitness","text":"group_split(data, n_groups; kwargs)\n\nFunction to split a set of labels into n_group subgroups sorted by a naive estimate of the fitness value.\n\nArguments\n\ndata::DataFrames.AbstractDataFrame: Tidy dataframe with the data to be\n\nused to infer the fitness values on mutants. The DataFrame must contain at least the following columns:     - id_col: Column identifying the ID of the barcode. This can the barcode     sequence, for example.     - time_col: Column defining the measurement time point.     - count_col: Column with the raw barcode count.     - neutral_col: Column indicating whether the barcode is from a neutral     lineage or not.\n\nn_groups::Int: Number of groups in which to split the data.\n\nOptional Keyword Arguments\n\nid_col::Symbol=:barcode: Name of the column in data containing the barcode   identifier. The column may contain any type of entry.\ntime_col::Symbol=:time: Name of the column in data defining the time point at which measurements were done. The column may contain any type of entry as long as sort will resulted in time-ordered names.\ncount_col::Symbol=:count: Name of the column in data containing the raw barcode count. The column must contain entries of type Int64.\nneutral_col::Symbol=:neutral: Name of the column in data defining whether the barcode belongs to a neutral lineage or not. The column must contain entries of type Bool.\nrm_T0::Bool=false: Optional argument to remove the first time point from the\n\ninference. Commonly, the data from this first time point is of much lower quality. Therefore, removing this first time point might result in a better inference.\n\npseudo_count::Int=1: Pseudo count number to add to all counts. This is useful to avoid divisions by zero.\n\nReturns\n\ngroups::Vector{Vector{typeof(data[groupby_col][1])}}: Vectors containing the\n\ndifferent groups in which to split the dataset.\n\n\n\n\n\n","category":"method"},{"location":"utils/#BayesFitness.utils.jld2_concat_chains-Tuple{String, String, Vector{Symbol}}","page":"utils","title":"BayesFitness.utils.jld2_concat_chains","text":"`jld2_concat_chains(dir, file_patern, chains, var_pattern, id_str)`\n\nConvenient function that peforms the same concatenation as BayesFitness.utils.concat_chains but giving a directory and a file pattern for jld2 files storing the chains. This function reads all files in dir that have the pattern file pattern, obtaining a list of MCMCChains.Chains as inputs. It then extracts the variables that match the patterns in the array var_pattern, and appends all extracted variables into a single chain adding a pattern of the form [$(id_str)i], where i is the file number. For example, if two chains contain a variable named var, the new chain returned by this function names them as var[f1] and var[f2] if id_str=f.\n\nNOTE: All chains must have the same number of samples to be concatenated.\n\nArguments\n\ndir::String: Directory where file(s) with MCMC chains are stored.\nfile_pattern::String: Pattern common among all files to process. NOTE: This is use in the Glob.glob command to locate all jld2 files from which to extract the chains.\nvar_pattern::Vector{Symbol}: Patterns that variables must follow to be extracted from the chain. For example, if several variables are named var[1], var[2], etc, providing a pattern [var] extracts all of them, while providing var[1] extracts only the one that perfectly matches this pattern.\n\nOptional arguments\n\nid_str::String=f: String to be attached to the variable names that identifies the different chains being concatenated. For example, if 4 chains are being concatenated, each repeated variable will be named var[$(id_str)i] to distinguish each of them.\n\nReturns\n\nMCMCChains.Chains: Chain with the requested variables from multiple files concatenated into a single object.\nchainname::String=\"chain\": String defining the dictionary key on the .jld2\n\nfile to extract the MCMC chain.\n\n\n\n\n\n","category":"method"}]
}
