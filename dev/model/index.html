<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>model · BayesFitness</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">BayesFitness</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">BayesFitness</a></li><li><a class="tocitem" href="../mcmc/">mcmc</a></li><li class="is-active"><a class="tocitem" href>model</a></li><li><a class="tocitem" href="../stats/">stats</a></li><li><a class="tocitem" href="../utils/">utils</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>model</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/mrazomej/BayesFitness.jl/blob/main/docs/src/model.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="model"><a class="docs-heading-anchor" href="#model">model</a><a id="model-1"></a><a class="docs-heading-anchor-permalink" href="#model" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.fitness_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}" href="#BayesFitness.model.fitness_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}"><code>BayesFitness.model.fitness_lognormal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fitness_lognormal(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲, n̲ₜ; s_pop_prior, σ_pop_prior, s_mut_prior, σ_mut_prior, λ_prior)</code></pre><p><code>Turing.jl</code> model to sample the joint posterior distribution for a competitive fitness experiment.</p><p><strong>Model</strong></p><p><code>[write model here]</code></p><p><strong>Arguments</strong></p><ul><li><code>R̲̲⁽ⁿ⁾::Matrix{Int64}</code>: <code>T × N</code> matrix where <code>T</code> is the number of time points in the data set and <code>N</code> is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲⁽ᵐ⁾::Matrix{Int64}</code>: <code>T × M</code> matrix where <code>T</code> is the number of time points in the data set and <code>M</code> is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲::Vector{Vector{Int64}}</code>:: <code>T × B</code> matrix–split into a vector of vectors for computational efficiency–where <code>T</code> is the number of time points in the data set and <code>B</code> is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. <strong>NOTE</strong>: This matrix does not necessarily need to be equivalent to <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾)</code>. This is because <code>R̲̲⁽ᵐ⁾</code> can exclude mutant barcodes to perform the joint inference only for a subgroup, but <code>R̲̲</code> must still contain all counts. Usually, if <code>R̲̲⁽ᵐ⁾</code> excludes mutant barcodes, <code>R̲̲</code> must be of the form <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾)</code>, where <code>R̲̲⁽ᴹ⁾</code> is a vector that aggregates all excluded mutant barcodes into a &quot;super barcode.&quot;</li><li><code>n̲ₜ::Vector{Int64}</code>: Vector with the total number of barcode counts for each time point. <strong>NOTE</strong>: This vector <strong>must</strong> be equivalent to computing <code>vec(sum(R̲̲, dims=2))</code>. The reason it is an independent input parameter is to avoid the <code>sum</code> computation within the <code>Turing</code> model.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>s_pop_prior::VecOrMat{Float64}=[0.0, 2.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>s_pop_prior[1]</code> = mean, <code>s_pop_prior[2]</code> =   standard deviation, Matrix: <code>s_pop_prior[:, 1] = mean</code>, <code>s_pop_prior[:, 2] =   standard deviation</code>) for a Normal prior on the population mean fitness   values. If <code>typeof(s_pop_prior) &lt;: Matrix</code>, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.</li><li><code>σ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>σ_pop_prior[1]</code> = mean, <code>σ_pop_prior[2]</code> =   standard deviation, Matrix: <code>σ_pop_prior[:, 1] = mean</code>, <code>σ_pop_prior[:, 2] =   standard deviation</code>) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If <code>typeof(σ_pop_prior) &lt;:   Matrix</code>, there should be as many rows in the matrix as pairs of time   adjacent time points in dataset.</li><li><code>s_mut_prior::VecOrMat{Float64}=[0.0, 2.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> =   standard deviation, Matrix: <code>s_mut_prior[:, 1] = mean</code>, <code>s_mut_prior[:, 2] =   standard deviation</code>) for a Normal prior on the mutant fitness values. If   <code>typeof(s_mut_prior) &lt;: Matrix</code>, there should be as many rows in the matrix   as mutant lineages in the dataset.</li><li><code>σ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]</code>: Vector or Matrix with the correspnding parameters (Vector: <code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> = standard deviation, Matrix: <code>s_mut_prior[:, 1] = mean</code>, <code>s_mut_prior[:, 2] = standard deviation</code>) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If <code>typeof(σ_mut_prior) &lt;: Matrix</code>, there should be as many rows in the matrix as mutant lineages in the dataset.</li><li><code>λ_prior::VecOrMat{Float64}=[3.0, 3.0]</code>: Vector or Matrix with the correspnding parameters (Vector: <code>λ_prior[1]</code> = mean, <code>λ_prior[2]</code> = standard deviation, Matrix: <code>λ_prior[:, 1] = mean</code>, <code>λ_prior[:, 2] = standard deviation</code>) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count <code>n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾)</code>. If <code>typeof(λ_prior) &lt;: Matrix</code>, there should be as many rows in the matrix as number of barcodes × number of time points in the dataset.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/4d21f704180ee859cb81dc408e3fbce15c2c3d2a/src/model_fitness_lognormal.jl#L5-L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.fitness_lognormal-Tuple{Matrix{Int64}, Vector{Int64}, Vector{Vector{Int64}}, Vector{Int64}}" href="#BayesFitness.model.fitness_lognormal-Tuple{Matrix{Int64}, Vector{Int64}, Vector{Vector{Int64}}, Vector{Int64}}"><code>BayesFitness.model.fitness_lognormal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fitness_lognormal(R̲̲⁽ⁿ⁾, r̲⁽ᵐ⁾, R̲̲, n̲ₜ; s_pop_prior, σ_pop_prior, s_mut_prior, σ_mut_prior, λ_prior)</code></pre><p><code>Turing.jl</code> model to sample the joint posterior distribution for a competitive fitness experiment for the neutral barcodes and <em>a single mutant barcode</em></p><p><strong>Model</strong></p><p><code>[write model here]</code></p><p><strong>Arguments</strong></p><ul><li><code>R̲̲⁽ⁿ⁾::Matrix{Int64}</code>: <code>T × N</code> matrix where <code>T</code> is the number of time points in the data set and <code>N</code> is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>r̲⁽ᵐ⁾::Vector{Int64}</code>: <code>T</code> dimensional vector where <code>T</code> is the number of time points in the data set. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲::Vector{Vector{Int64}}</code>:: <code>T × B</code> matrix–split into a vector of vectors</li></ul><p>for computational efficiency–where <code>T</code> is the number of time points in the data   set and <code>B</code> is the number of barcodes. Each column represents the barcode   count trajectory for a single lineage.</p><ul><li><code>n̲ₜ::Vector{Int64}</code>: Vector with the total number of barcode counts for each time point. <strong>NOTE</strong>: This vector <strong>must</strong> be equivalent to computing <code>vec(sum(R̲̲, dims=2))</code>. The reason it is an independent input parameter is to avoid the <code>sum</code> computation within the <code>Turing</code> model.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>s_pop_prior::Vector{Float64}=[0.0, 2.0]</code>: Vector with the correspnding   parameters (<code>s_pop_prior[1]</code> = mean, <code>s_pop_prior[2]</code> = standard deviation)   for a Normal prior on the population mean fitness values. <strong>NOTE</strong>: This   method assigns the same prior to <strong>all</strong> population mean fitness to be   inferred.</li><li><code>σ_pop_prior::Vector{Float64}=[0.0, 1.0]</code>: Vector with the correspnding   parameters (<code>σ_pop_prior[1]</code> = mean, <code>σ_pop_prior[2]</code> = standard deviation)   for a Log-Normal prior on the population mean fitness error utilized in the   log-likelihood function. <strong>NOTE</strong>: This method assigns the same prior to   <strong>all</strong> population mean fitness errors to be inferred.</li><li><code>s_mut_prior::Vector{Float64}=[0.0, 2.0]</code>: Vector with the correspnding   parameters (<code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> = standard deviation)   for a Normal prior on the mutant fitness values. <strong>NOTE</strong>: This method   assigns the same prior to <strong>all</strong> mutant fitness values to be inferred.</li><li><code>σ_mut_prior::Vector{Float64}=[0.0, 1.0]</code>: Vector with the correspnding   parameters (<code>σ_mut_prior[1]</code> = mean, <code>σ_mut_prior[2]</code> = standard deviation)   for a Log-Normal prior on the mutant fitness error utilized in the   log-likelihood function. <strong>NOTE</strong>: This method assigns the same prior to   <strong>all</strong> mutant fitness error values to be inferred.</li><li><code>λ_prior::Vector{Float64}=[3.0, 3.0]</code>: Vector with the corresponding parameters (<code>λ_prior[1]</code> = mean, <code>λ_prior[2]</code> = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count <code>n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾)</code>. <strong>NOTE</strong>: This method assigns   the same prior to <strong>all</strong> mutant fitness error values to be inferred.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/4d21f704180ee859cb81dc408e3fbce15c2c3d2a/src/model_fitness_lognormal.jl#L234-L286">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.fitness_lognormal_hierarchical_replicates-Tuple{Array{Int64, 3}, Array{Int64, 3}, Array{Int64, 3}, Matrix{Int64}}" href="#BayesFitness.model.fitness_lognormal_hierarchical_replicates-Tuple{Array{Int64, 3}, Array{Int64, 3}, Array{Int64, 3}, Matrix{Int64}}"><code>BayesFitness.model.fitness_lognormal_hierarchical_replicates</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fitness_lognormal_hierarchical_replicates(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲, n̲ₜ; s_pop_prior, logσ_pop_prior, s_mut_prior, logσ_mut_prior, logλ_prior)</code></pre><p><code>Turing.jl</code> model to sample the joint posterior distribution for a competitive fitness experiment.</p><p><strong>Model</strong></p><p><code>[write model here]</code></p><p><strong>Arguments</strong></p><ul><li><code>R̲̲⁽ⁿ⁾::Array{Int64, 3}</code>: <code>T × N × R</code> array where <code>T</code> is the number of time points in the data set, <code>N</code> is the number of neutral lineage barcodes, and <code>R</code> is the number of experimental replicates. For each slice on the <code>R</code>-axis, each column represents the barcode count trajectory for a single neutral lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲⁽ᵐ⁾::Array{Int64, 3}</code>: <code>T × M × R</code> array where <code>T</code> is the number of time</li></ul><p>points in the data set, <code>M</code> is the number of mutant lineage barcodes, and <code>R</code> is the number of experimental replicates. For each slice on the <code>R</code>-axis, each   column represents the barcode count trajectory for a single mutant lineage.   <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</p><ul><li><code>R̲̲::Array{Int64, 3}</code>:: <code>T × B × R</code> where <code>T</code> is the number of time points in the data set, <code>B</code> is the number of barcodes, and <code>R</code> is the number of experimental replicates. For each slince in the <code>R</code> axis, each column represents the barcode count trajectory for a single lineage. <strong>NOTE</strong>: This matrix does not necessarily need to be equivalent to <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾)</code>. This is because <code>R̲̲⁽ᵐ⁾</code> can exclude mutant barcodes to perform the joint inference only for a subgroup, but <code>R̲̲</code> must still contain all counts. Usually, if <code>R̲̲⁽ᵐ⁾</code> excludes mutant barcodes, <code>R̲̲</code> must be of the form <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾)</code>, where <code>R̲̲⁽ᴹ⁾</code> is a vector that aggregates all excluded mutant barcodes into a &quot;super barcode.&quot;</li><li><code>n̲ₜ::Vector{Vector{Int64}}</code>: <code>R</code> Vectors with the total number of barcode counts for each time point on each experimental replicate. <strong>NOTE</strong>: Each vector vector <strong>must</strong> be equivalent to computing <code>vec(sum(R̲̲, dims=2))</code>. The reason it is an independent input parameter is to avoid the <code>sum</code> computation within the <code>Turing</code> model.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>s_pop_prior::VecOrMat{Float64}=[0.0, 2.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>s_pop_prior[1]</code> = mean, <code>s_pop_prior[2]</code> =   standard deviation, Matrix: <code>s_pop_prior[:, 1] = mean</code>, <code>s_pop_prior[:, 2] =   standard deviation</code>) for a Normal prior on the population mean fitness   values. If <code>typeof(s_pop_prior) &lt;: Matrix</code>, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.</li><li><code>logσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>logσ_pop_prior[1]</code> = mean, <code>logσ_pop_prior[2]</code> =   standard deviation, Matrix: <code>logσ_pop_prior[:, 1] = mean</code>, <code>logσ_pop_prior[:, 2] =   standard deviation</code>) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If <code>typeof(logσ_pop_prior) &lt;:   Matrix</code>, there should be as many rows in the matrix as pairs of time   adjacent time points × number of replicates in dataset.</li><li><code>s_mut_prior::VecOrMat{Float64}=[0.0, 2.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> =   standard deviation, Matrix: <code>s_mut_prior[:, 1] = mean</code>, <code>s_mut_prior[:, 2] =   standard deviation</code>) for a Normal prior on the mutant fitness values. If   <code>typeof(s_mut_prior) &lt;: Matrix</code>, there should be as many rows in the matrix   as number of mutant lineages × number of replicates in the dataset.</li><li><code>logσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]</code>: Vector or Matrix with the correspnding parameters (Vector: <code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> = standard deviation, Matrix: <code>s_mut_prior[:, 1] = mean</code>, <code>s_mut_prior[:, 2] = standard deviation</code>) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If <code>typeof(logσ_mut_prior) &lt;: Matrix</code>, there should be as many rows in the matrix as mutant lineages × number of replicates in the dataset.</li><li><code>logλ_prior::VecOrMat{Float64}=[3.0, 3.0]</code>: Vector or Matrix with the correspnding parameters (Vector: <code>logλ_prior[1]</code> = mean, <code>logλ_prior[2]</code> = standard deviation, Matrix: <code>logλ_prior[:, 1] = mean</code>, <code>logλ_prior[:, 2] = standard deviation</code>) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count <code>n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾)</code>. If <code>typeof(logλ_prior) &lt;: Matrix</code>, there should be as many rows in the matrix as number of barcodes × number of time points × number of replicates in the dataset.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/4d21f704180ee859cb81dc408e3fbce15c2c3d2a/src/model_fitness_normal_hierarchical_replicates.jl#L5-L77">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.fitness_normal-Tuple{Matrix{Int64}, Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}" href="#BayesFitness.model.fitness_normal-Tuple{Matrix{Int64}, Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}"><code>BayesFitness.model.fitness_normal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fitness_lognormal(R̲̲, R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, n̲ₜ; s_pop_prior, logσ_pop_prior, s_mut_prior, logσ_mut_prior, logλ_prior)</code></pre><p><code>Turing.jl</code> model to sample the joint posterior distribution for a competitive fitness experiment.</p><p><strong>Model</strong></p><p><code>[write model here]</code></p><p><strong>Arguments</strong></p><ul><li><code>R̲̲⁽ⁿ⁾::Matrix{Int64}</code>: <code>T × N</code> matrix where <code>T</code> is the number of time points in the data set and <code>N</code> is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲⁽ᵐ⁾::Matrix{Int64}</code>: <code>T × M</code> matrix where <code>T</code> is the number of time points in the data set and <code>M</code> is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲::Matrix{Int64}</code>:: <code>T × B</code> matrix, where <code>T</code> is the number of time points in the data set and <code>B</code> is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. <strong>NOTE</strong>: This matrix does not necessarily need to be equivalent to <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾)</code>. This is because <code>R̲̲⁽ᵐ⁾</code> can exclude mutant barcodes to perform the joint inference only for a subgroup, but <code>R̲̲</code> must still contain all counts. Usually, if <code>R̲̲⁽ᵐ⁾</code> excludes mutant barcodes, <code>R̲̲</code> must be of the form <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾)</code>, where <code>R̲̲⁽ᴹ⁾</code> is a vector that aggregates all excluded mutant barcodes into a &quot;super barcode.&quot;</li><li><code>n̲ₜ::Vector{Int64}</code>: Vector with the total number of barcode counts for each time point. <strong>NOTE</strong>: This vector <strong>must</strong> be equivalent to computing <code>vec(sum(R̲̲, dims=2))</code>. The reason it is an independent input parameter is to avoid the <code>sum</code> computation within the <code>Turing</code> model.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>s_pop_prior::VecOrMat{Float64}=[0.0, 2.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>s_pop_prior[1]</code> = mean, <code>s_pop_prior[2]</code> =   standard deviation, Matrix: <code>s_pop_prior[:, 1] = mean</code>, <code>s_pop_prior[:, 2] =   standard deviation</code>) for a Normal prior on the population mean fitness   values. If <code>typeof(s_pop_prior) &lt;: Matrix</code>, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.</li><li><code>logσ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>logσ_pop_prior[1]</code> = mean, <code>logσ_pop_prior[2]</code> =   standard deviation, Matrix: <code>logσ_pop_prior[:, 1] = mean</code>, <code>logσ_pop_prior[:, 2] =   standard deviation</code>) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If <code>typeof(logσ_pop_prior) &lt;:   Matrix</code>, there should be as many rows in the matrix as pairs of time   adjacent time points in dataset.</li><li><code>s_mut_prior::VecOrMat{Float64}=[0.0, 2.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> =   standard deviation, Matrix: <code>s_mut_prior[:, 1] = mean</code>, <code>s_mut_prior[:, 2] =   standard deviation</code>) for a Normal prior on the mutant fitness values. If   <code>typeof(s_mut_prior) &lt;: Matrix</code>, there should be as many rows in the matrix   as mutant lineages in the dataset.</li><li><code>logσ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]</code>: Vector or Matrix with the correspnding parameters (Vector: <code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> = standard deviation, Matrix: <code>s_mut_prior[:, 1] = mean</code>, <code>s_mut_prior[:, 2] = standard deviation</code>) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If <code>typeof(logσ_mut_prior) &lt;: Matrix</code>, there should be as many rows in the matrix as mutant lineages in the dataset.</li><li><code>logλ_prior::VecOrMat{Float64}=[3.0, 3.0]</code>: Vector or Matrix with the correspnding parameters (Vector: <code>logλ_prior[1]</code> = mean, <code>logλ_prior[2]</code> = standard deviation, Matrix: <code>logλ_prior[:, 1] = mean</code>, <code>logλ_prior[:, 2] = standard deviation</code>) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count <code>n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾)</code>. If <code>typeof(logλ_prior) &lt;: Matrix</code>, there should be as many rows in the matrix as number of barcodes × number of time points in the dataset.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/4d21f704180ee859cb81dc408e3fbce15c2c3d2a/src/model_fitness_normal.jl#L1-L67">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.freq_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}" href="#BayesFitness.model.freq_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}"><code>BayesFitness.model.freq_lognormal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">freq_lognormal(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲, n̲ₜ; λ_prior)</code></pre><p><code>Turing.jl</code> model to sample the joint posterior distribution for frequency values on a fitness experiment.</p><p><strong>Model</strong></p><p><code>[write model here]</code></p><p><strong>Arguments</strong></p><ul><li><code>R̲̲⁽ⁿ⁾::Matrix{Int64}</code>: <code>T × N</code> matrix where <code>T</code> is the number of time points in the data set and <code>N</code> is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. <strong>NOTE</strong>: This is a place-holder variable only used to reuse functions from the <code>mcmc</code> module.</li><li><code>R̲̲⁽ᵐ⁾::Matrix{Int64}</code>: <code>T × M</code> matrix where <code>T</code> is the number of time points in the data set and <code>M</code> is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time. <strong>NOTE</strong>: This is a place-holder variable only used to reuse functions from the <code>mcmc</code> module.</li><li><code>R̲̲::Vector{Vector{Int64}}</code>:: <code>T × B</code> matrix–split into a vector of vectors for computational efficiency–where <code>T</code> is the number of time points in the data set and <code>B</code> is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. <strong>NOTE</strong>: This matrix does not necessarily need to be equivalent to <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾)</code>. This is because <code>R̲̲⁽ᵐ⁾</code> can exclude mutant barcodes to perform the joint inference only for a subgroup, but <code>R̲̲</code> must still contain all counts. Usually, if <code>R̲̲⁽ᵐ⁾</code> excludes mutant barcodes, <code>R̲̲</code> must be of the form <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾)</code>, where <code>R̲̲⁽ᴹ⁾</code> is a vector that aggregates all excluded mutant barcodes into a &quot;super barcode.&quot;</li><li><code>n̲ₜ::Vector{Int64}</code>: Vector with the total number of barcode counts for each time point. <strong>NOTE</strong>: This vector <strong>must</strong> be equivalent to computing <code>vec(sum(R̲̲, dims=2))</code>. The reason it is an independent input parameter is to avoid the <code>sum</code> computation within the <code>Turing</code> model.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>λ_prior::Vector{Float64}=[3.0, 3.0]</code>: Vector with the corresponding parameters (<code>λ_prior[1]</code> = mean, <code>λ_prior[2]</code> = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count <code>n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾)</code>. <strong>NOTE</strong>: This method assigns   the same prior to <strong>all</strong> mutant fitness error values to be inferred.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/4d21f704180ee859cb81dc408e3fbce15c2c3d2a/src/model_freq_lognormal.jl#L5-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.multienv_fitness_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}" href="#BayesFitness.model.multienv_fitness_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}"><code>BayesFitness.model.multienv_fitness_lognormal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">multienv_fitness_lognormal(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲, n̲ₜ; kwargs)</code></pre><p><code>Turing.jl</code> model to sample the joint posterior distribution for a competitive fitness experiment with different environments on each growth-dilution cycle.</p><p><strong>Model</strong></p><p><code>[write model here]</code></p><p><strong>Arguments</strong></p><ul><li><code>R̲̲⁽ⁿ⁾::Matrix{Int64}</code>: <code>T × N</code> matrix where <code>T</code> is the number of time points in the data set and <code>N</code> is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲⁽ᵐ⁾::Matrix{Int64}</code>: <code>T × M</code> matrix where <code>T</code> is the number of time points in the data set and <code>M</code> is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲::Vector{Vector{Int64}}</code>:: <code>T × B</code> matrix–split into a vector of vectors for computational efficiency–where <code>T</code> is the number of time points in the data set and <code>B</code> is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. <strong>NOTE</strong>: This matrix does not necessarily need to be equivalent to <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾)</code>. This is because <code>R̲̲⁽ᵐ⁾</code> can exclude mutant barcodes to perform the joint inference only for a subgroup, but <code>R̲̲</code> must still contain all counts. Usually, if <code>R̲̲⁽ᵐ⁾</code> excludes mutant barcodes, <code>R̲̲</code> must be of the form <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, R̲̲⁽ᴹ⁾)</code>, where <code>R̲̲⁽ᴹ⁾</code> is a vector that aggregates all excluded mutant barcodes into a &quot;super barcode.&quot;</li><li><code>n̲ₜ::Vector{Int64}</code>: Vector with the total number of barcode counts for each time point. <strong>NOTE</strong>: This vector <strong>must</strong> be equivalent to computing <code>vec(sum(R̲̲, dims=2))</code>. The reason it is an independent input parameter is to avoid the <code>sum</code> computation within the <code>Turing</code> model.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>envs::Vector{&lt;:Any}</code>: List of environments for each time point in dataset. NOTE: The length must be equal to that of <code>n̲ₜ</code> to have one environment per time point.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>s_pop_prior::VecOrMat{Float64}=[0.0, 2.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>s_pop_prior[1]</code> = mean, <code>s_pop_prior[2]</code> =   standard deviation, Matrix: <code>s_pop_prior[:, 1] = mean</code>, <code>s_pop_prior[:, 2] =   standard deviation</code>) for a Normal prior on the population mean fitness   values. If <code>typeof(s_pop_prior) &lt;: Matrix</code>, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.</li><li><code>σ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>σ_pop_prior[1]</code> = mean, <code>σ_pop_prior[2]</code> =   standard deviation, Matrix: <code>σ_pop_prior[:, 1] = mean</code>, <code>σ_pop_prior[:, 2] =   standard deviation</code>) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If <code>typeof(σ_pop_prior) &lt;:   Matrix</code>, there should be as many rows in the matrix as pairs of time   adjacent time points in dataset.</li><li><code>s_mut_prior::VecOrMat{Float64}=[0.0, 2.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> =   standard deviation, Matrix: <code>s_mut_prior[:, 1] = mean</code>, <code>s_mut_prior[:, 2] =   standard deviation</code>) for a Normal prior on the mutant fitness values. If   <code>typeof(s_mut_prior) &lt;: Matrix</code>, there should be as many rows in the matrix   as mutant lineages × number of unique environments in the dataset.</li><li><code>σ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]</code>: Vector or Matrix with the correspnding parameters (Vector: <code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> = standard deviation, Matrix: <code>s_mut_prior[:, 1] = mean</code>, <code>s_mut_prior[:, 2] = standard deviation</code>) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If <code>typeof(σ_mut_prior) &lt;: Matrix</code>, there should be as many rows in the matrix as mutant lineages × number of unique environments in the dataset.</li><li><code>λ_prior::VecOrMat{Float64}=[3.0, 3.0]</code>: Vector or Matrix with the correspnding parameters (Vector: <code>λ_prior[1]</code> = mean, <code>λ_prior[2]</code> = standard deviation, Matrix: <code>λ_prior[:, 1] = mean</code>, <code>λ_prior[:, 2] = standard deviation</code>) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count <code>n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾)</code>. If <code>typeof(λ_prior) &lt;: Matrix</code>, there should be as many rows in the matrix as number of barcodes × number of time points in the dataset.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/4d21f704180ee859cb81dc408e3fbce15c2c3d2a/src/model_multienv_fitness_lognormal.jl#L5-L78">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.multienv_fitness_lognormal-Tuple{Matrix{Int64}, Vector{Int64}, Vector{Vector{Int64}}, Vector{Int64}}" href="#BayesFitness.model.multienv_fitness_lognormal-Tuple{Matrix{Int64}, Vector{Int64}, Vector{Vector{Int64}}, Vector{Int64}}"><code>BayesFitness.model.multienv_fitness_lognormal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">multienv_fitness_lognormal(R̲̲⁽ⁿ⁾, r̲⁽ᵐ⁾, R̲̲, n̲ₜ; kwargs)</code></pre><p><code>Turing.jl</code> model to sample the posterior distribution for a competitive fitness experiment with different environments on each growth-dilution cycle using data from a single mutant barcode and all available neutral barcodes.</p><p><strong>Model</strong></p><p><code>[write model here]</code></p><p><strong>Arguments</strong></p><ul><li><code>R̲̲⁽ⁿ⁾::Matrix{Int64}</code>: <code>T × N</code> matrix where <code>T</code> is the number of time points in the data set and <code>N</code> is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>r̲⁽ᵐ⁾::Vector{Int64}</code>: <code>T</code> dimensional vector where <code>T</code> is the number of time points in the data set. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲::Matrix{Int64}</code>:: <code>T × (N+2)</code> matrix, where <code>T</code> is the number of time points in the data set and <code>N</code> is the number of neutral barcodes. Each of the first <code>N</code> columns represent the barcode count trajectory for a single neutral lineage. The <code>N+1</code> column represents the count trajectory for the relevant mutant barcode. The <code>N+2</code> column represents the trajectory of all other ignored barcodes.</li><li><code>n̲ₜ::Vector{Int64}</code>: Vector with the total number of barcode counts for each time point. <strong>NOTE</strong>: This vector <strong>must</strong> be equivalent to computing <code>vec(sum(R̲̲, dims=2))</code>. The reason it is an independent input parameter is to avoid the <code>sum</code> computation within the <code>Turing</code> model.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>envs::Vector{&lt;:Any}</code>: List of environments for each time point in dataset. NOTE: The length must be equal to that of <code>n̲ₜ</code> to have one environment per time point.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>s_pop_prior::VecOrMat{Float64}=[0.0, 2.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>s_pop_prior[1]</code> = mean, <code>s_pop_prior[2]</code> =   standard deviation, Matrix: <code>s_pop_prior[:, 1] = mean</code>, <code>s_pop_prior[:, 2] =   standard deviation</code>) for a Normal prior on the population mean fitness   values. If <code>typeof(s_pop_prior) &lt;: Matrix</code>, there should be as many rows in   the matrix as pairs of time adjacent time points in dataset.</li><li><code>σ_pop_prior::VecOrMat{Float64}=[0.0, 1.0]</code>: Vector or Matrix with the   correspnding parameters (Vector: <code>σ_pop_prior[1]</code> = mean, <code>σ_pop_prior[2]</code> =   standard deviation, Matrix: <code>σ_pop_prior[:, 1] = mean</code>, <code>σ_pop_prior[:, 2] =   standard deviation</code>) for a Log-Normal prior on the population mean fitness   error utilized in the log-likelihood function. If <code>typeof(σ_pop_prior) &lt;:   Matrix</code>, there should be as many rows in the matrix as pairs of time   adjacent time points in dataset.</li><li><code>s_mut_prior::VecOrMat{Float64}=[0.0, 2.0]</code>: Vector or Matrix with the correspnding parameters (Vector: <code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> = standard deviation, Matrix: <code>s_mut_prior[:, 1] = mean</code>, <code>s_mut_prior[:, 2] = standard deviation</code>) for a Normal prior on the mutant fitness values. If <code>typeof(s_mut_prior) &lt;: Matrix</code>, there should be as many rows in the matrix as unique environments.</li><li><code>σ_mut_prior::VecOrMat{Float64}=[0.0, 1.0]</code>: Vector or Matrix with the correspnding parameters (Vector: <code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> = standard deviation, Matrix: <code>s_mut_prior[:, 1] = mean</code>, <code>s_mut_prior[:, 2] = standard deviation</code>) for a Log-Normal prior on the mutant fitness error utilized in the log-likelihood function. If <code>typeof(σ_mut_prior) &lt;: Matrix</code>, there should be as many rows in the matrix as unique environments.</li><li><code>λ_prior::Vector{Float64}=[3.0, 3.0]</code>: Vector with the corresponding parameters (<code>λ_prior[1]</code> = mean, <code>λ_prior[2]</code> = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count <code>n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾)</code>. <strong>NOTE</strong>: This method assigns   the same prior to <strong>all</strong> mutant fitness error values to be inferred.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/4d21f704180ee859cb81dc408e3fbce15c2c3d2a/src/model_multienv_fitness_lognormal.jl#L256-L322">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.neutrals_lognormal-Tuple{Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}" href="#BayesFitness.model.neutrals_lognormal-Tuple{Matrix{Int64}, Vector{Vector{Int64}}, Vector{Int64}}"><code>BayesFitness.model.neutrals_lognormal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mean_fitness_lognormal(R̲̲, R̲̲⁽ⁿ⁾, n̲ₜ; s_pop_prior, σ_pop_prior, λ_prior)</code></pre><p><code>Turing.jl</code> model to sample the joint posterior distribution of the population mean fitness for a competitive fitness experiment using only the neutral lineages.</p><p><strong>Model</strong></p><p><code>[write model here]</code></p><p><strong>Arguments</strong></p><ul><li><code>R̲̲⁽ⁿ⁾::Matrix{Int64}</code>: <code>T × N</code> matrix where <code>T</code> is the number of time points in the data set and <code>N</code> is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲::Matrix{Int64}</code>:: <code>T × B</code> matrix, where <code>T</code> is the number of time points in the data set and <code>B</code> is the number of barcodes. Each column represents the barcode count trajectory for a single lineage.</li><li><code>n̲ₜ::Vector{Int64}</code>: Vector with the total number of barcode counts for each time point. <strong>NOTE</strong>: This vector <strong>must</strong> be equivalent to computing <code>vec(sum(R̲̲, dims=2))</code>. The reason it is an independent input parameter is to avoid the <code>sum</code> computation within the <code>Turing</code> model.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>s_pop_prior::Vector{Float64}=[0.0, 2.0]</code>: Vector with the correspnding   parameters (<code>s_pop_prior[1]</code> = mean, <code>s_pop_prior[2]</code> = standard deviation)   for a Normal prior on the population mean fitness values. <strong>NOTE</strong>: This   method assigns the same prior to <strong>all</strong> population mean fitness to be   inferred.</li><li><code>σ_pop_prior::Vector{Float64}=[0.0, 1.0]</code>: Vector with the correspnding   parameters (<code>σ_pop_prior[1]</code> = mean, <code>σ_pop_prior[2]</code> = standard deviation)   for a Log-Normal prior on the population mean fitness error utilized in the   log-likelihood function. <strong>NOTE</strong>: This method assigns the same prior to   <strong>all</strong> population mean fitness errors to be inferred.</li><li><code>λ_prior::Vector{Float64}=[3.0, 3.0]</code>: Vector with the corresponding parameters (<code>λ_prior[1]</code> = mean, <code>λ_prior[2]</code> = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count <code>n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾)</code>. <strong>NOTE</strong>: This method assigns   the same prior to <strong>all</strong> mutant fitness error values to be inferred.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/4d21f704180ee859cb81dc408e3fbce15c2c3d2a/src/model_neutrals_lognormal.jl#L1-L41">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../mcmc/">« mcmc</a><a class="docs-footer-nextpage" href="../stats/">stats »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Saturday 29 July 2023 18:21">Saturday 29 July 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
