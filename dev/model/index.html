<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>model · BayesFitness</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">BayesFitness</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">BayesFitness</a></li><li><a class="tocitem" href="../mcmc/">mcmc</a></li><li class="is-active"><a class="tocitem" href>model</a></li><li><a class="tocitem" href="../stats/">stats</a></li><li><a class="tocitem" href="../utils/">utils</a></li><li><a class="tocitem" href="../viz/">viz</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>model</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/mrazomej/BayesFitness.jl/blob/main/docs/src/model.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="model"><a class="docs-heading-anchor" href="#model">model</a><a id="model-1"></a><a class="docs-heading-anchor-permalink" href="#model" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.env_mutant_fitness_lognormal-Tuple{Vector{Int64}, Vector{Int64}}" href="#BayesFitness.model.env_mutant_fitness_lognormal-Tuple{Vector{Int64}, Vector{Int64}}"><code>BayesFitness.model.env_mutant_fitness_lognormal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">env_mutant_fitness_lognormal(r̲⁽ᵐ⁾, R̲; α, μ_sₜ, σ_sₜ, s_prior, σ_prior, σ_trunc)</code></pre><p><code>Turing.jl</code> model to sample out of the posterior distribution for a single mutant fitness value <code>s⁽ᵐ⁾</code>, given the raw barcode counts and the parametrization of the population mean fitness distribution.</p><p><strong>Arguments</strong></p><ul><li><code>r̲⁽ᵐ⁾::Vector{Int64}</code>: Mutant <code>m</code> raw barcode counts time-series. Note: this vector must be the same length as <code>r̲⁽ᶜ⁾</code>. This means that each entry <code>r̲⁽ᵐ⁾[i]</code> contains the number of reads from barcode <code>m</code> at time <code>i</code>.</li><li><code>R̲::Vector{Int64}</code>: time-series of Raw <strong>total</strong> reads. This means that entry <code>R̲[i]</code> contains the total number of reads obtained at time <code>i</code>.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>envs::Vector{&lt;:Any}</code>: Vector defining the order of environments. Environments can be labeled with numbers (e.g. [1, 2, 2, 3, 1, 3]), strings (e.g. [&quot;env1&quot;, &quot;env2&quot;, &quot;env1&quot;]), or any convenient label. The point being that they should follow the order of environments to which strains were exposed during the experiment.</li><li><code>α::Vector{Float64}</code>: Parameters for Beta prior distribution.</li><li><code>μ_sₜ::Vector{Float64}</code>: Array with the time-series mean values of the population mean fitness. This means entry <code>μ_sₜ[i]</code> contains the inferred mean value of the population mean fitness for time <code>i</code>, assuming <code>sₜ[i] ~ Normal(μ_sₜ[i], σ_sₜ[i])</code>.</li><li><code>σ_sₜ::Vector{Float64}</code>: Array with the time-series values of the population mean fitness standard deviation. This means entry <code>σ_sₜ[i]</code> contains the inferred value of the standard deviation of the population mean fitness at time <code>i</code>, assuming <code>sₜ[i] ~ Normal(μ_sₜ[i], σ_sₜ[i])</code>.</li></ul><p><strong>Optional arguments</strong></p><ul><li><code>s_prior::Vector{Real}=[0.0, 2.0]</code>: Parameters for the mutant fitness prior distribution π(s⁽ᵐ⁾).</li><li><code>σ_prior::Vector{Real}=[0.0, 1.0]</code>: Parameters for the nuisance standard deviation parameter prior distribution π(σ⁽ᵐ⁾).</li><li><code>σ_trunc::Real=0.0</code>: Value at which truncate the normal distribution to define it as a half-normal.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/b9d49a8fa8c80b61c0277c07ba25049a6a649e57/src/model.jl#L452-L489">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.fitness_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Matrix{Int64}, Vector{Int64}}" href="#BayesFitness.model.fitness_lognormal-Tuple{Matrix{Int64}, Matrix{Int64}, Matrix{Int64}, Vector{Int64}}"><code>BayesFitness.model.fitness_lognormal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fitness_lognormal(R̲̲, R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾, n̲ₜ; s_pop_prior, σ_pop_prior, s_mut_prior, σ_mut_prior, λ_prior)</code></pre><p><code>Turing.jl</code> model to sample the joint posterior distribution for a competitive fitness experiment.</p><p><strong>Model</strong></p><p><code>[write model here]</code></p><p><strong>Arguments</strong></p><ul><li><code>R̲̲⁽ⁿ⁾::Matrix{Int64}</code>: <code>T × N</code> matrix where <code>T</code> is the number of time points in the data set and <code>N</code> is the number of neutral lineage barcodes. Each column represents the barcode count trajectory for a single neutral lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲⁽ᵐ⁾::Matrix{Int64}</code>: <code>T × M</code> matrix where <code>T</code> is the number of time points in the data set and <code>M</code> is the number of mutant lineage barcodes. Each column represents the barcode count trajectory for a single mutant lineage. <strong>NOTE</strong>: The model assumes the rows are sorted in order of increasing time.</li><li><code>R̲̲::Matrix{Int64}</code>:: <code>T × B</code> matrix, where <code>T</code> is the number of time points in the data set and <code>B</code> is the number of barcodes. Each column represents the barcode count trajectory for a single lineage. <strong>NOTE</strong>: This matrix <strong>must</strong> be equivalent to <code>hcat(R̲̲⁽ⁿ⁾, R̲̲⁽ᵐ⁾)</code>. The reason it is an independent input parameter is to avoid the <code>hcat</code> computation within the <code>Turing</code> model.</li><li><code>n̲ₜ::Vector{Int64}</code>: Vector with the total number of barcode counts for each time point. <strong>NOTE</strong>: This vector <strong>must</strong> be equivalent to computing <code>vec(sum(R̲̲, dims=2))</code>. The reason it is an independent input parameter is to avoid the <code>sum</code> computation within the <code>Turing</code> model.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>s_pop_prior::Vector{Float64}=[0.0, 2.0]</code>: Vector with the correspnding   parameters (<code>s_pop_prior[1]</code> = mean, <code>s_pop_prior[2]</code> = standard deviation)   for a Normal prior on the population mean fitness values. <strong>NOTE</strong>: This   method assigns the same prior to <strong>all</strong> population mean fitness to be   inferred.</li><li><code>σ_pop_prior::Vector{Float64}=[0.0, 1.0]</code>: Vector with the correspnding   parameters (<code>σ_pop_prior[1]</code> = mean, <code>σ_pop_prior[2]</code> = standard deviation)   for a Log-Normal prior on the population mean fitness error utilized in the   log-likelihood function. <strong>NOTE</strong>: This method assigns the same prior to   <strong>all</strong> population mean fitness errors to be inferred.</li><li><code>s_mut_prior::Vector{Float64}=[0.0, 2.0]</code>: Vector with the correspnding   parameters (<code>s_mut_prior[1]</code> = mean, <code>s_mut_prior[2]</code> = standard deviation)   for a Normal prior on the mutant fitness values. <strong>NOTE</strong>: This method   assigns the same prior to <strong>all</strong> mutant fitness values to be inferred.</li><li><code>σ_mut_prior::Vector{Float64}=[0.0, 1.0]</code>: Vector with the correspnding   parameters (<code>σ_mut_prior[1]</code> = mean, <code>σ_mut_prior[2]</code> = standard deviation)   for a Log-Normal prior on the mutant fitness error utilized in the   log-likelihood function. <strong>NOTE</strong>: This method assigns the same prior to   <strong>all</strong> mutant fitness error values to be inferred.</li><li><code>λ_prior::Vector{Float64}=[3.0, 3.0]</code>: Vector with the corresponding parameters (<code>λ_prior[1]</code> = mean, <code>λ_prior[2]</code> = standard deviation) for a Log-Normal prior on the λ parameter in the Poisson distribution. The λ parameter can be interpreted as the mean number of barcode counts since we assume any barcode count <code>n⁽ᵇ⁾ ~ Poisson(λ⁽ᵇ⁾)</code>. <strong>NOTE</strong>: This method assigns   the same prior to <strong>all</strong> mutant fitness error values to be inferred.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/b9d49a8fa8c80b61c0277c07ba25049a6a649e57/src/model.jl#L556-L610">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.mean_fitness_neutrals_lognormal-Tuple{Vector{Int64}, Vector{Int64}}" href="#BayesFitness.model.mean_fitness_neutrals_lognormal-Tuple{Vector{Int64}, Vector{Int64}}"><code>BayesFitness.model.mean_fitness_neutrals_lognormal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mean_fitness_neutrals_lognormal(r̲ₜ, r̲ₜ₊₁; α, s_prior, σ_prior, σ_trunc)</code></pre><p><code>Turing.jl</code> model to sample the posterior for a single population mean fitness value <code>sₜ</code>, given the raw barcode counts. </p><p><strong>Model</strong></p><p>For this inference, we can write Bayes theorem as</p><p class="math-container">\[\pi(
    \bar{s}_t, \sigma_t, \underline{f}_t, \underline{f}_{t+1} \mid
    \underline{r}_t, \underline{r}_{t+1}
) \propto
\prod_{n=1}^N \left[
        \pi(f_t^{(n)} \mid \gamma_t^{(n)}) 
        \pi(\gamma_t^{(n)} \mid \bar{s}_t, \sigma_t)
\right]
\pi(\bar{s}_t) \pi(\sigma_t)
\pi(\underline{f}_t \mid \underline{r}_t)
\pi(\underline{f}_{t+1} \mid \underline{r}_{t+1})\]</p><p>where</p><p class="math-container">\[\gamma_t^{(n)} \equiv \frac{f_{t+1}^{(n)}}{f_t^{n}}.\]</p><p>The parametric distributions assumed in this model are of the form</p><p class="math-container">\[f_t^{(n)} \mid \gamma_t^{(n)} \sim 
\operatorname{Uniform} \left(0, \frac{1}{\gamma_t^{(n)}} \right),\]</p><p class="math-container">\[\gamma_t^{(n)} \mid \bar{s}_t, \sigma_t \sim 
\log\mathcal{N}(\bar{s}_t, \sigma_t),\]</p><p class="math-container">\[\bar{s}_t \sim \mathcal{N}(\mu_{\bar{s}_t}, \sigma_{\bar{s}_t}),\]</p><p class="math-container">\[\sigma_t \sim 
\operatorname{Half}-\mathcal{N}(\mu_{\sigma_t}, \sigma_{\sigma_t}),\]</p><p class="math-container">\[\underline{f}_t \mid \underline{r}_t \sim 
\operatorname{Dirichlet}(\underline{\alpha}_t + \underline{r}_t),\]</p><p>and</p><p class="math-container">\[\underline{f}_{t+1} \mid \underline{r}_{t+1} \sim 
\operatorname{Dirichlet}(\underline{\alpha}_{t+1} + \underline{r}_{t+1}).\]</p><p>For this inference, we enforce all frequencies to be &gt; 0 (even for barcodes with zero reads) to compute <span>$\gamma_t^{(n)}$</span>.</p><p>The user defines the distribution parameters as:</p><ul><li><span>$\underline{\alpha}_t$</span>: <code>α</code>.</li><li><span>$[\mu_{\bar{s}_t}, \sigma_{\bar{s}_t}]$</span>: <code>s_prior</code>.</li><li><span>$[\mu_{\sigma_t}, \sigma_{\sigma_t}]$</span>: <code>σ_prior</code>.</li></ul><p><strong>Arguments</strong></p><ul><li><code>r̲ₜ::Vector{Int64}</code>: Raw counts for <strong>neutral</strong> lineages and the cumulative counts for mutant lineages at time <code>t</code>. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.</li><li><code>r̲ₜ₊₁::Vector{Int64}</code>: Raw counts for <strong>neutral</strong> lineages and the cumulative counts for mutant lineages at time <code>t + 1</code>. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>α::Vector{Float64}</code>: Parameters for Dirichlet prior distribution.</li></ul><p><strong>Optional arguments</strong></p><ul><li><code>s_prior::Vector{Real}=[0.0, 2.0]</code>: Parameters for the mean fitness prior distribution π(sₜ).</li><li><code>σ_prior::Vector{Real}=[0.0, 1.0]</code>: Parameters for the nuisance standard deviation parameter prior distribution π(σₜ).</li><li><code>σ_trunc::Real=0.0</code>: Value at which truncate the normal distribution to define it as a half-normal.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/b9d49a8fa8c80b61c0277c07ba25049a6a649e57/src/model.jl#L28-L111">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.mean_fitness_neutrals_lognormal_priors-Tuple{Vector{Int64}, Vector{Int64}}" href="#BayesFitness.model.mean_fitness_neutrals_lognormal_priors-Tuple{Vector{Int64}, Vector{Int64}}"><code>BayesFitness.model.mean_fitness_neutrals_lognormal_priors</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mean_fitness_neutrals_lognormal_priors(r̲ₜ, r̲ₜ₊₁; α, s_prior, σ_prior)</code></pre><p><code>Turing.jl</code> model to sample out of the posterior for a single population mean fitness value <code>sₜ</code>, given the raw barcode counts. Note: this function allows for the definition of any prior distributions on the mean fitness and the nuisance standard deviation parameter for the log-likelihood function.</p><p><strong>Model</strong></p><p>For this inference, we can write Bayes theorem as</p><p class="math-container">\[\pi(
    \bar{s}_t, \sigma_t, \underline{f}_t, \underline{f}_{t+1} \mid
    \underline{r}_t, \underline{r}_{t+1}
) \propto
\prod_{n=1}^N \left[
        \pi(f_t^{(n)} \mid \gamma_t^{(n)}) 
        \pi(\gamma_t^{(n)} \mid \bar{s}_t, \sigma_t)
\right]
\pi(\bar{s}_t) \pi(\sigma_t)
\pi(\underline{f}_t \mid \underline{r}_t)
\pi(\underline{f}_{t+1} \mid \underline{r}_{t+1})\]</p><p>where</p><p class="math-container">\[\gamma_t^{(n)} \equiv \frac{f_{t+1}^{(n)}}{f_t^{n}}.\]</p><p>The parametric distributions assumed in this model are of the form</p><p class="math-container">\[f_t^{(n)} \mid \gamma_t^{(n)} \sim 
\operatorname{Uniform} \left(0, \frac{1}{\gamma_t^{(n)}} \right),\]</p><p class="math-container">\[\gamma_t^{(n)} \mid \bar{s}_t, \sigma_t \sim 
\log\mathcal{N}(\bar{s}_t, \sigma_t),\]</p><p class="math-container">\[\bar{s}_t \sim \operatorname{User-defined},\]</p><p class="math-container">\[\sigma_t \sim  \operatorname{User-defined},\]</p><p class="math-container">\[\underline{f}_t \mid \underline{r}_t \sim 
\operatorname{Dirichlet}(\underline{\alpha}_t + \underline{r}_t),\]</p><p>and</p><p class="math-container">\[\underline{f}_{t+1} \mid \underline{r}_{t+1} \sim 
\operatorname{Dirichlet}(\underline{\alpha}_{t+1} + \underline{r}_{t+1}).\]</p><p>For this inference, we enforce all frequencies to be &gt; 0 (even for barcodes with zero reads) to compute <span>$\gamma_t^{(n)}$</span>.</p><p>The user defines the distribution parameters as:</p><ul><li><span>$\underline{\alpha}_t$</span>: <code>α</code>.</li></ul><p><strong>Arguments</strong></p><ul><li><code>r̲ₜ::Vector{Int64}</code>: Raw counts for <strong>neutral</strong> lineages and the cumulative counts for mutant lineages at time <code>t</code>. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.</li><li><code>r̲ₜ₊₁::Vector{Int64}</code>: Raw counts for <strong>neutral</strong> lineages and the cumulative counts for mutant lineages at time <code>t + 1</code>. NOTE: The last entry of the array must be the sum of all of the counts from mutant lineages.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>α::Vector{Float64}</code>: Parameters for Dirichlet prior distribution.</li><li><code>s_prior::Distributions.ContinuousUnivariateDistribution</code>: Parametrized univariate continuous distribution for the prior on the mean fitness π(sₜ).</li><li><code>σ_prior:::Distributions.ContinuousUnivariateDistribution</code>: Parametrized univariate continuous distribution for the prior on the nuisance standard deviation of the log-normal likelihood π(σₜ).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/b9d49a8fa8c80b61c0277c07ba25049a6a649e57/src/model.jl#L156-L235">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.mutant_fitness_lognormal-Tuple{Vector{Int64}, Vector{Int64}}" href="#BayesFitness.model.mutant_fitness_lognormal-Tuple{Vector{Int64}, Vector{Int64}}"><code>BayesFitness.model.mutant_fitness_lognormal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mutant_fitness_lognormal(r̲⁽ᵐ⁾, R̲; α, μ_sₜ, σ_sₜ, s_prior, σ_prior, σ_trunc)</code></pre><p><code>Turing.jl</code> model to sample out of the posterior distribution for a single mutant fitness value <code>s⁽ᵐ⁾</code>, given the raw barcode counts and the parametrization of the population mean fitness distribution.</p><p><strong>Arguments</strong></p><ul><li><code>r̲⁽ᵐ⁾::Vector{Int64}</code>: Mutant <code>m</code> raw barcode counts time-series. Note: this vector must be the same length as <code>r̲⁽ᶜ⁾</code>. This means that each entry <code>r̲⁽ᵐ⁾[i]</code> contains the number of reads from barcode <code>m</code> at time <code>i</code>.</li><li><code>R̲::Vector{Int64}</code>: time-series of Raw <strong>total</strong> reads. This means that entry <code>R̲[i]</code> contains the total number of reads obtained at time <code>i</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>α::Vector{Float64}</code>: Parameters for Beta prior distribution.</li><li><code>μ_sₜ::Vector{Float64}</code>: Array with the time-series mean values of the population mean fitness. This means entry <code>μ_sₜ[i]</code> contains the inferred mean value of the population mean fitness for time <code>i</code>, assuming <code>sₜ[i] ~ Normal(μ_sₜ[i], σ_sₜ[i])</code>.</li><li><code>σ_sₜ::Vector{Float64}</code>: Array with the time-series values of the population mean fitness standard deviation. This means entry <code>σ_sₜ[i]</code> contains the inferred value of the standard deviation of the population mean fitness at time <code>i</code>, assuming <code>sₜ[i] ~ Normal(μ_sₜ[i], σ_sₜ[i])</code>.</li></ul><p><strong>Optional arguments</strong></p><ul><li><code>s_prior::Vector{Real}=[0.0, 2.0]</code>: Parameters for the mutant fitness prior distribution π(s⁽ᵐ⁾).</li><li><code>σ_prior::Vector{Real}=[0.0, 1.0]</code>: Parameters for the nuisance standard deviation parameter prior distribution π(σ⁽ᵐ⁾).</li><li><code>σ_trunc::Real=0.0</code>: Value at which truncate the normal distribution to define it as a half-normal.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/b9d49a8fa8c80b61c0277c07ba25049a6a649e57/src/model.jl#L283-L315">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BayesFitness.model.mutant_fitness_lognormal_priors-Tuple{Vector{Int64}, Vector{Int64}}" href="#BayesFitness.model.mutant_fitness_lognormal_priors-Tuple{Vector{Int64}, Vector{Int64}}"><code>BayesFitness.model.mutant_fitness_lognormal_priors</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mutant_fitness_lognormal_priors(r̲⁽ᵐ⁾, R̲; α, s_mean_priors, s_prior, σ_prior, σ_trunc)</code></pre><p><code>Turing.jl</code> model to sample out of the posterior distribution for a single mutant fitness value <code>s⁽ᵐ⁾</code>, given the raw barcode counts and the parametrization of the population mean fitness distribution. Note: this function allows for the definition of any prior distributions on the population mean fitness, the nuisance standard deviation parameter for the log-likelihood function, and the mutant mean fitness.</p><p><strong>Arguments</strong></p><ul><li><code>r̲⁽ᵐ⁾::Vector{Int64}</code>: Mutant <code>m</code> raw barcode counts time-series. Note: this vector must be the same length as <code>r̲⁽ᶜ⁾</code>. This means that each entry <code>r̲⁽ᵐ⁾[i]</code> contains the number of reads from barcode <code>m</code> at time <code>i</code>.</li><li><code>R̲::Vector{Int64}</code>: time-series of Raw <strong>total</strong> reads. This means that entry <code>R̲[i]</code> contains the total number of reads obtained at time <code>i</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>α::Vector{Float64}</code>: Parameters for Beta prior distribution.</li><li><code>s_mean_priors::Vector{&lt;:Distributions.ContinuousUnivariateDistribution}</code>: Vector of univariate distributions defining the prior distribution for each population mean fitness value.</li><li><code>s_prior::Distributions.ContinuousUnivariateDistribution</code>: Parametrized univariate continuous distribution for the prior on the mean fitness π(sₜ).</li><li><code>σ_prior:::Distributions.ContinuousUnivariateDistribution</code>: Parametrized univariate continuous distribution for the prior on the nuisance standard deviation of the log-normal likelihood π(σₜ).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mrazomej/BayesFitness.jl/blob/b9d49a8fa8c80b61c0277c07ba25049a6a649e57/src/model.jl#L365-L392">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../mcmc/">« mcmc</a><a class="docs-footer-nextpage" href="../stats/">stats »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Wednesday 7 June 2023 00:37">Wednesday 7 June 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
